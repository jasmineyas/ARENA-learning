{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hirmlHtbPgY"
      },
      "source": [
        "# [0.1] - Ray Tracing (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter0-fundamentals.streamlit.app/01_[0.1]_Ray_Tracing)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_exercises.ipynb?t=20250209) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_solutions.ipynb?t=20250209)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2zick19fl-6GY1yoGaoUozyM3wObwmnQ), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUxEf2a9bPga"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-01.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37LpO4glbPga"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp_mZ7qNbPga"
      },
      "source": [
        "Today we'll be practicing batched matrix operations in PyTorch by writing a basic graphics renderer. We'll start with an extremely simplified case and work up to rendering your very own 3D Pikachu!\n",
        "\n",
        "We'll also be touching on some general topics which will be important going forwards in this course, such as:\n",
        "\n",
        "* Using GPT systems to assist your learning and coding\n",
        "* Typechecking, and good coding practices\n",
        "* Debugging, with VSCode's built-in run & debug features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_ERNigybPga"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ Rays & Segments\n",
        "\n",
        "This section introduces the key ideas and concepts in today's exercises, and guides you through some basic functions involving creating & using 2D rays.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create PyTorch tensors in a variety of ways\n",
        "> - Understand how to parametrize lines and rays in 2D\n",
        "> - Learn about type annotations and linear operations in PyTorch\n",
        "\n",
        "### 2️⃣ Batched Operations\n",
        "\n",
        "In the next section, you'll extend your work from the first section to perform batched operations, i.e. operations over several different dimensions at once.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about some important concepts related to batched operations, e.g. broadcasting and logical reductions\n",
        "> - Understand and use the `einops` library\n",
        "> - Apply this knowledge to create & work with a batch of rays\n",
        "\n",
        "### 3️⃣ Triangles\n",
        "\n",
        "In the final section we move into the 2D and 3D realms, and build up to rendering a full 3D mesh as a 2D image.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to parametrize triangles in 2D and 3D, and solve for their intersection with rays\n",
        "> - Put everything together, to render your mesh as a 2D image\n",
        "\n",
        "### 4️⃣ Video & Lighting\n",
        "\n",
        "In the last set of exercises, you can implement some more mathematically complex forms of raytracing to get things like dynamic lighting & videos. There's also some optional material at the very end which covers the `pytest` library, and has you write your own tests.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how surface normal vectors can be used to compute lighting effects\n",
        "> - Render your figures in video form (as an animated camera pan)\n",
        "> - (optional) Learn about the `pytest` library, and write your own tests for the functions you wrote"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auEwMMC2bPgb"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgTVMX9IbPgb",
        "outputId": "d8fcb24f-9c69-422f-fb22-cc6aeba5b1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.2.38-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.3-py3-none-any.whl.metadata (17 kB)\n",
            "Downloading jaxtyping-0.2.38-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, jaxtyping\n",
            "Successfully installed jaxtyping-0.2.38 wadler-lindig-0.1.3\n",
            "--2025-03-07 04:00:22--  https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main [following]\n",
            "--2025-03-07 04:00:22--  https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/main.zip’\n",
            "\n",
            "main.zip                [          <=>       ]  20.96M  9.25MB/s    in 2.3s    \n",
            "\n",
            "2025-03-07 04:00:25 (9.25 MB/s) - ‘/content/main.zip’ saved [21977856]\n",
            "\n",
            "Archive:  /content/main.zip\n",
            "4e4cea4bd6ceb184c6f10fe698ba06c38a0fc8e6\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/\n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/0.0_Prerequisites_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/numbers.npy  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part0_prereqs/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/0.1_Ray_Tracing_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/pikachu.stl  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/test_with_pytest.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part1_ray_tracing/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/0.2_CNNs_&_ResNets_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/imagenet_labels.json  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/astronaut.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/chimpanzee.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/dragonfly.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/fireworks.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/frogs.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/golden_retriever.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/goofy.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/hourglass.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/iguana.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/platypus.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/resnet_inputs/volcano.jpg  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part2_cnns/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/0.3_Optimization_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part3_optimization/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/0.4_Backprop_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part4_backprop/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/\n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/0.5_VAEs_&_GANs_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/part5_vaes_and_gans/utils.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter0_fundamentals/exercises/plotly_utils.py  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "try:\n",
        "    import jaxtyping\n",
        "except:\n",
        "    %pip install jaxtyping einops\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/{repo}-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C9lOtHDbbPgb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable\n",
        "\n",
        "import einops\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import torch as t\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact\n",
        "from jaxtyping import Bool, Float\n",
        "from torch import Tensor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter0_fundamentals\"\n",
        "section = \"part1_ray_tracing\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "if str(exercises_dir) not in sys.path:\n",
        "    sys.path.append(str(exercises_dir))\n",
        "\n",
        "import part1_ray_tracing.tests as tests\n",
        "from part1_ray_tracing.utils import render_lines_with_plotly, setup_widget_fig_ray, setup_widget_fig_triangle\n",
        "from plotly_utils import imshow\n",
        "\n",
        "MAIN = __name__ == \"__main__\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo7sUmTHbPgb"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I get a NumPy-related error</summary>\n",
        "\n",
        "This is an annoying colab-related issue which I haven't been able to find a satisfying fix for. If you restart runtime (but don't delete runtime), and run just the imports cell above again (but not the `%pip install` cell), the problem should go away.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Note on <code>pathlib</code></summary>\n",
        "\n",
        "We'll be using the `pathlib` library to define file paths. This is a more modern way of working with file paths than the `os` library, and is more cross-platform. You can read more about it [here](https://realpython.com/python-pathlib/).\n",
        "\n",
        "A major advantage of using `pathlib` rather than just relative path names is that it is more robust to which file / directory you happen to be running your code in. There's nothing more frustrating than failing to import or load a file, even though you can see it right there in your directory! Most of our code to load files will look something like this:\n",
        "\n",
        "```python\n",
        "with open(section_dir / \"pikachu.pt\", \"rb\") as f:\n",
        "    triangles = t.load(f)\n",
        "```\n",
        "\n",
        "since `section_dir` is the name of the `part1_ray_tracing` directory, and forward slashes are used to define files or directories within that directory.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcReZ7ElbPgb"
      },
      "source": [
        "# 1️⃣ Rays & Segments\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how to create PyTorch tensors in a variety of ways\n",
        "> - Understand how to parametrize lines and rays in 2D\n",
        "> - Learn about type annotations and linear operations in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WxCYeP-bPgb"
      },
      "source": [
        "## 1D Image Rendering\n",
        "\n",
        "In our initial setup, the **camera** will be a single point at the origin, and the **screen** will be the plane at x=1.\n",
        "\n",
        "**Objects** in the world consist of triangles, where triangles are represented as 3 points in 3D space (so 9 floating point values per triangle). You can build any shape out of sufficiently many triangles and your Pikachu will be made from 412 triangles.\n",
        "\n",
        "The camera will emit one or more **rays**, where a ray is represented by an **origin** point and a **direction** point. Conceptually, the ray is emitted from the origin and continues in the given direction until it intersects an object.\n",
        "\n",
        "We have no concept of lighting or color yet, so for now we'll say that a pixel on our screen should show a bright color if a ray from the origin through it intersects an object, otherwise our screen should be dark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7VIqs29bPgc"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/ray_tracing.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fK36HtZbPgc"
      },
      "source": [
        "To start, we'll let the z dimension in our `(x, y, z)` space be zero and work in the remaining two dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ifcLn23bPgc"
      },
      "source": [
        "### Exercise - implement `make_rays_1d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M343UO-bPgc"
      },
      "source": [
        "Implement the following `make_rays_1d` function so it generates some rays coming out of the origin, which we'll take to be `(0, 0, 0)`.\n",
        "\n",
        "Calling `render_lines_with_plotly` on your rays will display them in a 3D plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "ncmUo8M_bPgc",
        "outputId": "617a04d1-dba0-4e15-ddc9-cd065c8b04cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"fe1af060-de06-4140-9779-9dcebf24aa67\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fe1af060-de06-4140-9779-9dcebf24aa67\")) {                    Plotly.newPlot(                        \"fe1af060-de06-4140-9779-9dcebf24aa67\",                        [{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,10.0],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,7.7777777],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,5.5555553],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,3.3333333],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,1.1111112],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,-1.1111112],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,-3.3333333],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,-5.5555553],\"z\":[0.0,0.0],\"type\":\"scatter3d\"},{\"mode\":\"lines\",\"x\":[0.0,1.0],\"y\":[0.0,-7.7777777],\"z\":[0.0,0.0],\"type\":\"scatter3d\"}],                        {\"height\":600,\"showlegend\":false,\"title\":{\"text\":\"3D rays\"},\"width\":600,\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fe1af060-de06-4140-9779-9dcebf24aa67');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def make_rays_1d(num_pixels: int, y_limit: float) -> Tensor:\n",
        "    \"\"\"\n",
        "    num_pixels: The number of pixels in the y dimension. Since there is one ray per pixel, this is also the number of rays.\n",
        "    y_limit: At x=1, the rays should extend from -y_limit to +y_limit, inclusive of both endpoints.\n",
        "\n",
        "    Returns: shape (num_pixels, num_points=2, num_dim=3) where the num_points dimension contains (origin, direction) and the num_dim dimension contains xyz.\n",
        "\n",
        "    Example of make_rays_1d(9, 1.0): [\n",
        "        [[0, 0, 0], [1, -1.0, 0]],\n",
        "        [[0, 0, 0], [1, -0.75, 0]],\n",
        "        [[0, 0, 0], [1, -0.5, 0]],\n",
        "        ...\n",
        "        [[0, 0, 0], [1, 0.75, 0]],\n",
        "        [[0, 0, 0], [1, 1, 0]],\n",
        "    ]\n",
        "    \"\"\"\n",
        "\n",
        "    increment = 0\n",
        "    rays=[]\n",
        "    for num in range(num_pixels):\n",
        "      y = y_limit - increment\n",
        "      rays.append([[0,0,0],[1,y, 0]])\n",
        "      increment += (2 * y_limit) /num_pixels;\n",
        "    return t.tensor(rays, dtype=t.float32)\n",
        "\n",
        "\n",
        "\n",
        "    # raise NotImplementedError()\n",
        "\n",
        "\n",
        "rays1d = make_rays_1d(9, 10.0)\n",
        "fig = render_lines_with_plotly(rays1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ospkPiHObPgc"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def make_rays_1d(num_pixels: int, y_limit: float) -> Tensor:\n",
        "    \"\"\"\n",
        "    num_pixels: The number of pixels in the y dimension. Since there is one ray per pixel, this is also the number of rays.\n",
        "    y_limit: At x=1, the rays should extend from -y_limit to +y_limit, inclusive of both endpoints.\n",
        "\n",
        "    Returns: shape (num_pixels, num_points=2, num_dim=3) where the num_points dimension contains (origin, direction) and the num_dim dimension contains xyz.\n",
        "\n",
        "    Example of make_rays_1d(9, 1.0): [\n",
        "        [[0, 0, 0], [1, -1.0, 0]],\n",
        "        [[0, 0, 0], [1, -0.75, 0]],\n",
        "        [[0, 0, 0], [1, -0.5, 0]],\n",
        "        ...\n",
        "        [[0, 0, 0], [1, 0.75, 0]],\n",
        "        [[0, 0, 0], [1, 1, 0]],\n",
        "    ]\n",
        "    \"\"\"\n",
        "    rays = t.zeros((num_pixels, 2, 3), dtype=t.float32)\n",
        "    t.linspace(-y_limit, y_limit, num_pixels, out=rays[:, 1, 1])\n",
        "    rays[:, 1, 0] = 1\n",
        "    return rays\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rays = t.tensor([[[0, 0, 0], [1, -1.0, 0]],\n",
        "        [[0, 0, 0], [1, -0.75, 0]]])\n",
        "rays[:, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7J-_OIOkhb2",
        "outputId": "99c2b059-9b7c-4a73-b9c9-8971e1507c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0000, -0.7500])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wurPqhjAkhO_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek9vT4ACbPgc"
      },
      "source": [
        "### Tip - the `out` keyword argument\n",
        "\n",
        "Many PyTorch functions take an optional keyword argument `out`. If provided, instead of allocating a new tensor and returning that, the output is written directly to the `out` tensor.\n",
        "\n",
        "If you used `torch.arange` or `torch.linspace` above, try using the `out` argument. Note that a basic indexing expression like `rays[:, 1, 1]` returns a view that shares storage with `rays`, so writing to the view will modify `rays`. You'll learn more about views later today.\n",
        "\n",
        "## Ray-Object Intersection\n",
        "\n",
        "Suppose we have a line segment defined by points $L_1$ and $L_2$. Then for a given ray, we can test if the ray intersects the line segment like so:\n",
        "\n",
        "- Supposing both the ray and line segment were infinitely long, solve for their intersection point.\n",
        "- If the point exists, check whether that point is inside the line segment and the ray.\n",
        "\n",
        "Our camera ray is defined by the origin $O$ and direction $D$ and our object line is defined by points $L_1$ and $L_2$.\n",
        "\n",
        "We can write the equations for all points on the camera ray as $R(v)=O +v D$ for $v \\in [0, \\infty)$ and on the object line as $O(v)=L_1+v(L_2 - L_1)$ for $v \\in [0, 1]$.\n",
        "\n",
        "The following interactive widget lets you play with this parameterization of the problem. Run the cells one after another:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441,
          "referenced_widgets": [
            "b0a79012eb5c4678b6b4fe43dfe6ee68",
            "3bef4abd682b4496a7444c7667736126",
            "dd75869c15f0470fad4f883dacb48989",
            "6ae824706a2c42069758ff0f5233f83a",
            "d9c32151f25c4cbb81f22c3c11ea2d3f",
            "b2d230dfba894960b77d2062ce1ab315",
            "66b70d30a10e43bdac5f2810d463d8e2",
            "98f8a3669ad340dd9bb43e4f42821f71",
            "72d7e2c9a16c4dcdb3f67d709921c604",
            "a525a11a0ecd4c8db87bd03aa2df57d7",
            "7c5c63daf4d641799aaff4e230c1ec75"
          ]
        },
        "id": "MGj6cXQobPgc",
        "outputId": "6cdb6833-485e-4469-d987-2b15187a8499"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0a79012eb5c4678b6b4fe43dfe6ee68"
            },
            "text/plain": [
              "FigureWidget({\n",
              "    'data': [{'type': 'scatter', 'uid': '999efce1-388c-44ff-8ed9-df8920929091', 'x': [], 'y': []},\n",
              "             {'marker': {'size': 12},\n",
              "              'mode': 'markers',\n",
              "              'name': 'v=0',\n",
              "              'type': 'scatter',\n",
              "              'uid': 'cd644589-6d7b-41ae-b1b8-2e6fc0e2071e',\n",
              "              'x': [],\n",
              "              'y': []},\n",
              "             {'marker': {'size': 12, 'symbol': 'x'},\n",
              "              'mode': 'markers',\n",
              "              'name': 'v=1',\n",
              "              'type': 'scatter',\n",
              "              'uid': '99e810f8-7290-4baf-a835-9fcba1d7bc95',\n",
              "              'x': [],\n",
              "              'y': []}],\n",
              "    'layout': {'height': 400,\n",
              "               'margin': {'b': 10, 'l': 40, 't': 60},\n",
              "               'showlegend': False,\n",
              "               'template': '...',\n",
              "               'title': {'text': 'Ray coordinates illustration'},\n",
              "               'width': 500,\n",
              "               'xaxis': {'range': [-1.5, 2.5]},\n",
              "               'yaxis': {'range': [-1.5, 2.5]}}\n",
              "})"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(FloatSlider(value=0.0, description='v', max=6.0, step=0.01), Dropdown(description='seed'…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98f8a3669ad340dd9bb43e4f42821f71"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "fig: go.FigureWidget = setup_widget_fig_ray()\n",
        "display(fig)\n",
        "\n",
        "\n",
        "@interact(v=(0.0, 6.0, 0.01), seed=list(range(10)))\n",
        "def update(v=0.0, seed=0):\n",
        "    t.manual_seed(seed)\n",
        "    L_1, L_2 = t.rand(2, 2)\n",
        "    P = lambda v: L_1 + v * (L_2 - L_1)\n",
        "    x, y = zip(P(0), P(6))\n",
        "    with fig.batch_update():\n",
        "        fig.update_traces({\"x\": x, \"y\": y}, 0)\n",
        "        fig.update_traces({\"x\": [L_1[0], L_2[0]], \"y\": [L_1[1], L_2[1]]}, 1)\n",
        "        fig.update_traces({\"x\": [P(v)[0]], \"y\": [P(v)[1]]}, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "-0KSzsdZnK1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "8eb12ls3nUMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "DwbtvCQ7nUMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "84b7SGT6nUMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6VLIHUtz7ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j841JpDtbPgc"
      },
      "source": [
        "Setting the line equations from above equal gives the solution:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}O + u D &= L_1 + v(L_2 - L_1) \\\\ u D - v(L_2 - L_1) &= L_1 - O  \\\\ \\begin{pmatrix} D_x & (L_1 - L_2)_x \\\\ D_y & (L_1 - L_2)_y \\\\ \\end{pmatrix} \\begin{pmatrix} u \\\\ v \\\\ \\end{pmatrix} &=  \\begin{pmatrix} (L_1 - O)_x \\\\ (L_1 - O)_y \\\\ \\end{pmatrix} \\end{aligned}\n",
        "$$\n",
        "\n",
        "Once we've found values of $u$ and $v$ which satisfy this equation, if any (the lines could be parallel) we just need to check that $u \\geq 0$ and $v \\in [0, 1]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnSYzE-TbPgd"
      },
      "source": [
        "### Exercise - implement `intersect_ray_1d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        "> It involves some of today's core concepts - tensor manipulation, linear operations, etc.\n",
        "> ```\n",
        "\n",
        "Using [`torch.linalg.solve`](https://pytorch.org/docs/stable/generated/torch.linalg.solve.html) and [`torch.stack`](https://pytorch.org/docs/stable/generated/torch.stack.html), implement the `intersect_ray_1d` function to solve the above matrix equation.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - difference between stack and concatenate</summary>\n",
        "\n",
        "`torch.stack` will combine tensors along a new dimension.\n",
        "\n",
        "```python\n",
        ">>> t.stack([t.ones(2, 2), t.zeros(2, 2)], dim=0)\n",
        "tensor([[[1., 1.],\n",
        "         [1., 1.]],\n",
        "\n",
        "        [[0., 0.],\n",
        "         [0., 0.]]])\n",
        "```\n",
        "\n",
        "`torch.concat` (alias `torch.cat`) will combine tensors along an existing dimension.\n",
        "\n",
        "```python\n",
        ">>> t.cat([t.ones(2, 2), t.zeros(2, 2)], dim=0)\n",
        "tensor([[1., 1.],\n",
        "        [1., 1.],\n",
        "        [0., 0.],\n",
        "        [0., 0.]])\n",
        "```\n",
        "\n",
        "Here, you should use `torch.stack` to construct e.g. the matrix on the left hand side, because you want to combine the vectors $D$ and $L_1 - L_2$ to make a matrix.\n",
        "</details>\n",
        "\n",
        "Is it possible for the solve method to fail? Give a sample input where this would happen.\n",
        "\n",
        "<details>\n",
        "<summary>Answer - Failing Solve</summary>\n",
        "\n",
        "If the ray and segment are exactly parallel, then the solve will fail because there is no solution to the system of equations. For this function, handle this by catching the exception and returning False.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = t.tensor([1,2,3])\n",
        "l1 = t.tensor([4,4,4])\n",
        "l2 = t.tensor([6,6,6])\n",
        "t.stack((d, (l1-l2)), dim = 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eclo3oh3u5KW",
        "outputId": "cc733958-bca5-4230-9640-7a3a2b86814b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, -2],\n",
              "        [ 2, -2],\n",
              "        [ 3, -2]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "einops.einsum(t.stack((d, - (l2 - l1))), 'i j -> j i')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPLjmcuExsTq",
        "outputId": "d188ac24-97e3-436c-eafd-dde8ffa3fad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, -2],\n",
              "        [ 2, -2],\n",
              "        [ 3, -2]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the line equations from above equal gives the solution:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}O + u D &= L_1 + v(L_2 - L_1) \\\\ u D - v(L_2 - L_1) &= L_1 - O  \\\\ \\begin{pmatrix} D_x & (L_1 - L_2)_x \\\\ D_y & (L_1 - L_2)_y \\\\ \\end{pmatrix} \\begin{pmatrix} u \\\\ v \\\\ \\end{pmatrix} &=  \\begin{pmatrix} (L_1 - O)_x \\\\ (L_1 - O)_y \\\\ \\end{pmatrix} \\end{aligned}\n",
        "$$\n",
        "\n",
        "Once we've found values of $u$ and $v$ which satisfy this equation, if any (the lines could be parallel) we just need to check that $u \\geq 0$ and $v \\in [0, 1]$."
      ],
      "metadata": {
        "id": "rU-UxxzFvqQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEBIGpa6bPgd",
        "outputId": "cb975fb5-e1d6-4b1d-8abb-155d9fa6f555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_intersect_ray_1d` passed!\n",
            "All tests in `test_intersect_ray_1d_special_case` passed!\n"
          ]
        }
      ],
      "source": [
        "def intersect_ray_1d(ray: Float[Tensor, \"points dims\"], segment: Float[Tensor, \"points dims\"]) -> bool:\n",
        "    \"\"\"\n",
        "    ray: shape (n_points=2, n_dim=3)  # O, D points\n",
        "    segment: shape (n_points=2, n_dim=3)  # L_1, L_2 points\n",
        "\n",
        "    Return True if the ray intersects the segment.\n",
        "    \"\"\"\n",
        "    line = segment[1] - segment[0]\n",
        "    crossProduct = t.cross(line, ray[1])\n",
        "    if t.all(crossProduct == 0):\n",
        "      return False\n",
        "    try:\n",
        "      RHS = segment[0] - ray[0]\n",
        "      LHS = einops.einsum(t.stack((ray[1], - (segment[1] - segment[0]))), 'i j -> j i')\n",
        "      # LHS = t.stack((d, (l2-l1)), dim = 1)\n",
        "      solution = t.linalg.lstsq(LHS, RHS).solution\n",
        "      u_value, v_value = solution.tolist()\n",
        "      # u must be positive so the intersection is in front of O, and u must be between 0 and 1 so the intersection is wihtin segment\n",
        "      return u_value >= 0 and 0 <= v_value <= 1\n",
        "    except RuntimeError:\n",
        "      return False\n",
        "\n",
        "\n",
        "    # raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_intersect_ray_1d(intersect_ray_1d)\n",
        "tests.test_intersect_ray_1d_special_case(intersect_ray_1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjBi6h4sbPgd"
      },
      "source": [
        "<details>\n",
        "<summary>Help! My code is failing with a 'must be batches of square matrices' exception.</summary>\n",
        "\n",
        "Our formula only uses the x and y coordinates - remember to discard the z coordinate for now.\n",
        "\n",
        "It's good practice to write asserts on the shape of things so that your asserts will fail with a helpful error message. In this case, you could assert that the `mat` argument is of shape (2, 2) and the `vec` argument is of shape (2,). Also, see the aside below on typechecking.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def intersect_ray_1d(ray: Float[Tensor, \"points dims\"], segment: Float[Tensor, \"points dims\"]) -> bool:\n",
        "    \"\"\"\n",
        "    ray: shape (n_points=2, n_dim=3)  # O, D points\n",
        "    segment: shape (n_points=2, n_dim=3)  # L_1, L_2 points\n",
        "\n",
        "    Return True if the ray intersects the segment.\n",
        "    \"\"\"\n",
        "    # Get the x and y coordinates (ignore z)\n",
        "    ray = ray[:, :2]\n",
        "    segment = segment[:, :2]\n",
        "\n",
        "    # Ray is [[Ox, Oy], [Dx, Dy]]\n",
        "    O, D = ray\n",
        "    # Segment is [[L1x, L1y], [L2x, L2y]]\n",
        "    L_1, L_2 = segment\n",
        "\n",
        "    # Create matrix and vector, and solve equation\n",
        "    mat = t.stack([D, L_1 - L_2], dim=-1)\n",
        "    vec = L_1 - O\n",
        "\n",
        "    # Solve equation (return False if no solution)\n",
        "    try:\n",
        "        sol = t.linalg.solve(mat, vec)\n",
        "    except RuntimeError:\n",
        "        return False\n",
        "\n",
        "    # If there is a solution, check the soln is in the correct range for there to be an intersection\n",
        "    u = sol[0].item()\n",
        "    v = sol[1].item()\n",
        "    return (u >= 0.0) and (v >= 0.0) and (v <= 1.0)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Hu1lzIbPgd"
      },
      "source": [
        "### Aside - type hints\n",
        "\n",
        "Adding type hints to your code is a useful habit to get into. Some advantages of using them:\n",
        "\n",
        "- **They help document your code**, making it more readable (for yourself and for others)\n",
        "- **The improve IDE behaviour**, i.e. getting better code completion\n",
        "- **They encourage better code structure**, since they force you to consider your inputs & outputs explicitly\n",
        "- **They make debugging easier**, since you'll find it easier to spot where a variable might not match the type signature you've given for it\n",
        "\n",
        "As well as simple objects, you can also typecheck iterables of objects, for example:\n",
        "\n",
        "- `list[int]` for a list of integers,\n",
        "- `dict[str, float]` for a dict mapping strings to floats,\n",
        "- `tuple[Tensor, Tensor]` for a length-2 tuple containing tensors,\n",
        "- `tuple[int, ...]` for a tuple containing one or more integers.\n",
        "\n",
        "and you can also use other syntax to extend behaviour, e.g. `x: int | None` for a variable which can either be an integer or `None`.\n",
        "\n",
        "Jaxtyping also gives us useful type hint features, e.g. we have `ray: Float[Tensor, \"points dims\"]` to indicate a tensor of floats with dimensions `points` and `dims`. Unlike the examples above this is unlikely to be captured by syntax highlighting when you make a mistake, instead it's best to view this as an alternative to annotating the tensor shape. You may or may not prefer to use this.\n",
        "\n",
        "When in doubt however, it's best to make assertions on the variable type or tensor shape explicitly, e.g. `assert isinstance(x, Tensor)` or `assert x.shape == ...`. We generally don't recommend static type checking like [mypy](https://mypy-lang.org/) in this course, because there aren't generally standard and robust ways to do it which will fit all IDEs & use-cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_P2JiNQbPgd"
      },
      "source": [
        "# 2️⃣ Batched Operations\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn about some important concepts related to batched operations, e.g. broadcasting and logical reductions\n",
        "> - Understand and use the `einops` library\n",
        "> - Apply this knowledge to create & work with a batch of rays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNiPLImPbPgd"
      },
      "source": [
        "In this section, we'll move onto batched operations. First, it's necessary to cover some important tips for working effectively with PyTorch tensors. If you've gone through the prerequisite material then several of these should already be familiar to you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoRenZO9bPgd"
      },
      "source": [
        "## Tensor Operations - 5 Tips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEFdjaDWbPgd"
      },
      "source": [
        "### Tip (1/5) - Elementwise Logical Operations on Tensors\n",
        "\n",
        "For regular booleans, the keywords `and`, `or`, and `not` are used to do logical operations and the operators `&`, `|`, and `~` do and, or and not on each bit of the input numbers. Analogously, we use the operators `&`, `|` `~` on tensors to perform these operations on each element of the tensor, e.g. `x & y` returns the tensor with elements `x[i] and y[i]`.\n",
        "\n",
        "A few important gotchas here:\n",
        "\n",
        "- Don't try to use `and`, `or` or `not` on tensors, since Python will try to coerce the tensors to booleans, and you'll get an exception.\n",
        "- Remember about **operator precedence**! For instance, `v >= 0 & v <= 1` will actually throw an error because it's evaluated as actually evaluated as `(v >= (0 & v)) <= 1` (because `&` has high precedence) and `0 & v` is not a valid operation. When in doubt, use parentheses to force the correct parsing: `(v >= 0) & (v <= 1)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb1GW5YAbPgd"
      },
      "source": [
        "### Tip (2/5) - `einops`\n",
        "\n",
        "* Einops is a useful library which we'll dive deeper with tomorrow.\n",
        "* For now, the only important function you'll need to know is `einops.repeat`.\n",
        "* This takes as arguments a tensor and a string, and returns a new tensor which has been repeated along the specified dimensions.\n",
        "* For example, the following code shows how we can repeat a 2D tensor along the last dimension:\n",
        "\n",
        "```python\n",
        "x = t.randn(4, 3)\n",
        "x_repeated = einops.repeat(x, 'a b -> a b c', c=2) # copies x along a new dimension at the end\n",
        "\n",
        "assert x_repeated.shape == (4, 3, 2)\n",
        "t.testing.assert_close(x_repeated[:, :, 0], x)\n",
        "t.testing.assert_close(x_repeated[:, :, 1], x)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF6tM7XebPgd"
      },
      "source": [
        "### Tip (3/5) - Logical Reductions\n",
        "\n",
        "* In plain Python, if you have a list of lists and want to know if any element in a row is `True`, you could use a list comprehension like `[any(row) for row in rows]`.\n",
        "* The efficient way to do this in PyTorch is with `torch.any()` or equivalently the `.any()` method of a tensor, which accept the dimension to reduce over. Similarly, `torch.all()` or `.all()` method.\n",
        "* Both of these methods accept a `dim` argument, which is the dimension to reduce over.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - tensor methods</summary>\n",
        "\n",
        "Most functions like `torch.any(tensor, ...)` (which take a tensor as first argument) have an equivalent tensor method `tensor.any(...)`. We'll see many more examples of functions like this as we go through the course.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlQspYVGbPgd"
      },
      "source": [
        "### Tip (4/5) - Broadcasting\n",
        "\n",
        "* Broadcasting is what happens when you perform an operation on two tensors, and one is a smaller size, but is copied along the dimensions of the larger one in order to apply to it.\n",
        "* There are some complicated broadcasting rules which we'll get into later in the course (you can also review the broadcasting section in the prerequisite material which comes before this chapter), but for our purposes the only thing you need to know is this:\n",
        "* if you perform an operation on 2 tensors `A, B` where `A.shape == B.shape[-A.ndim:]` (i.e. `A` matches the last dimensions of `B`), then `A` will be copied along its leading dimensions until it has the same shape as `B`.\n",
        "\n",
        "For example:\n",
        "\n",
        "```python\n",
        "B = t.ones(4, 3, 2)\n",
        "A = t.ones(3, 2)\n",
        "C = A + B\n",
        "print(C.shape) # torch.Size([4, 3, 2]), the size of the broadcasted tensor\n",
        "print(C.max(), C.min()) # tensor(2.) tensor(2.), because all elements are 2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K24zifuVbPgd"
      },
      "source": [
        "### Tip (5/5) - Indexing\n",
        "\n",
        "Indexing is a pretty deep topic in PyTorch, and it takes a while to get fully comfortable with it. However, we'll specifically cover some features which will be useful for the following exercises.\n",
        "\n",
        "**Using ellipses.** You can use an ellipsis `...` in an indexing expression to avoid repeated `:` and to write indexing expressions that work on varying numbers of input dimensions. For example, `x[..., 0]` is equivalent to `x[:, :, 0]` if `x` is 3D, and equivalent to `x[:, :, :, 0]` if `x` is 4D.\n",
        "\n",
        "**Boolean indexing.** Boolean indexing allows you to select elements of a tensor based on a corresponding boolean tensor. Only the elements where the boolean value is True are selected. The following example shows boolean indexing *and* broadcasting:\n",
        "\n",
        "```python\n",
        "D = t.ones(2)  # Tensor with shape (2,)\n",
        "E = t.zeros(3, 2)  # Tensor with shape (3, 2)\n",
        "E[[True, False, True], :].shape  # Shape: (2, 2)\n",
        "E[[True, False, True], :] = D  # Assign values from D to selected rows\n",
        "print(E)\n",
        "# output:\n",
        "# tensor([[1., 1.],\n",
        "#         [0., 0.],\n",
        "#         [1., 1.]])\n",
        "```\n",
        "\n",
        "Note that `E` gets modified when `E[[True, False, True], :]` gets modified - this is because the latter is a **view** of the former, not a new tensor (i.e. it points to the same place in memory) - we'll look a bit more at this topic later.\n",
        "\n",
        "**Multi-dimensional indexing.** You can also apply boolean indexing to multiple dimensions simultaneously. This allows you to select elements across several dimensions based on a boolean condition. The following example shows multi-dimensional boolean indexing *and* broadcasting:\n",
        "\n",
        "```python\n",
        "D = t.ones(2)  # Tensor with shape (2,)\n",
        "F = t.zeros(2, 2, 2)  # Tensor with shape (2, 2, 2)\n",
        "F[[[True, True], [False, True]], :].shape  # Shape: (3, 2)\n",
        "F[[[True, True], [False, True]], :] = D\n",
        "print(F)\n",
        "# output:\n",
        "# tensor([[[1., 1.],\n",
        "#          [1., 1.]],\n",
        "\n",
        "#         [[0., 0.],\n",
        "#          [1., 1.]]])\n",
        "```\n",
        "\n",
        "This works because our indexing creates a tensor of shape `(3, 2)`, formed by stacking the three tensors `F[0, 0]`, `F[0, 1]` and `F[1, 1]` (those where the corresponding index value is True) along a new leading dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYEWRTJsbPge"
      },
      "source": [
        "### Summary of tips\n",
        "\n",
        "> * Use `...` to avoid repeated `:` in indexing expressions\n",
        "> * Use `&`, `|`, and `~` for elementwise logical operations on tensors\n",
        "> * Use parentheses to force the correct operator precedence\n",
        "> * Use `torch.any()` or `.any()` to do logical reductions (you can do this over a single dimension, with the `dim` argument)\n",
        "> * Tensors can broadcast along leading dimensions to operate together\n",
        ">   * e.g. `t.ones(2) + t.ones(3, 2)` works because the former tensor gets broadcasted to shape `(3, 2)`\n",
        "> * We can index with boolean tensors to select multiple elements\n",
        ">   * e.g. if `A.shape = (3, n1, n2, ...)` then `A[[True, False, True]]` has shape `(2, n1, n2, ...)` and contains the first & third rows of `A`\n",
        "> * We can index with multi-dimensional boolean tensors too\n",
        ">   * e.g. if `A.shape = (2, 2, n1, n2, ...)` then `A[[[True, True], [False, True]], :]` has shape `(3, n1, n2, ...)` and contains the elements `A[0, 0]`, `A[0, 1]` and `A[1, 1]`, stacked along a new leading dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yQWMH7EbPge"
      },
      "source": [
        "## Batched Ray-Segment Intersection\n",
        "\n",
        "We'll now move on to implementing a batched version of our previous function which takes multiple rays, multiple line segments, and returns a boolean for each ray indicating whether ***any*** segment intersects with that ray.\n",
        "\n",
        "Note - in the batched version, we don't want the solver to throw an exception just because some of the equations don't have a solution - these should just return False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq5fKoHdbPge"
      },
      "source": [
        "### Exercise - implement `intersect_rays_1d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 25-40 minutes on this exercise.\n",
        "> This will probably be one of the hardest exercises you'll complete today.\n",
        "> ```\n",
        "\n",
        "One part you might find difficult is dealing with the zero determinant cases. Previously we dealt with those by using `try / except`, but here we can't do that because we want to perform all the operations at once. Instead, we can use the following clever trick to find all the pairs of intersecting rays and segments:\n",
        "\n",
        "1. Figure out which matrices have zero determinant (e.g. with `determinants.abs() < 1e-8`)\n",
        "2. Replace those matrices with the identity matrix `t.eye(2)`, since this will certainly not raise an error when solving\n",
        "3. Find the matrices s.t. `u, v` are in the required range **and** our original matrix was non-singular\n",
        "\n",
        "This way, we've identified all pairs of rays and segments where an intersection point exists **and** that intersection point is valid (i.e. it's actually on the positive side of the ray, and somewhere in the middle of the segment).\n",
        "\n",
        "Once we have this 2D array of booleans representing whether each ray intersects with each segment, we can reduce using the torch function `t.all` to find the rays which intersect *any* segment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA1oAAADoCAYAAAD2SJV9AAAMS2lDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU8kWnltSIQQIREBK6E0QkRJASggtgPQiiEpIAoQSY0JQsaOLCq5dRLCiqyCKHRCxYVcWxe5aFgsqK+tiwa68CQF02Ve+N983d/77z5l/zjkztwwA9Ha+VJqDagKQK8mTxQT7s8YlJbNInQAFGGACI4DxBXIpJyoqHMAy0P69vLsJEGV7zUGp9c/+/1q0hCK5AAAkCuI0oVyQC/FBAPAmgVSWBwBRCnnzqXlSJV4NsY4MOghxlRJnqHCTEqep8JU+m7gYLsRPACCr8/myDAA0uiHPyhdkQB06jBY4SYRiCcR+EPvk5k4WQjwXYhtoA+ekK/XZaT/oZPxNM21Qk8/PGMSqWPoKOUAsl+bwp/+f6fjfJTdHMTCHNazqmbKQGGXMMG9PsieHKbE6xB8kaRGREGsDgOJiYZ+9EjMzFSHxKnvURiDnwpzBdQboGHlOLK+fjxHyA8IgNoQ4XZITEd5vU5guDlLawPyhZeI8XhzEehBXieSBsf02J2STYwbmvZku43L6+ed8WZ8PSv1viux4jkof084U8fr1MceCzLhEiKkQB+SLEyIg1oA4Qp4dG9Zvk1KQyY0YsJEpYpSxWEAsE0mC/VX6WGm6LCim335nrnwgduxEppgX0Y+v5mXGhahyhT0R8Pv8h7Fg3SIJJ35ARyQfFz4Qi1AUEKiKHSeLJPGxKh7Xk+b5x6jG4nbSnKh+e9xflBOs5M0gjpPnxw6Mzc+Dm1OljxdJ86LiVH7i5Vn80CiVP/heEA64IACwgALWNDAZZAFxa1d9F7xT9QQBPpCBDCACDv3MwIjEvh4JvMaCAvAnRCIgHxzn39crAvmQ/zqEVXLiQU51dQDp/X1KlWzwFOJcEAZy4L2iT0ky6EECeAIZ8T884sMqgDHkwKrs//f8APud4UAmvJ9RDMzIog9YEgOJAcQQYhDRFjfAfXAvPBxe/WB1xtm4x0Ac3+0JTwlthEeEG4R2wp1J4kLZEC/HgnaoH9Sfn7Qf84NbQU1X3B/3hupQGWfiBsABd4HzcHBfOLMrZLn9fiuzwhqi/bcIflihfjuKEwWlDKP4UWyGjtSw03AdVFHm+sf8qHxNG8w3d7Bn6PzcH7IvhG3YUEtsEXYAO4edxC5gTVg9YGHHsQasBTuqxIM77knfjhuYLabPn2yoM3TPfF9ZZSblTjVOnU5fVH15oml5yoeRO1k6XSbOyMxjceAXQ8TiSQSOI1jOTs6uACi/P6rX25vovu8Kwmz5zs3/HQDv4729vUe+c6HHAdjnDl8Jh79zNmz4aVED4PxhgUKWr+Jw5YUA3xx0+PTpA2NgDmxgPM7ADXgBPxAIQkEkiANJYCL0PhPucxmYCmaCeaAIlIDlYA0oB5vAVlAFdoP9oB40gZPgLLgEroAb4C7cPR3gBegG78BnBEFICA1hIPqICWKJ2CPOCBvxQQKRcCQGSUJSkQxEgiiQmch8pARZiZQjW5BqZB9yGDmJXEDakDvIQ6QTeY18QjFUHdVBjVArdCTKRjloGBqHTkAz0CloAboAXYqWoZXoLrQOPYleQm+g7egLtAcDmBrGxEwxB4yNcbFILBlLx2TYbKwYK8UqsVqsEa7zNawd68I+4kScgbNwB7iDQ/B4XIBPwWfjS/ByvAqvw0/j1/CHeDf+jUAjGBLsCZ4EHmEcIYMwlVBEKCVsJxwinIHPUgfhHZFIZBKtie7wWUwiZhFnEJcQNxD3EE8Q24iPiT0kEkmfZE/yJkWS+KQ8UhFpHWkX6TjpKqmD9IGsRjYhO5ODyMlkCbmQXEreST5Gvkp+Rv5M0aRYUjwpkRQhZTplGWUbpZFymdJB+UzVolpTvalx1CzqPGoZtZZ6hnqP+kZNTc1MzUMtWk2sNletTG2v2nm1h2of1bXV7dS56inqCvWl6jvUT6jfUX9Do9GsaH60ZFoebSmtmnaK9oD2QYOh4ajB0xBqzNGo0KjTuKrxkk6hW9I59In0Anop/QD9Mr1Lk6JppcnV5GvO1qzQPKx5S7NHi6E1SitSK1dridZOrQtaz7VJ2lbagdpC7QXaW7VPaT9mYAxzBpchYMxnbGOcYXToEHWsdXg6WTolOrt1WnW6dbV1XXQTdKfpVuge1W1nYkwrJo+Zw1zG3M+8yfw0zGgYZ5ho2OJhtcOuDnuvN1zPT0+kV6y3R++G3id9ln6gfrb+Cv16/fsGuIGdQbTBVIONBmcMuobrDPcaLhhePHz/8N8MUUM7wxjDGYZbDVsMe4yMjYKNpEbrjE4ZdRkzjf2Ms4xXGx8z7jRhmPiYiE1Wmxw3+YOly+KwclhlrNOsblND0xBThekW01bTz2bWZvFmhWZ7zO6bU83Z5unmq82bzbstTCzGWsy0qLH4zZJiybbMtFxrec7yvZW1VaLVQqt6q+fWetY86wLrGut7NjQbX5spNpU2122JtmzbbNsNtlfsUDtXu0y7CrvL9qi9m73YfoN92wjCCI8RkhGVI245qDtwHPIdahweOjIdwx0LHesdX460GJk8csXIcyO/Obk65Thtc7o7SntU6KjCUY2jXjvbOQucK5yvj6aNDho9Z3TD6Fcu9i4il40ut10ZrmNdF7o2u351c3eTudW6dbpbuKe6r3e/xdZhR7GXsM97EDz8PeZ4NHl89HTzzPPc7/mXl4NXttdOr+djrMeIxmwb89jbzJvvvcW73Yflk+qz2afd19SX71vp+8jP3E/ot93vGceWk8XZxXnp7+Qv8z/k/57ryZ3FPRGABQQHFAe0BmoHxgeWBz4IMgvKCKoJ6g52DZ4RfCKEEBIWsiLkFs+IJ+BV87pD3UNnhZ4OUw+LDSsPexRuFy4LbxyLjg0du2rsvQjLCElEfSSI5EWuirwfZR01JepINDE6Kroi+mnMqJiZMediGbGTYnfGvovzj1sWdzfeJl4R35xAT0hJqE54nxiQuDKxfdzIcbPGXUoySBInNSSTkhOStyf3jA8cv2Z8R4prSlHKzQnWE6ZNuDDRYGLOxKOT6JP4kw6kElITU3emfuFH8iv5PWm8tPVp3QKuYK3ghdBPuFrYKfIWrRQ9S/dOX5n+PMM7Y1VGZ6ZvZmlml5grLhe/ygrJ2pT1Pjsye0d2b05izp5ccm5q7mGJtiRbcnqy8eRpk9uk9tIiafsUzylrpnTLwmTb5Yh8grwhTwf+6LcobBQ/KR7m++RX5H+YmjD1wDStaZJpLdPtpi+e/qwgqOCXGfgMwYzmmaYz5818OIsza8tsZHba7OY55nMWzOmYGzy3ah51Xva8XwudClcWvp2fOL9xgdGCuQse/xT8U02RRpGs6NZCr4WbFuGLxItaF49evG7xt2Jh8cUSp5LSki9LBEsu/jzq57Kfe5emL21d5rZs43Licsnymyt8V1St1FpZsPLxqrGr6lazVhevfrtm0poLpS6lm9ZS1yrWtpeFlzWss1i3fN2X8szyGxX+FXvWG65fvP79BuGGqxv9NtZuMtpUsunTZvHm21uCt9RVWlWWbiVuzd/6dFvCtnO/sH+p3m6wvWT71x2SHe1VMVWnq92rq3ca7lxWg9Yoajp3pey6sjtgd0OtQ+2WPcw9JXvBXsXeP/al7ru5P2x/8wH2gdqDlgfXH2IcKq5D6qbXdddn1rc3JDW0HQ493Nzo1XjoiOORHU2mTRVHdY8uO0Y9tuBY7/GC4z0npCe6TmacfNw8qfnuqXGnrp+OPt16JuzM+bNBZ0+d45w7ft77fNMFzwuHL7Iv1l9yu1TX4tpy6FfXXw+1urXWXXa/3HDF40pj25i2Y1d9r568FnDt7HXe9Us3Im603Yy/eftWyq3228Lbz+/k3Hn1W/5vn+/OvUe4V3xf837pA8MHlb/b/r6n3a396MOAhy2PYh/dfSx4/OKJ/MmXjgVPaU9Ln5k8q37u/LypM6jzyh/j/+h4IX3xuavoT60/17+0eXnwL7+/WrrHdXe8kr3qfb3kjf6bHW9d3jb3RPU8eJf77vP74g/6H6o+sj+e+5T46dnnqV9IX8q+2n5t/Bb27V5vbm+vlC/j9/0KYEB5tEkH4PUOAGhJADDguZE6XnU+7CuI6kzbh8B/wqozZF9xA6AW/tNHd8G/m1sA7N0GgBXUp6cAEEUDIM4DoKNHD9aBs1zfuVNZiPBssDnpa1puGvg3RXUm/cHvoS1QqrqAoe2/AE9RgvikXgmfAAAAlmVYSWZNTQAqAAAACAAFARIAAwAAAAEAAQAAARoABQAAAAEAAABKARsABQAAAAEAAABSASgAAwAAAAEAAgAAh2kABAAAAAEAAABaAAAAAAAAAJAAAAABAAAAkAAAAAEAA5KGAAcAAAASAAAAhKACAAQAAAABAAADWqADAAQAAAABAAAA6AAAAABBU0NJSQAAAFNjcmVlbnNob3Qm0cQQAAAACXBIWXMAABYlAAAWJQFJUiTwAAAC22lUWHRYTUw6Y29tLmFkb2JlLnhtcAAAAAAAPHg6eG1wbWV0YSB4bWxuczp4PSJhZG9iZTpuczptZXRhLyIgeDp4bXB0az0iWE1QIENvcmUgNi4wLjAiPgogICA8cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPgogICAgICA8cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0iIgogICAgICAgICAgICB4bWxuczpleGlmPSJodHRwOi8vbnMuYWRvYmUuY29tL2V4aWYvMS4wLyIKICAgICAgICAgICAgeG1sbnM6dGlmZj0iaHR0cDovL25zLmFkb2JlLmNvbS90aWZmLzEuMC8iPgogICAgICAgICA8ZXhpZjpVc2VyQ29tbWVudD5TY3JlZW5zaG90PC9leGlmOlVzZXJDb21tZW50PgogICAgICAgICA8ZXhpZjpQaXhlbFhEaW1lbnNpb24+ODU4PC9leGlmOlBpeGVsWERpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6UGl4ZWxZRGltZW5zaW9uPjIzMjwvZXhpZjpQaXhlbFlEaW1lbnNpb24+CiAgICAgICAgIDx0aWZmOlJlc29sdXRpb25Vbml0PjI8L3RpZmY6UmVzb2x1dGlvblVuaXQ+CiAgICAgICAgIDx0aWZmOlhSZXNvbHV0aW9uPjE0NC8xPC90aWZmOlhSZXNvbHV0aW9uPgogICAgICAgICA8dGlmZjpZUmVzb2x1dGlvbj4xNDQvMTwvdGlmZjpZUmVzb2x1dGlvbj4KICAgICAgICAgPHRpZmY6T3JpZW50YXRpb24+MTwvdGlmZjpPcmllbnRhdGlvbj4KICAgICAgPC9yZGY6RGVzY3JpcHRpb24+CiAgIDwvcmRmOlJERj4KPC94OnhtcG1ldGE+CqAQqBgAAEAASURBVHgB7Z0H/BxF+f9HmpRIly4kdCEgEIIRkNAioUgRKRKFCFIFKYL0IhBKftIRBJTeJAiC9D81hCqEJkqV0ELvIErRf96rc8zNzd3t7u3u7d59ntfr+93duZnZmc8zOzPPPM8886Vhw4b9x4iEgBAQAkJACAgBISAEhIAQEAJCoGME/vOf/5gvfelLZqqOc1IGQkAICAEhIASEgBAQAkJACAiBPkcAAQtCyOJeglafNwhVXwgIASEgBISAEBACQkAICIHOEUDAsiSNlkVCVyEgBISAEBACQkAICAEhIASEQIcIWK0W2Uij1SGYSi4EhIAQEAJCQAgIASEgBIRAfyLgClYgYLVaMh3sz/agWgsBISAEhIAQEAJCQAgIASGQAQJWsAplJY1WCBWFCQEhIASEgBAQAkJACAgBISAEEiJgNVzao5UQOEUXAkJACAgBISAEhIAQEAJCQAg0Q8BquGQ62AwhhQsBISAEhIAQEAJCQAgIASEgBFIggJAljVYK4JRECAgBISAEhIAQEAJCQAgIASFgEbDmgjxbIYt77dECBZEQEAJCQAgIASEgBISAEBACQqBDBKzpINlI0OoQTCUXAkJACAgBISAEhIAQEAJCoH8RsMKVr9mapn8hUc2FgBAQAv2LwAwzzGCWWWYZM9dcc5mvfvWrZs4554zAePHFF80LL7xgnn/+efPKK6+Yf//73/0LUgc1n2mmmcw008QfYv/5z3+af/3rXx28UUmFQDkRGDlypNlqq63MbrvtZt57771yFlKl6joCX/nKV8zJJ59s7r33XnPuuedWtj+0ApcFNP4oYFPoKgSEgBAQApVFYNlllzVrrLGGWWmllcx0003XUA/CLb311lvmnHPOMffdd58N0jUmAmPHjo2E2JjRo2gIWkxE//a3v5kJEyaYRx99tO8F3S9/+ctm+umnTwJjtD/i/fffT5RGkbNHYNpppzU77rijGT58eLR488knn7R8iXjdEp5Mfywj1p999lm0uLf22mubgQMHmqOPPtpU7Tt292bBMISuLw0bNuw/mXJPmQkBISAEhEDpEEBrtfPOO0daLFu4zz//3Dz77LPRJAjt1eyzz24WX3xxs+iii9ZOtifuww8/bI4//njz8ccf26S6tkFg/vnnN0xmwHTNNdc0Q4cObZOi8WeErptuusmMGzcuEh4aY/R+yLbbbmvWXXfdRBVlgWCnnXZKlEaRs0WA/mbvvfc2Cy+8sHnppZfMYYcd1labJV5ny4NWuZUVaxb/9thjj6i/ZEw68sgjzeuvv96qKqX4zRew3GcJWqVgkQohBISAEMgPgREjRpitt966TjPw2GOPmbPPPjuaBPlvXm211cwuu+xipp566tpPDz74oDn22GP7dsJfAyLFDRqZCy64oC4lq7dgjDCFmSEmnCuvvLJZa621omc38gMPPGBOPPHEyprSuHVJeo850SyzzBIJrGADRj4xqbnjjjvMPffcYxCyWAV/5513/Gh6LgiBwYMHm7322svAu5dfftkceuihbYUsiiZeF8SgkmPNuLPffvuZ5ZZbzrz77ruRsIUpe5nJFawop32OrtJolZl1KpsQEAJCoDMENt10U7PlllvWMqHjP/PMM83NN99cCwvdrLrqqmb33Xev++mKK64wl1xySV2YHtojsOSSS5ojjjiiLuKTTz5pDjrooLowHhZccEFz+OGHNwhbzz33XKQV+Mc//tGQpl8C2PMWan8XXnihueqqq/oFhlLX82tf+1pk8oU298033zT7779/NFlOWmjxOili6eOXEWsWp8aMGRP1h2+//XYkuH/00UfpK1lQSitgua+T10EXDd0LASEgBHoIAV/IompMStsJWcS76667zGuvvcZtjdZff/0GAaD2Y4c3mCxSNv4OPPDADnMrV/KlllqqoUDswwoRjkjYm+A7xhg0aJDZYIMNQkn6JmzeeedtqCs43XDDDQ3hVQvohfaPZnbfffeNTGbBn/2daCTSUC/zOg0eeaYpI9Y4B6L9QJhfY+pYBWJPFsIWxJU/CVpV4JzKKASEgBBIiAAmVq4mi+S33HKLufrqq2PlxADhC2SsUuNIIw+aaqqpogka72DS2Uv09a9/vaE6zQQtIqLtuvTSSxvSIGgxme1XQjPo0xNPPNEglPpxqvDcC+1/9OjRZu65547gxpHL/fffnxr6XuZ1alBySlhWrP/yl7+YiRMnRrXGnN111JQTFJlka4Ut631QglYmsCoTISAEhEB5EJhtttnM9ttvX1cgTM4uuuiiurB2DzjK8GmKubkfpOcWCLDfwJ/IIMS2ErTIDo0i8VzCJT9axX6lkGaQyZio+wjgJQ7vghBOdtj/2QmJ152glyxtmbHGwsEeMYIHS/bxlZH8vtoKWVwlaJWRYyqTEBACQqADBPC4NmDAgLocrrzySvPBBx/UhbV7wDbeJ7ti7YfrOYwAJn++e/JJkya19eCIM4eQMBbSjoXf3HuhSy+9dEOlHn/88YYwBaRDgEUBztZbb731ghnQ9tCqol3AdbtLo0aNqnkqxUspTjA6IfG6E/SSpS0z1pzriCMmaOaZZza4fi8jWcHKls0KXlx1jpZFRVchIASEQA8gsMQSS5gVVlihribYu19//fV1YXEeQo4XZp111uj8rXZn4sTJv5txmFSyN2GBBRYwbODniifAU045paFYDKJDhgypTSTxbPf3v/+9IV4oILRaHBKgQmmZYPjp8U7YjwSv0NS6xHEDcfngptP9fxGgXYMrproIWLRxTFNxp33dddfVwUS/gpMWSywgnHfeedEjXiG/8Y1v2J9Mp8KveF2DMvebKmBNf2mPx1h99dUNi4ZlJ74thCyuErTKzi2VTwgIASGQAIGNNtqoITZ7JXznCg2RAgEIIz6RD4NHlQkTFPaa+fWbPHlysFpMKtnkb4lJaNwJfmi1+K9//avNquU15KJ8zjnnjMqNeVY/kS9wUncmYP2GQ5Y858iA+eabryFLjn7wacUVV6wLQjCz9M1vfrOuT+hU0BKvLbL5X6uANXtWLdFeMcVmb2YZyQpX7lWCVhk5pTIJASEgBFIgwOqkPyEimzvvvDNFbv811fATcqAkmp8q0/jx4yOHEwhb7kSj2X4fznNxKa6ghEDq788in7gaLc7Y8gmnCRwG++qrr/o/tX1efvnlo8OT20ZMGeHcc8+NzrFKmbxlMpdPNmKnE3qbT79ecZWPNvd73/uewcW3pUceecTe1q58Gyzi2EWWeeaZp/YbgpYlXHBzFEEnJF53gl6ytFXAmkWtTz/9tGauilarrIKW/T7c6xdfVjLeKLYQEAJCQAiUDAHMK2wHb4vGANVMgLBxml0xp/OJfV5V1yIg6PDHfjN3ohFayaf+CCiWWKmMK2gNnOIgYMYZZ7RJo+tLL70UHahbF9jkIY0WsklWUTCT4zydmVx22WW5CVohzWDadt0Ko3767d577zX8cRD0HHPMEVWd9h36DhC+TjvtNMP+TzTBVjBjr5bLG7TC5NEJufnZfMRri0S21ypgzcIeBxYvuuiiUeV90/hsEckuN6vVkjOM7DBVTkJACAiBriLg7pOwBcFzYFoNFKvdPnEIaa+QO8lgUAxpSNASsj/FEgN+XKcirhBn08fVZhGf82NCFDIpDMXzwzqdAPv5+c955Y9AbAUB+84sNCc2r36+0r5dbOkvPvzwwyAkt99+u/njH/8Y/Wa1rezZdE1wQ/s6g5k1CRSvmwCTQ3CVsHYPK6bN+c5YcoAnkyzpE6XRygRKZSIEhIAQ6C4CDDwhj3RPPfVU6oK5+zBsJiFhxP5WpSvndS222GK1IjcToPBy5WoJk6yshwStuNowCuaaZ9mC4gAiraYL5xp47sqDcMHcbI9bp+8L4YjAmodgB+bk6x/W3WkdypreN4sNmQ26Zaf9cxC6PYg45KDEjZ/0vghe8+2jree75rtH69+PVATWFlc0oPS3mPyl+W7p9yzBN/aqvvLKKzao61fqRLnslQLZZwlaXWePCiAEhIAQ6BwBVqVDq3wvvPBCqsxZ6V5kkUUa0uK6OQlhqhbn7CfXxI77I444ItZrjj/+eJNGw4OWypo/8aKQAMVKvT0byBYmrqDJIBsSfJNotEKCVidus9944w2DeV/VyNU82rLH5YON3+5Ke998883NKqusYq699tqaR7126dr9Xtb2b8vta8E5aLgVsUcTspNcX9DqVKOVJ68HTjHl3WGHHSITNL5PCG0/e8o49+uZZ56Jwjr9t/POOwedjHSa74QJE8yNN97YaTa19HlibV9CH8qeKoRz9pZuvfXWbY+2sGndK55zXSIv2wbd8G7d2/Zkr5TDCl0StLrFFb1XCAgBIZAhAphThAhXzWno29/+dkMyzDeSCApkwEQs5BCiIXMvIG6akHDpZRV8HDx4cF14SNBaaaWVDK6rLaG1iauRYsXcP1wTXuAaPi4tuOCCDVH//Oc/N4T1ekBo5T3ErzQ4IMx+//vfN7R3HI1kTWVt/9SThQb3O2Ay63p4C2GBK3jICmTu90G4PyEmLAnlxWv29fziF7+oM3OkXFbTcsghh5ixY8cGF1ySlJ+4CHQLL7xw0mRt43dinRDKPC+seRffEuet8W1hotgp+e0KQausZDV2CF3cZ9+rlLXmKpcQEAJCoIcR8Cc8tqpZClo33HBD6cxsEH7SkDvBDAlQDJIbbrhhXdZ4v4q7Yh9aLY4rpPFSJmp287dbiH4TtJhQ+ZMq9hBh8tUpMQE84YQTonOkqmo+lrb9gx2LGZjRWUJ4beXohm/Cehi0gpaPm6sltvnGvebFa84Gs048OCwcre4VV1xRd0TDDDPMYPbcc886M+G45S4qXie89suYF9b2PWgOf/KTn7RsTzZunKtfd3dfYJz0RcbhO+EP4iqNVpHo611CQAgIgZwQsKtofvbNNrb78dxnJvi+2Rr7gjCpSkpM3s4666y2yXjfd7/73SgehyHbw1BbJWSSl8Y5B5Mqd8UZBwDuHgDeufLKKzcIOkm0KKHV4iTawNB5aJjLvfjii60g6bnfQjgisDZr70kAYB/WT3/6U/P222+bLbfcMjJvSpI+Ttwytn9bbt9ssN3+LOKjqX366adr3x3mqC7xbaWlvHiNV0U0ixxzwYHktu1ceumlZquttjIbb7xxVGT2L6JF7lSI50DdPPZCWuE2Lb5uurywtu+g/+a4BwT3Cy64oEGTaOPFvU4//fR1Ue0ewbrALj7YNmUFLIpCmAStLjJFrxYCQkAIZIlAM4EjjcfBddddt6Fo11xzTWxve25iBIM4wgGr61bQosw33XSTm02m9+ydcldEfQGKQX3UqFEN70yyL6jZRKYh00DAXHPN1eCGnUH7/PPPD8SOH8R+s8022yx+goQxx4wZk/m+iZBm0OdXnGJiygSGdkJk0yBkQXlN3MrY/m3dkwpa9vukL7CUpaCVF6+HDBkSCdO/+c1v6vhPW0DYQkvHHj2I77ZTQQuX+WWnvLC29XYXrrAC8M2obby4V1+Az+t7jVseP54rYNnfbJg0WhYRXYWAEBACFUagmZc0Ju1JNg3jaRDbepfQ+IwbN84NqvS9P8nwJ+5s2PbN1ViZjauRmn/++ev2dgEWDjviHjK8ySabNOwXuuWWW+pMndIwACcjWeyXaPbuTszGmuUZElh9fjVLa8Nxk88ZUKeeeqrBoYDov4eRD5yyl8gSAlOrfoI9Tssuu6wh3n333WeTRZotBBY7qXSd2tQixbzJi9cIUbilR1PuE981e5+soGXr4cfrtee8sM4LJ1/QSuMAKa+yNcvXfhfao9UMIYULASEgBCqEAI4qQhqX0FlYzarFJGnHHXes+xmTwZNOOikzW/u6zLv04E4y0J7hctgSHrJGjBhh3HNb+A1zqbhu1d38bb5xhTTej0t5lzCV+93vfucGpbpPo91M8qKs88eTpi8Yvv/++4ZDn5MQpmFotEIH8SbJp5fiYiLnChWtzNLQRuBJD0Kr6u7j4t5qBfk9rclcnrxmv9B1111H8YLk7jNLu6c1mHFJA/PEOq8qu4IWAnOZBS2rNef74l4arbxahfIVAkJACBSMAM4qfG0NQsP999/ftiQIWQcddFDdxBbB4phjjmm50t024xJGQONkCW2dXelmXxYTSsxerr/++shjlo2HEItr63322Sda0b/55pvtTw3XtILWqquu2iDo4p4fb2hZCDF33323sQfNNhS6wwAm3K00Immy99syeSTdn8VevHXWWSfyppdX3dPUrdtp/D2Yzczl0FLusssuBq+mEydONCGzOL4NqwXn28L5hL9Q0a6+3eT1fPPNFxWP/i60WNWu7FX7vZtYp8EKgcXts1kUyKI/TFOWOGncBQzuJWjFQU1xhIAQEAIVQACTnoceesgsv/zytdJyICmToPHjx9fC/BvMC/G45Xq5Q9g46qij6rQ9froqPrM6766Oco+LeARSTAZZgeRsLly7u8SegJ///OcGPO+44w73p7p79n6FDnputQKLFoBN+WzadwmenXnmmbE1aW7a0D2T3zhCdyhtN8JCAmsSs0E86uFtDm2Wa+7WjbqU7Z2+5smdyNqy4sl07733jrwT0n5piyHCrNUKWkws2QP5wAMPhKI2DesWr3GSYc+7u+222xqc4jQtcIV/6BbWaSFD+zpgwIBa8ir0YdZskEJL0KqxTjdCQAgIgWojQOeOmR8Ckl2lpUa77rqrGTRoULTx2zV/w4QEF+bf+c536g7v5eBO9rTEcWJRNcSYdLvEIH7xxRfXgvCQyKHMvkOQ7bbbLorDpLLVPp+RI0c27M8i4Q9/+MNIwJs8ebLBEyQTXQRcNuoj1Ln7mzhri036t99+e/TOfvzHhN131gAOcV3kzznnnGbfffc1A/+3D0mCVn0r8s9k4mDlq666KtqDRVukTbLwQB+BgM4B4s3OgIMntGvb5yQVtLrJa7x78n4WUvjmep26iXVabF3BEDfvSYX4tO9Nks4VrEgHzhDhErQiKPRPCAgBIdAbCDAp2n///c32229vMEWD6PQ32GCDSHh4+eWXIw0Jm7/dVULiocVisoHZHANELxLmY+zDQMjxCZfE1tuhK5DaeGgLfVf1TC6Z1DMhZXKK4BQiTLVwJd6K4A0e3RCwymwa06oOWf2GhhFcfVpsscWiib+LD+0bzSTtGb7ChxVXXLF2RhTnn/ne8fx8++2ZPYN4g7POK9BenXzyydF+K+7t+VrEwyV6O/xuvfXWaDEBHHGakYS6xWsWn1hQwewVRylJzR2T1LEscbuFdSf1dwUtzJ8/+OCDTrLLJa0VrEKZS9AKoaIwISAEhECFEWAChWaLCfuaa65phg4dGpnHYdaGBsclVgixecccjsNwQwKGG78X7jER2mKLLWpVwTU+Qpa7/wQTtW9961tRHCZibKa/6KKL6hwB8OM222xj8MiWhJjQ4dSBPyawvAtHDf2wEb8ZTgiseHpEYKW9NhNYrVOGZvmEwqXNakSFNo2WCkcRCBwQmiy7AIGDmBtvvNHcddddsRZd6Gs4OgABbeAULSI8bHa4dhl4jQnxXnvtFZmVsnjS7gyxRgSrEVIGrDtBigVBFk0gFlcuueSSTrIrLK3VcCGASdAqDHa9SAgIASFQLAJMHvhjtZ8BCw0Bm9oZsBAu+MMcqB+EKxf5yy+/PDI/YRKCcDNp0qQGDRKaLUwocQ3Oqn6z1e6jjz7azVr3KRFII7DGfZUErTBStO/99tsvcjRA30A/QX+AUxMWAZIQmmI8Y+I4A8JUFucZCHQ+dZvX7MnEqQ1a5j/84Q81LbZfzl547jbWnWI4evTomlk1i11VWYyyGi6ZDnbaApReCAgBIVABBDAJxHyKv7ISeySsJz/rBTDPsiJc8deKyo5Zq7JX7bd+F1iLbv+2faDRjnuosk3T7IqmmH11q6yySrRfi2MK0Ir51E1es0dzjz32iBxg4KW11/dldRNrn+9Jn7EUsNYCHK9RFW2WrafVakmjZRHRVQgIASEgBLqGAIf5nnHGGV17v14sBLqJQK+0f75h9tFhgoh5Lvsay6KFQMuAxo09fHj0PPvssxtYjvdFJvd/+tOfGn5TQHEIYNq57bbbRi9Eu3rcccc1WB0UV5p4b7KCFbHd+3r3S/HyUiwhIASEgBAQAkJACPQMAtbUp2cq1KWKoD0/4YQTIsc6TJYPOOCA6FytLhWn7rVM3IcPHx4dcYBXVSbDLuFMBW0XgpgoOwSSflvs86PdcFg5JqmHH354U4+X2ZUy25zcOkujlS22yk0ICAEhIASEgBCoGAJLLrlkrcScrSRKjwB7v/B8yj4oNESHHHKIGTNmTOJ9X+lL0JjyBz/4geHoBWj66aePzgdzYyFkLbLIIpHToF//+tfuT7rvAAH473q35dtCGG9GxGXfIGc64igIIQttbxXICleuNov7qRdYYIHDqlABlVEICAEhIASEgBAQAlkigCtzTMU4T8meZYbjGPaEcN7Zp59+muXr+iYvXHDjyZSJ9uDBgyMvhHfeeWdX8IS3rpdRNCU4wnH/cAaCV1aEALRdIScefcO8DCqKwxF4j4DL1RLnBz777LOGfbjsD3RppplmigRyvGDiSOWYY46pnCaL+liBy9ZNGi2LhK5CQAgIASEgBIRA3yDAxJpjEJjgucQk8eCDD44m27iTf+edd9yfdR8TAYSWX/3qV2aTTTaJTPZiJss8Gh4Q4xLCYL95YY2LTZJ4nE/2ox/9qCEJjlL4w0nKb3/727rfEVBY7MDdvj3PsC5CBR5cbRbFpU5fmnIaeL2RagUqoiIKASEgBISAEBACQkAICAEhIAS6jYAvYLnPcobRbe7o/UJACAgBISAEhIAQEAJCQAj0FAIIXBK0eoqlqowQEAJCQAgIASEgBISAEBACRSFg92UhWEH2masEraK4oPcIASEgBISAEBACQkAICAEh0JMIIFhZYYurNFo9yWZVSggIASEgBISAEBACQkAICIGiEbDCltVqSaNVNAf0PiEgBISAEBACQkAICAEhIAR6AgGrxbKVsUIWVwlaFhVdhYAQEAJCQAgIASEgBISAEBACCRCwgpVNYgUvmQ5aRHQVAkJACAgBISAEhIAQEAJCQAh0iACCF0KWNFodAqnkQkAICAEhIASEgBAQAkJACAgBV5NlhS2ZDqpdCAEhIASEgBAQAkJACAgBISAEOkDAmhC6VwlaHQCqpEJACAgBISAEhIAQEAJCQAgIARcBq92SoOWionshIASEgBAQAkJACAgBISAEhECHCMgZRocAKrkQEAJCQAgIASEgBISAEBAC/YuA1V7ZK0hY80FptPq3XajmQkAICAEhIASEgBAQAkJACHSAgBWq7JWsELp4nqaDfJVUCAgBISAEhIAQEAJCQAgIASEgBKYgYLVaCFncS9BSsxACQkAICAEhIASEgBAQAkJACHSIgKvV4l6mgx0CquRCQAgIASEgBISAEBACQkAI9CcCaK6sJssiYJ+l0bKI6CoEhIAQEAJCQAgIASEgBISAEEiAgKvFsslsmAQti4iuQqDiCMw000xmmmnif9L//Oc/zb/+9a+K17rcxR85cqTZaqutzG677Wbee++9chdWpesaAl/5ylfMySefbO69915z7rnn6rvsGif04hACM8wwg1lmmWXMXHPNZb761a+aOeecM4r24osvmhdeeME8//zz5pVXXjH//ve/Q8kVJgT6EgE0Wghb8WdlfQmTKi0EqoPA2LFjo4EwSYkRtBAA/va3v5kJEyaYRx99VINlEgCbxJ122mnNjjvuaIYPHx5NRD755JMmMf8b/OUvf9lMP/30LeP4P9KJv//++36wntsgUEasP/vss2iiuvbaa5uBAweao48+Wrz9Hx/LyK82Taxnfl522WXNGmusYVZaaSUz3XTTNdSLcEtvvfWWOeecc8x9991ng3QVAn2JgBWwELKi+2HDhv2nL5FQpYVAjyEw//zzGyYls88+u1lzzTXN0KFDE9cQoeumm24y48aNa7A3TpxZnyZgxXfvvfc2Cy+8sHnppZfMYYcd1labte2225p11103EWJMbHbaaadEaRTZmLJizUR2jz32iL5btANHHnmkef311/ueZWXlVy8zhj5s5513jrRYtp6ff/65efbZZ6OFI9on48ziiy9uFl100dp5QcR9+OGHzfHHH28+/vhjm1RXIdDXCHxJglZf81+V71EE0I5ccMEFdbVj1XyXXXaJJv2YGWIGsvLKK5u11lrL8OzSAw88YE488USZMLmgxLgfPHiw2WuvvQymYC+//LI59NBD2wpZZEv8WWaZJZq8wA/44hMrY3fccYe55557DEIW2qx33nnHj6bnNgiUGeupp57a7Lfffma55ZYz7777biRsYZbVz1RmfvUiX0aMGGG23nrrOg37Y489Zs4+++xo4civ82qrrRaNK7RdSw8++KA59thjtVhnAdG17xCwWi0qLkGr79ivCvcDAksuuaQ54ogj6qr65JNPmoMOOqgujIcFF1zQHH744Q3C1nPPPRdpY/7xj380pFFAIwJf+9rXIpMvtIpvvvmm2X///aPJcmPM1iHss7vkkksaIl144YXmqquuaghXQHoEyog1iyRjxoyJvsu33347Etw/+uij9JXsoZRl5FcPwWs23XRTs+WWW9aqxGTxzDPPNDfffHMtLHSz6qqrmt13373upyuuuCLYj9VF0oMQ6BEEXMHKrRLhcu/uIqJ7IdAjCCy11FINNWEfVojYzMyeEN8xxqBBg8wGG2wQSqIwDwE0gvvuu29kuslP7FVAI5GG5p133oZk8OaGG25oCFdAZwiUEWuc1NB+IMyzMJ0T/ReBMvKrV3jjC1nUi8WddkIW8e666y7z2muvcVuj9ddfv2HxrvajboRAjyFgPQyGqiVBK4SKwoRAxRH4+te/3lCDZoIWEdF2XXrppQ1pELR8s8KGSAowo0ePNnPPPXeEBA5F7r///tSooI306YknnmgQhP04ek6OQFmx/stf/mImTpwYVQjTLNfpQPJa9k6KsvKr6ghjquxqsqjPLbfcYq6++upYVWPV3hfI0OzjSEMkBPoRAb4JCAFMglY/tgDVuacRwFben5Dw0bcStACEVUnbOViAcOvLyqSoOQJ4icO7IMSGcfYydEIhbSQTb1H2CJQZa7QJ1l02HizZq9TvVGZ+VZU3s802m9l+++3rio+5+EUXXVQX1u4BRxk+TfEB4AfpWQj0BQJWw8WcSoJWX7BclewnBDD5812FT5o0qa0XKBwrhISxkHasl/BEMOWMmPXWWy9YLeqPZg/NAm7bfRo1alTN6xYet3CC0QktvfTSDckff/zxhjAFdI5AmbHmjCKcCkAzzzyzwfV7v1OZ+VVV3uC5dMCAAXXFv/LKK80HH3xQF9bugf2EPlktvx+uZyHQDwggZCFw6RytfuC26lgKBJjQs8dggQUWMDhO4IonwFNOOaWhfHycQ4YMqU3g8TL397//vSFeKCC06hsSoEJpmdj56fFO2EsEtvAB18QIWOCMeSSutK+77rq6qi6xxBKRoxAbiBB73nnn2cfIU+A3vvGN2nOnAhHlYoXZJdwkx+W9m073rRGoAtZ8t/aYhtVXX90wAe5XqgK/qsYb+rcVVlihrtjsEbz++uvrwuI8hJwmzTrrrNH5W+3OEYyTv+IIgbIjYAUryuneS9AqO+dUvp5AANMf7NVdF7hUbPLkycH6MaHHuYIlBIC4k+3Qqu9f//pXm1XLa8hd+JxzzhmVG7O4XiDc1s8333wNVcGFsU8rrrhiXRCCmUvf/OY3a8Iw4Z0KWr6QS55MtnsFe+pTFqoC1uydtESbxSSY/Xr9SFXgV9X4stFGGzUUmf2lvmOkhkiBAH9sIwr5WBOqQBIFCYGeRcBt9xK0epbNqliZEBg/fnzkcAJhy50wNNt7wzk6LsUVlPi4/f1Z5BNXo8WBxT5NNdVUhgMsX331Vf+nSj7jOh2N4ve+9z2Du2hLjzzyiL2tXeEPkxHbac4zzzy137hB0LKEC25c4ndCbtuw+XQqvNl8dK1HoApYs7jy6aef1kxW0Wp1Imgtv/zy0WHm9Uhk93TuuedGZ7xll+MXOVWBX1+Utvx3aAj9hSRKfeedd6YqPOatPnEIN1YbIiHQDwjYeYKrzeL+i1lGP6CgOgqBLiGAoMMfNuvuhCGkRaGITIgs8aHGFbQGTnHMMOOMM9qk0fWll16KDretC2zykGYls0lWpQ2+9957DX8cDDzHHHNE5QTjEC8Qvk477TTDPgZWbF3BjP1arvYQ7ST5dEJufjafZsK4/V3XdAhUAWsmqRxYvOiii0aV9M28ktachYI8HRRcdtlluQlaVeBXUn50Mz4mqXZiaMuBUJ+2v8EU3if2eUkb76Oi515HwP+u5Ayj1zmu+pUKAXeywKQ8pK1gpRHbeUtMtOJuTHaFOJs+rjaL+JzbE6KQSWEoXlXCwNgKWZQZj1kffvhhsPi33367+eMf/xj95mr82H/gmsuE9igEM2wSiBDuloloWWjJmryur4OrhLV7WDFtLuSQJS4zO10IaPeevPKvEr/aYVSW3929pbZM9INpNVBYCfjEwe0iIdBPCPh9IEKXNFr91AJU164iwLkiiy22WK0MzQQovIu5KyJJVhhDglZcbRgF803jCMMZQ69punzTzJDZIHW3BA840NM9hDjktMLGT3MN8Q4h2e+40+Rt07Dfjkkrh4v28ySoCKwt5nxT8NA/0NX+3u7K92eJfgEevvLKKzYo0RVnNyETr0SZNImMK/pme06bJIkdXCV+xa5UFyMirIe8yT711FOpS+XvXyWj0EJi6hcooRAoMQL08fTPdu5mnymyBK0SM05F6y0E0FK5pmchAQoNiT2TydY+7mDFBx4aPJNotEKCVlp35TvvvHPQ6YStV9rrhAkTzI033pg2eZTOX83lkOFWxF4DyJ3g+oJWpxotV9tpyxKX9zZ+6EqbQkjkPDTXrBR3zHfffbe54IILauc1hdLHDSszv/065IW1+x60pptvvrlZZZVVzLXXXlvnrdKN1+4eL3AusV/SbYfub+3u33jjDYN5X9WoSvwKYVu2bwPNeUgz+sILL4SK3zaMtr7IIos0xOO4C5EQ6GcEELgkaPVzC1DdC0Vg8ODBde8LCVorrbRS5DLcRmSVOK5GCht5/1BTXJbjGj4uLbjggg1R//znPzeExQkYOGW/2MILLxwnaqI4nay68iKEXZcXTGRd726hwuAKHnIFsllmmaUuqj8hrvsxxkNo1T7URmJkVYuCI5NDDz00KIBjJsr5YEzcTzrppMjpQi1hipuy8jtUlTywtu9hseL73/+++fa3v23Av1Py2xX86jeqEr9CvCnbt4EJaogYL9IQbd0nTF6TLPL56fUsBKqEgK/Jss9cJWhViZMqa6URcCf3IQGKD3LDDTesqyNex+JqSkKrvnGFNF6KUGQ33buFSCtouXlkeQ92nRBeGTHjtIQw02rDNnyx3gVdQYuN4y652ko3PM49k2d/As2eMcxLOyHaE1pOynrHHXcYNBqYDq666qrR+TbkTd1wDHLDDTd08qrc0nbKb79geWHNe8D2hBNOiHAGc7ed+eWI++zX390XGDePKserGr+KxNpvG3Hf7S8S2XRZClr0J34fad+jqxDoVQSYL1izQa6QBK1e5bbqVSoEZphhhjrtDpuO3b0XFHbllVduEHSSaDRCq75JVhRDZ6pguvbiiy+mwpLDVfPYD+IKO2kK5psNttufRXy0hU8//XTdviaEFpfgcVoK8Q4h2XbUafJlQr7xxhtH++sOPvjgOtfz8OaII44wdmWb/RWdClpl5bePXR5Y23ewD+unP/2pwSxzyy23jEw27W9pr9NPP31dUnefYN0PPfpQNX6F2FC2b6NZv9LMIVCoTjaMxTnf5Jw9vZjLioRAPyLgC1sStPqxFajOhSOAVsFdifYFKCZTo0aNaihXkj06zSYkDZkGAuaaa64Gt88Mxueff34gdrwgXKiXkZIKWt/97nejalxzzTV11clS0AppI/02UvfyJg+YqsE3/tDczTTTTObss8+uE7JIyploF110USQU8BxqO4QnobLy269DHli770DIgrISiHwBvpN82f+52WabucXN9H7MmDGp9481K0jV+BWqR9m+jWaOcNJ4HFx33XUbqkxfGddTbkNiBQiBCiLAmIuAZcnec5WgZVHRVQjkiIA/WfAn0VtvvXWD6RjmbHE1UvPPP3/d3i6qgkv2uIcMb7LJJg37SW655RaD6WIvERq2gVP2jllCWGrlWIBzi5ZddtnIFOy+++6zyaIrkxW3c3UdTdRFjPEQEnT8NtIuG/ZccebXqaeeanAYQpugjDfffHMwqWtWageFYMQeC8wD6zwh8gWtTo5aoI1i3pgXdWI+26xMVeNXs3qUKbyZB0wW3Fr1h34d0ISvttpqdcFYa4wbN64uTA9CoNcR8MdQOzfg2vlO3V5HT/UTAhkg4E4WWDV84oknarmuvvrqZsSIEdGZSbXAKTeYqsV1q+7mb/OIK6TxflzKu8Qk/He/+50b1BP3OPtwO8RWZog4FsFbGIRmz9/HxbPVXhAnrZkkHsD8ye/7779vOGg6CWEmiEbLHrx80003ReVvtk/CDU+7NyNJ+coQNy+s86ybK2h98skn0QJK2vel0VgkeVfW+VeRX0nw6lZcHFWErCVCZ2E1KyNC+4477lj3M+MVjnX8vrIukh6EQB8gwDzDClvSaPUBw1XF7iOAdsESK35MmCD2ZTGZZ7/W9ddfH3krs/EYCHErvs8++xi0Kc00E8RPK2jhFMEfLHHxO3bs2NQHV9ryl/Hq7yVo5myClflddtkl2sM0ceJE08z0Bx7ZFV14jKmee8BsHAx8bSdpku7PwpHJOuusE3lPdA9VbvX++eabr/bzAw88ULvv5ZtuYZ0WUwZrt+9gYaATYQZ3/nHbR9IyM7lOog2Jk3/V+BWnTmWJw55MH18W/O6///62RUTIOuigg+oWiBCyjjnmmMzbQNvCKIIQKBECVrhyrxK0SsQgFaU3EUAz4q5Kc88ZJgxqmAzyQR5//PEG1+4usRfj5z//ueFwXTzGNSP2foUOi2xlYoT2Zauttoq8zbn5jh8/3px55pmxNWlu2irc+1ondxJry49Hrr333jva4wSG4NGMMK+0ghaTYvbiJRVaQkJyErNBPNvttNNOkTbLN29sVm7COd8JQrNFPfqBuoV1WmzRwA4YMKCWPM4kuBY5cMMiQKd5BLLNLahq/MoNiBwypq946KGHzPLLL1/LnbGG/oxxoBlhXrjnnnvWOW5iofCoo46qs9Roll7hQqCXEbAWM+5VglYvc1x1KwUC/lk6TJ4uvvjiWtnOOussw8GO/qbi7bbbLorDJJg9N81o5MiRDfuziPvDH/4wEvAmT55s8CaFkMEgOWTIkEioc/dTcNbWpZdeam6//fZmr+mJcP8MrmHDhpmrrroq2oMFHgi7CL+YLDEpxTNfq3PI0DyBr9UOJRW06Ix95xwA7e6fagX8nHPOafbdd18z8H/7zuIKWuznsmffcIBtqzq2en+VfusW1p1g5AoauPJOKsR38u5up60iv7qNWZL3s8CHmR8Cku2/SL/rrruaQYMGReOBa7pOn8hxEd/5zneiswjtu5555plob2ha77Q2H12FQK8hYLVaErR6jbOqT+kQwFSHPTAIOT6dd955hr00kDuo2XisOCKIucSgyASbgQ/BAMEpRJjJ4Wq6Fb388ssGD1EIWJ2YJLV6R5l+Y98a55JZxxVor04++eRorxX39twj4p1yyimRANau/Lfeemsk1BIPxxlJCK0mvPRpscUWiwQ9lydMPNGGouGgLcH7FVdcsVZmHJf4nhD9fO3ztttua/B0iebsT3/6kw3u6Wu3sO4EVFfQwuyvnzy5VZFfnfC6G2lZTNp///3N9ttvH52tRxnoZzjInIU/xgfGpXnnnbdOs0o8tFgszmHyzoRSJASEQCMCfBsStBpxUYgQyByB2267zWyxxRa1fPEGh5Dl7v1h0vutb30risN+h+uuuy5ywe1vLN5mm20M3vCSEAMqDhb4YzLOu3Ca0C9OECxWYImWaocddohWbQlHk2WFYJyU3Hjjjeauu+6KPXlASMVlNkIamqWhQ4eaZoc8IyRzACtCMvGaCcnWCYctd5xrXG3WeuutFx1SzCTqV7/6Vc9uXC8D1nH41iwOk1sEaQiB+5JLLmkWtSfCq86vqjKBhSc0W/Rja665ZtQvYdqOSTrWFy6hVWWfIKbs9HGhxUE3vu6FQL8gYLVX9kq9WbSQoNUvLUD17DoCl19+eWT2w2QC4WbSpEkNGiQ0W5hhYNaFRgXhKERHH310KFhhMREA4/322y9yMoA2CS0RpnNs5EcQTUpoLPHQiPMMCJNNHGj4AjK/pRGSSReH4ghaCHajR4+O6suZR83aWJz3lT1Ot7HuFB/4ZM17WXTp9UWRqvOrU353Oz0Ht/NHf4iQT9/IgeYI+SwM8kc/KeGq25zS+8uIAEIVZK/cW6FLGi3QEAmBAhBAuOKvFWH+1WtnV7Wqb7d+Y2WWPQVZ7StAY8leKxxMIEzjLh/NmE/dFJI5wJhN7OzXQ6sX18zQr0NVnruJdacYobG2WmuOeeh1bRZ4VZlfnfK7TOkxCdQ4VCaOqCxVQwABC7IaLZ2jVTUOqrxCQAiUEoEzzjijpnXATNSaI5ahsLh/P+CAAwwC5pFHHhntvfDLhUmhbyrkx9Fz/gjgpZQ9dBAa1uOOO65B+51/KfQGISAEhIAQSIMAApbVbHGVoJUGRaURAkJACHgIsBJ8wgknRJvEmSwj2HCuVrcJF/acecOeC7QGIY0pezN+/OMfB71Xdrv8VX2/HWiTlJ99frQbDrDGJPXwww/vC4+QSTDKK24afuVVFuUrBIRAtRBAi2U1Wbbk9lmmgxYRXYWAEBACHSLA/i+8eHHINALOIYccYtgLlWbvV4dFiZKjVaMMCH5os3DPzJ8ljh5Ai8V+DPYAJTm/y+ahaxgBTDUtzTbbbPa26RVvkuwdXHTRRSOzToSsV199tWl8/ZAtAkn5le3blZsQEAJVRiC0UGPDpl5ggQUOq3LlVHYhIASEQJkQwAU3XrkQtAYPHhx58brzzjujg4GLLCeT+1/+8peRl0PeS6fP/jH3j03v1tX91VdfHTlhKbKMvfgujglgf9VGG21Uc2YBzuy1Yn8cB0T7hOYTgXzQlPOLcKRyzDHHSJPlg5TTcxp+5VQUZSsEhEAPIYBGi3FXGq0eYqqqIgSEQDkQwIwQ1+mbbLKJGT58eFcKhft4TNDiENouHHqIOkMA80xcZfsmo7jLPvjggyNPlLjuf+edd+peFA3GU44Z4Mw8e65eXQQ95IJAWn7lUhhlKgSEQE8gYAUs+vXoftiwYTppridYq0oIASEgBISAEBACQkAICAEhUBYE5AyjLJxQOYSAEBACQkAICAEhIASEgBCoNALWEQaVkKBVaVaq8EJACAgBISAEhIAQEAJCQAh0CwFXsKIMmA1ChEvQiqDQPyEgBISAEBACQkAICAEhIASEQDIErGAVSiVBK4SKwoSAEBACQkAICAEhIASEgBAQAgkRsBouBDAJWgnBU3QhIASEgBAQAkJACAgBISAEhEAIAavhkulgCB2FCQEhIASEgBAQAkJACAgBISAEUiKAkCWNVkrwlEwICAEhIASEgBAQAkJACAgBIQAC1lzQ3lutlkwH1T6EgBAQAkJACAgBISAEhIAQEAIZIGCFLLKSoJUBoMpCCAgBISAEhIAQEAJCQAgIgf5EwApXvmZLglZ/tgfVWggIASEgBISAEBACQkAICIEMEbACl81SgpZFQlchIASEgBAQAkJACAgBISAEhEAKBFxtFskRuiRopQBSSYSAEBACQkAICAEhIASEgBAQAlbAstos+wwyErRSto+ZZpopZUolEwJCQAhki8Css86abYYlzq3MfW8/8aHETSRYtDK3m2CBFSgEYiKgficmUF2IhsAlQSsF8AsttJA58cQTzXLLLZcitZIIASEgBLJDYIYZZjCnn366WX755bPLtKQ5lbnv7Sc+lLR5NC1WmdtN00LrByEQAwH1OzFAKiCKr8myzzIdTAH+UkstZQ4//HDDCsKMM86YIgclEQJCQAhkhwAd+TTTTGP23ntvs/TSS2eXcclyKnvf2y98KFmzaFucsrebthVQBCHQAgH1Oy3A6cJP8MOaDXKVRishE1ZccUVz0EEHRQLWG2+8YR5//PGEOSi6EBACQiBbBP75z3+aSZMmmemmm87st99+ZvHFF8/2BSXIrQp9bz/woQRNIVERqtBuElVIkYWAh4D6HQ+QEjxaYYsrNPUCCyxwWHSnfy0RWGKJJcz+++9vpp12WvPxxx+bX/7yl+b1119vmUY/CgEhIATyRoAVs8cee8ysvvrqBjOSYcOGmUceecS8++67eb+6kPyr0vf2Oh8KYXaGL6lKu8mwysqqDxFQv1MOpsMHK1hRInvPVYJWDB7NM8885tBDD40mMf/+97/N//3f/5mnnnoqRkpFEQJCQAjkj8CHH35oJk+ebFZZZZVIszVkyBBz5513mn/961/5vzzHN1St7+1VPuTI4lyyrlq7yQUEZdo3CKjf6T6rrWBlS2IFL64StCwqTa5f+cpXzGGHHWbmmGOOKMall15qbrvttiaxkwfjCYm9XtNPP32sP97w+eefJ3+RUjQgMHLkSHPIIYeYW2+9teWE9Mtf/rIZMGBALP5YPpKm6pPcBsAKCCgj1vQBZ5xxhmHy9pe//KW039/LL78c9SWYDqLZGjRokBk/fnwBXMvnFXn3vfmU2phe40NeOOWVb1HtRuNHXhzMPl/6wxVWWCFyGMRi1IgRI6JFqQUXXNDMPPPMhgX0jz76qLa3xi9BFcYA9Ts+17r7jOBlha1puluUcr8doPbYYw8z77zzRgV95plnzB//+MdMCz127Fgz11xzJcqTCfx7771n/va3v5kJEyaYRx99NOooEmXSx5Ex/9xxxx3N8OHDzQsvvGA++eSTlmiMGjXKrLvuui3j+D++9dZbZqeddvKD9dwGgTJi/dlnn5lXXnnFrL322mbgwIHm6KOPNu+//36bmnTn54svvjiaUMw333xmmWWWMVtssYVhcahqVETfmycmvcKHPDHKI+8i2o3Gjzw4l0+eyy67rFljjTXMSiutFGn6/bcQbokx+5xzzjH33XefDapdqzIGqN+psaxrN1a4qrtOsef/T9dKVPIXr7/++mb06NFRKT/99FOzzz77RKuVWRZ7/vnnN6zizz777GbNNdc0Q4cOTZw9QtdNN91kxo0b13RFJnGmPZrgq1/9auSdbeGFFzYvvfRSpK0Ev1bEatYss8wS8WittdYyK6+8ckN0Pqo77rjD3HPPPYYOm4n4O++80xBPAa0RKCvWOJpg0YXvE6HryCOPLO0ezSWXXDLyjGpX1I455hgzceLE1sCX7Nci+t68q9wLfMgbo6zzz7vdaPzImmP55Aefdt5552ixyb4BS6Bnn302WlylD2fOhfZ/0UUXre2nIe7DDz9sjj/++Ggvvk3LtSpjgPodl2vluP+SBK0wI772ta+ZY489NnJ+QYwLLrjAXH311eHIGYVidsZ7XGIlZZdddok0WJgZov1ios+E3z+A8YEHHojO95LJmovgF/eDBw82e+21l2Eyj5qdfXfthKwvUv/3Djfal1xyiR9sLrzwQnPVVVc1hCsgPQJlw3rqqaeOvPpxfh6OJhC2nn/++fQVzDHldtttZzBtgjCJwfX7m2++meMbs8u6G31vdqWvz6nKfKivSfmf8m43Gj/K3wYoIWaBW2+9dWTqb0uMs6Czzz47Wly1Yfa62mqrRXMs+ndLDz74YDT/YwHVpaqMAep3XK51795qtXRgcYAHTPB+9rOf1YQsJuXXXHNNIGa2QZgl+cQKDJoRbIg/+OCDaEUGYYy9RUygXMKV7RFHHKHzvVxQ/nfPIIzra4QsJpyHTdl3l1TIIitrRuq+AsH2hhtucIN0nwECZcOaFdHjjjsuWhHlHL0DDjigYbEjg2pnksVFF10UaVbJjAUZBt4qULf63rywqSof8sIjr3zzbjcaP/LiXLb5brrppmaHHXaoCVlMdNlfy9mnWLCEiH2sp556at1POBPacsst68J4qMoYoH6ngXVdC6ANStAKwL/hhhtGezHsT2gwEHTyJg5W9Il9WCFibxF7RXztFRvgN9hgg1CSvg1jornvvvtGJpqAgB12WtfXqOV9euKJJxr44MfRc3IEyog1Z5bQfiBMT7bddtvkFSsgBeV092axCJPGLLmAota9olt9b10hMnyoKh8yhKCQrPJsNxo/CmFhxy9ByPKFIyxNbr755rZ533XXXea1116ri4cZqm81RIQqjAHqd+pYWciD1X7aKy/FfB+SoBXB8MW/2WabzWyyySa1ABxghDZH1iJkePP1r3+9IbdmghYRn3zyybrJlE2MoBXqIOzv/XZln93cc88dVRvHIffff39qCELCMJ7oRNkjUFas4bfd84TZibuhOnsU0ufInkEWZCwhFLIftKzUzb43T0yqxoc8scgj77zbjcaPPLiWbZ5sp/CFrFtuuSX2dg8mx75ARl+JI40QVWEMUL8T4lx+YVaoslfeRLviWYKWhzsfK3ulLKGCLYKw/fVX8GFSK0GLcrES40rQhOHKlNUYkYk0k3gXhFD7Y6fdCS299NINyR9//PGGMAV0jkCZsWal1Gq58WCJSWrZiH4BL1SW5pxzTrP55pvbx9Jdu9X35g1E1fiQNx5Z559nuxk4xZxf40fWHMs2PwTt7bffvi7Tf/zjHybp3I1tGj5x+HszKvsYoH6nGefyDwd7/hCyuErQcjCnU3VXMNB+FKWtwOTPFfAo1qRJkxo83zjFjW7ZvxUSxkLaMT9tPzzjLtyuMOBNiP12aYk9Q3TqLn388cfm73//uxuk+wwQKDvWL774omHDNMQ5LLh+LyNRRrd/YAGG/SZlo272vUVgURU+FIFFlu/Iu91o/MiSW/nkxTEqnHPp0pVXXhntaXfD2t2//fbbDVGsJUzDD1MCqjAGqN8JcS7/MOacdt7JVYKWg/mPfvSjGjgEX3vttc6v+d6GzKTcCVKrt9sJnxsn6dlcbtpeuccl+ze+8Y1adTrVPDXjEZoyUbYIVAFr9/tcffXVswUgw9wuu+yyWm5ozn0Tm9qPXbzpZt9bVLWrwIeisMjqPXm2G40fWXEpv3yWWGKJ6NxA9w3sT7r++uvdoFj3aMF8wukRbt2bURXGAPU7zbiXbbjVYrm5EgZJ0PofKpyrxOF2ll5//XXz0EMP2cfcryEzqb/+9a+x3hs6rwkzIdddaayMeizSN7/5zTrBOQ9Bq9M8ewzyzKoTErTKhjV7JC1xQLBv+mt/6/YVrby7VwunGGXSanW77y2KP2XnQ1E4ZPWevNuNxo+sOJVfPhtttFFD5uzB9p2ENUQKBITmS+RjNROBJNE+eRte1jFA/Y7lUL5XV4tl32TbjgSt/yHy3e9+12ITXTkA2EqjdT/k8AAzQpM0d7Wk1WtDbsqnmmoqw6F9/UwMlJZwhf/cc8/Zx1TXkDBclGlpqgJXOFEVsMZklIPMLZVZq+UeP0B/4zr8seXv1jXvvpcJ1AILLGDYb7HZZpuZPffc0+y2227B6oKN9dCIQMpkPksqMx+yrGcReeXdbjR+FMHF9O/AvJxv1ac777zTD4r1jAm4T2izOMu0GVVlDFC/04yD+YZbGUKC1hSc0f5861vfqiHO5OnWW2+tPed9M3DK3rAZZ5yx7jWc+fD+++/XhTV7SLN60yyvXgmfdtpcTjt9AAA4i0lEQVRpjTtZnzx5ckeCM7bac8wxRx08WQhvdRnqIUKgKlgzALsHFq+wwgql5SBnxbjn7q2yyio1T5zdLHTefS+OStgUf8IJJ5if//znkTMQPJQtuuiiwWqzV5ajIH7xi19Ef9YRQjByisCy8iFFVbqaJO92o/Gjq+yN9XIWQqzGwCZg7pZ28ZPFGJ84u7TV1oCqjAHqd3zO5vtsBSzaJ/cStKbgzQZxV218zz33JN5I2QnbQmZScbVZvJfzfEIUMikMxevFMGyrXZ6G7K+T1LsZj+wHlSSvdnHnmWeeUkyC25Uzr9+LwJqJGoI4107IFV5oc0zQykgsxriLR2i8N954464XNe++lwnGb37zG+ObYTebjC233HJ1mPjp6n5M8VBWPqSoSleT5N1uqjx+cHgzzrB8IaSrDMvh5e7+a5s9ngNbaaBsvNA1ZE795ptvhqLWhVVhDFC/U8ey3B/cb4/7vhe0OCthrbXWqgOe8weKpNDEMskAz8TcJ7zh9bOmK+Qd0McoybOrHbPpst4zhCnE7rvvbk4++WQzcuRI+5q+u+aFNYI37s3PO+88c/rpp5vDDjssup5xxhlmm222MQgfSYnvzBIdaqeCm80rjyvm0C5h6uh/J+7ved8X0feyYHX77bc3CFqPPfZYsHrLL798LZxFlCT9cC1hm5uy8aFNcUv3cxHtxv8u3O88DSB59WluWejfmMswfhx++OENXozduFW/Z0Er5Fn5qaeeSl21ZZZZpiFtnDHebRtlHgPU7zSwN9cAdxF+mlzfVIHMUT9z7pQlNB9xPi4bv9MrH2aow0ii0QoJWp24Me+0TmVI7w+UeWi0mq2KJ60//Pv+979vvv3tb6ea7Md5384772zYrJs1TZgwwdx4442ZZhtaeOgUa4SoQw89NPitoRHmkG/2NJ500kl1+67aVQwPVy6RxyuvvOIGleb+1VdfjfYpYh4HsfJNm7v66qu7UsYi+153ossAGOrjWejAi5klzEIxHcqaysaHrOuXd35FtJsqjR/0bRyczhjSyh15J3wp2/iBGX/IesB1+pOkvnz7iyyySEMSjoRpR1UZA9TvtONkZ78zrjCft2TvCe97QYuJhksTJ05saZPrxs3iHrtg/7BTPB6+9dZbsbNfcMEFG+L++c9/bgjrpwBc87rkd4bub+3umTz7jkU+/PDDuv057fJo9jsDI/tH3njjjWiCz2ptHjRwyj7ArDf2U85OVhBD9cwL6w033DASsrDhR2MN3mC/6qqr1tz3svmdFWF343CojG6Y3678duLGLcP9fffdZ6ygRXm6KWgV1ffyTS222GI1+JsJUJyFZgdHIncq3NdeGLgpEx8CxSt1UBHtpirjB4zaYYcdon4syZwhKYPLNn5g2hki5k5pyG9T5IFJYJwF7yqNAep30rSOeGncscNPkdxWxs+hws8IOL6db9ECirvSaqFMYq7C5Dm0sbvoetiyl+XqeoOjTKzep6WQhgUeuarhtHm/9tpr5qc//an52c9+Zq655pq02XQt3b///e9M350H1pjUsB8JU9oDDzzQYCp4xRVXRGaDOEh49913a3UImY/Ufgzc+PV39wUGonc9iIHWJSZQob0Jbpw87ovse9FSud9/SICCb77ji5DWKyssysKHrOpTVD5FtZuqjB/gjin0T37yE7P33nsXukicBc/9/jNunr4gbNNlKWix4Oa3A/se9+rXocxjgPodl3P53tv5IQJY+tlnvmUsJHe8T7kfBZsoizw7i0qGJpZxVlEsQKFzJJggcGp5PxMaC5dc81A3PM59SBgOTdba5YWJBx+f/QBtfHsivTvht79ldb3yyitNyH1tp/k/+uijnWZRlz4PrDk6YaaZZjJnn312g4t/zCnwSoewC4W+x7oCeg/TTz99XUiePKx7UcoHvJnigdM1I2U19+KLL06ZY7pkRfa9gwcPritk6NtdaaWVjDt5Y/KUZMGr7gUxHsrChxhFLVWUotpNlcYPd48QJvK+hUwWDCzb+OGPobaOWJokJRaq/e0XLMpde+21sbKq0higficWSzOJZDVctNW+FrRwcewSA7Dbabm/5XUfmtjFHeDnmmuu6GwYt2ww9fzzz3eD+vI+y4EyxKPQZK0V0OwDOu2008ypp55q2NdUNN17771FvzLV+/LAev755zd4j7r55puDZXK/N9s5BiMGAn0BvuyCFlXgQE/X4yDmk5dccknDAkCgupkFFdn3uoJWSICC55iWusT5OJ3u63TzC92XgQ+hcpU5rKh2o/GjvhWUbfxo5g0wjcfBddddt76yU56wLom7P7NqY4D6nQZ25xbAfLyvNVp8HIsvvngdwHE2PtYl6PCBCaC7ikp2uGRnlT0Oceio7yntlltuMUwSXGKPAuYzaAuo81133VU36QQL8iIOncuvf/3rwgVOt7xZ3NMR20ZOfv45ZXHfwaZbf4Mx55uxMpSEmNjCq2bezpLk1atx88Iab0u+xyUXQ9c8JKnpiT/Iho5UKNv3h1mxK2ixrwytXxJNuotf0vsi+17e5e5NxP2zv5gWOlcr6UJKUgyI320+pClzN9MU2W40fnST0+3fjcl9iFh8TuKMCFNxHIm4RB8xbtw4N6jlfdXGAPU7LdnZ0Y/unNO971uNFkKHazYIuk8//XRHICdNHFq9jzvZWX2Ka2Y2b7vEyvzvfvc7Nyhy4nDKKafU1dWu8LLCDwYHHHBANNGyCbHjTXu6us2j21cOGcQkzx4ynNZsLmTKBs58RHGJid4666xjnnzySfPee+/FTdZ38bqFtWtG98ADDyTC3R1kP/nkk2ihxM0AIaZs3x8LMQiXrteuIUOGFCZoFdn34tHV7ed9AQqzn1GjRrksi+7z3J9lX9ZtPthyVOVaZLvR+FHuVoGjCr5Rf8xgv2lcQYvFVw40dwmTQTzPtjqk2I3PfdXGAPU7PgfzeXatY/rWGYbvBIMP67nnnssH8Sa5phW0MPXxOwjcmo4dO7bhsD6EjUMOOcTsu+++kSbLFuUHP/iBYaX9xz/+cSRksZJPB4Ww6U9GbJqqXd3JEtpD9ukkpRCPkuADxjvttFOkzfI3oiYtS6/H7xbW1hwJ4QONcFyiI6VdWWK/mm+6UsbvjzL6Wu8Q9rZeWV+L7Hv9iZj/7W699dYNHkUZC+IueHWCTbf50EnZu5G2yHZD/TR+dIPL8d8Z8g47YsSIWBkgZB100EF11ioIWcccc0xsQY0XVXEMUL8Tq4mkimSFK3chnvu+1Wj53sUmTZoUy8NMKvQDiVhl9ctAtJDpkU2OVmarrbZqOGB5/Pjx5swzzwweUMykwbrgZmWdsyLY+EleuIVFbY7J5FFHHZVIS2PLVOYrk2ZrFsAHwOp2Eo0FafzBnfq6e3pa1Z/DaxFwB07x7AZJ0IpgCP7rFtbsnbOufS+77LLExyoMGDCgVh9s330q6/fHgop7ZhRaV7Q7vqtivz5ZPPv9Xp59rytAMsF44oknalXAKoCJGavj7iIM2DDpKoK6yYci6pflO4psN5Rb40eW3Ms+L8ZTnJe5h4wvt9xy0ZjPnKgZYV6455571nlrxpyYOZDbPzRL74ZztE4VxwD1Oy4Xs7+3ApfNuS8FLczJ3JVowKDhFUkjR45s2J/F+3/4wx9Gqmg8g+FBB4GIjgHTHjxjuW6KOTfj0ksvNbfffnusojPp+/3vf2923333KD5CCB3M6aef3nNCFhVEIHI9rCUVtJiEISz5xJk8TM6YuFniw8KEgE4XfsGrFVdcMdIaEgcNgr/B2qbV1UQT3m5gve2220YCBpqOP/3pT4lY4U7icbLQTogv0/eHGSuHNFti4QfB65FHHrFBuVyL7nvdfp69F5h3QuzL4hBW+r/rr78+OuzVVhhNxnTTTWf22WefaHGkmRMVG7+Ta7f40EmZu5G26HZDHTV+dIPT8d+JpgAzPwQk1/x71113jc4KZG7kLpjQhnB6853vfKduHvXMM89EjqrSeGqu6higfid+O0sak3bpClrc96Wg5a7kWhDzFrToCJhI8rEzCUdwChHaJutqOvQ7YS+//HLkFQcBy53sN4vvhrMK5K7gXn755dFeJjdOL93feuutkfBKnZZddtmWVYNH7KmBR0OHDm3KIyZoSUnarHrEyoD1euutZzikmO/pV7/6VSK7fGrjDrJ33313LC9VZfn+Qv0d9clb0Cqy78XNtbt/gnv2pbGAgskgA+Lxxx8f9cdu68RzJOersTrO4dZ5Urf4kGed8si7yHbjll/jh4tG+e6Zy+y///5m++23jw5tpoRMbFlEwpsgfTvC1rzzzluneSIeiywIYyy00BekoaqOAep30nC7dRorYFkhyz6Tqi8FLWvK5cIWanju753eb7PNNmaFFVZIlA2dCB7u+EMbwqo7XuuSekZzX8o+FPYfoG2B0nYwbp5lvkcY3WyzzSLNEnxHgGp2mHMaHsWtuwSteqS6jTULHaNHj45MBceMGRMtPtSXsPUTA7f9hljswD16HCrL94c2nP1jmE5acicNNizra5F9r++RFTMf97yws846KzKb9t07b7fddlG1MR3L+yiGbvEha77mnV+R7cati8YPF41y3nMMA5oteLXmmmtGYzwLKmjp+eZdwvKAvbQsoDAPcDVebrw491UeA9TvxOFwNnGYY/eloLXQQgvVIYg5SVyX6nUJEzwcffTRCWLnFxVtjfU6yFswH0xqMpVf6bLPGS9/eGLcZZddoswxzZw4cWJQe1EWHmWPQvly7CbWuDLHRh/T3COOOCKVSSdCmjXjve6662IvfpTp+8Oc1RW0OLiTCQrCYF5UZN/Lt8+iFKa8Pp133nk1l/+hyRZ7PxDEiqBu8KGIemX5jiLbjVtujR8uGuW+RxvPH5prhCAsiGadddbI6gd3/fwhYIS+9zQ1q/oYoH4nDdebp/E1WfaZa196HRw0aFAdWmiLel2zYyuMAwz3JHNWCumUepluu+22msdFTNZ8t/i9XHfVrR4BnD5wnAErm0ceeWRkWlIfwxhMCv2VUDcOmmmrnUYTHlebRR5l+v58zTiCI99HnlR038u37xKTreOOOy4yvbbhridC9tGx8HTssccGF2Nsmiyv3eBDluUvIq+i241bJ40fLhrlv8ckECEC50Scn4j5J1os9mtnJWT1whigfieftoxgZeUJrvz1naDFAcGzzTZbHcL94qQAtTodBCvwV199dQ0DHHNAeO/Zcssta+G9dHPGGWfUtA5bbLFFcJW72/W1KyDdLkevvh/HCLj0xaQEjRqDsU98Ixx54B8kbuOx7wcHGhAmvUza4+6TLNv3F+r38lx06Ubfyx5UnFqccMIJ0V6O3Xbbzdx7772WndGVyRjeQRGuMBs8//zzCxOyKEDRfKirfAUeutFufFiqMH5QZo0hPueyf+6VMUD9TvZtw+ZohS37Pfad6aBvggAwvmRvwar6FbX55ptvHu0/+eCDDyIhirqyAj/33HNHHnio41prrRUdpMsG0mb7l6qOBatcTLY4U4yOEq3GgQcemHhvTp44YNJmyV8MsOG6pkMA8zHLe7RZeJ/izxL7edBiYW7CN+JqOWwczkSj3fDtYFKE2SGmKM2o7N9fqN/DGU9e1K2+F/fx/LUihO6Q4N0qTVa/Fc2HrMpdVD7dajdu/aowfrCQ5LoaZwyh3KLsEOilMUD9TnbtgpzQXFnBimd7z7XvBK2QvX5IsgeoqhMHG7sH+LHyjrDBWTnPP/98dL7W4osvHjmK4ABjzvBiNbdXCTeueChihZtBiYk3jhDQTHSTWLHFEYHriRLPlHhJxCU1TlFE6RFgwgGv7X4khCrryCKUK04QrOrf/s4EZr/99ovOXqG/OPzww9vu6yz79xcaaPPUaPVT32vbTZxr0XyIU6YyxSlLuynr+MG+ShZIfGsUFlkvuuiiaFyPq3UvE9/LVpZeGwPU72TbwqxgZXO1gldfmg6GzuoJNTgLVpWvHETMngMIhx+nnXaaYbCwRCdsO2CELPas9PqkHnevCFvYb7NfB62Ee1ipxaaoK2ZseEzaa6+9amdu8W4Gz4MPPjhy5CHtVmfcwNMkWqg4hLbL39dD++DbwMU0jlRoP3Gc55T9+wstMOWp0eqnvjdOW7NxiuaDfW9VrmVqN2UbP+AhXjNDxxSsssoq0ZiP0wZRZwj04higfqezNtEuNYKXFbb6TqOF1y+fQg3Oj1PF55deeik6nBgTJg7jww2qSxzIiDc+zo5Cc2KFMjdOL95jTsG5SZtssokZPnx4V6sI5hoI82UBe3D4S0uR6n+Kowi80CXJp+zfH4sq/LkLDXlqtPqp703S1ormQ5KylSFu2dpNmcYP+MN+a3fPdRl41mtl6MUxQP1OPq3UClfute8ELWs+5ELcqxot6vjaa69Ff2593Xs0Wfz1G/ERXHHFFdFfv9Vd9U2GAG7gd91112SJ/he77N8fi0yuoIX2lH0IWXnnckHrt77XrXu7+yL50K4sZfu9jO1G40fZWkm+5enVMUD9TvbtxpoQute+8zoYMkPgIxIJASEgBPoNAZzk+JSXqar6Xh/pL56L5MMXb63GndpNNfikUlYPAfU7+fKMBRmo7wQtf3UM061+MZnLt0kpdyEgBKqGQEhzhUYrD1Lf2xzVIvnQvBTl/EXtppx8Uamqj4D6nfx5iLDVV4IWqjz3sF4gxgOfSAgIASHQjwjgJMenGWaYwQ/q+Fl9b2sIi+JD61KU71e1m/LxRCXqHQTU72THS6u9sldytuaDfbVHC09uPoUamh9Hz0JACAiBXkQgtNCUh0ZLfW/r1lMUHziUnoOz86Jzzz235dlySd+rdpMUMcUXAvERKKrfiV+i6sa0QpW9UhOELp77StAKTSBCqtPqslolFwJCQAjERyC00ORr/ePn1jym+t7m2PBLUXzAff+wYcNaF6aDXy+77LJMBS21mw6YoaRCoA0CRfU7bYrRcz9brRZCFvd9JWhNN910DQwNSfQNkRQgBISAEOhBBEILTXkIWup7WzeeovhgJwCtS5P+16zzV7tJzwulFALtECiq32lXjl773dVq9Z1GK9RphyT6XmO66iMEhIAQCCEQWmgqStBS3/sFR4riw4MPPmhmnnnmL16c4R2HfU+ePDnDHI3RmJ0pnMpMCNQhUFS/U/fSHn2wi0yukEWYBK0pDA9J9D3aDlQtISAEhEAdAiFhpyhBS33vF6woig+cm4N5X1UoJGip3VSFeypn2REoqt8pOw5ZlM8VsGx+NqyvvA7ayrtXK4W6YboXAkJACPQDAqH+zw4Oedc/9O6831nW/ENYFMWHsmLSrFwhrJrFVbgQEALNEQh9S+p3muOV9BeLb18JWqGVsNBm26RgKr4QEAJCoIoIhPq/0Cpnp3VT39sawaL40LoU5ftV7aZ8PFGJegcB9Tv58NIKWAit3PeVoBWyRw01tHygV65CQAgIgXIhEOr/8hC01Pe25ntRfGhdivL9qnZTPp6oRL2DgPqdfHjpagW57yuvg6FOO2QDng/0ylUICAEhUC4EQgNtSIvQaanV97ZGsCg+DB8+3Gy22WatC9PBr2PGjDGvvPJKBznUJ1W7qcdDT0IgSwSK6neyLHNV8kKTZQWuvhK0mEC4lYdheWz8rkpDUDmFgBDobwRCA20eGi31va3bWVF8mHHGGc3cc8/dujAd/DrNNNlOKdRuOmCGkgqBNggU1e+0KUZP/OzLFlbI6jvTQSrsTyJCDa0nuK5KCAEhIATaIBDq//w+sk0WsX5W39sapqL48Nlnn7UuSIe/Zp2/2k2HDFFyIdACgaL6nRZF6JmfrGAVqlC2y0+hN5QsDFMEt3HJdLBkDFJxhIAQKAwBty+0L/3444/tbaZX9b3N4SyKD3fffbd57733mhekg18+//zzTM0GbVHUbiwSugqBbBEoqt/JttTVyI1FIoQv/vpS0JpllllqnJp22mnNVFNNZThsUSQEhIAQ6CcEQgtN77zzTi4QMGFW3xuGtig+fPTRR+b+++8PF6KkoWo3JWWMilV5BIrqdyoPVIoKWA0XAldfeR0Eq3fffbcBsplmmqkhTAFCQAgIgV5HYMCAAXVVZFB466236sKyelDf2xzJIvnQvBTl/EXtppx8Uamqj4D6nXx5aLVafSdovfrqqw3IfvWrX20IU4AQEAJCoNcR8Pu+999/32S9z8ZiqL7XItF4LZIPjW8vd4jaTbn5o9JVFwH1O9nyDsHKkhWyeO47QSvkenauueay2OgqBISAEOgLBPC4+pWvfKWurnlps3iJ+t46qGsPRfOh9uKK3KjdVIRRKmalEFC/ky+7rOkgb5GgNQUECVr5NjjlLgSEQPkQ8FczKaEEreL5VDQfiq9hZ2+UoNUZfkotBEIIqN8JodJZmBWufM1W3wlaITMECVqdNS6lFgJCoHoIhAba119/PbeKqO8NQ1s0H8KlKG+o2k15eaOSVRcB9Tv58c4KXPYNfed1MLQ6FmpwFqC8rzjiSHLIIx6YOMRR1DkCI0eONFtttZXZbbfdWro8xgVq0oOtWdFgv4soGQJlxBrzupNPPtnce++95txzz+2Z7y+0wDRp0qRkDEsQu2x9b4Ki5xq1aD7kWpkcMi9ru9H4kQOzc8pyhhlmMMsss0xkvcR8b84554ze9OKLL5oXXnjBPP/885FpczPv0704BqjfyaexuXuzeANCV98JWpwRwzkirpvhUIPLhwWNuY4dOzax6SKCFnX429/+ZiZMmGAeffRRuadvhLZpCC79d9xxRzN8+PCok213QOuoUaPMuuuu2zS/0A+YYO20006hnxTWAoEyYo1zCCZ7a6+9thk4cKA5+uije0KIDi0w5Slola3vbdEMC/2paD4UWrkMXla2dqPxIwOmFpTFsssua9ZYYw2z0kormZArc8ItMWafc8455r777rNBtWsvjgHqd2rszeTGClhWm2WfybzvBC0qzSqGL2gBDsAUTUcddVR0gPLss89u1lxzTTN06NC2RWDVH+GQP4QFhK6bbrrJjBs3rit1aFvgEkWgc9l7773NwgsvbF566SVz+OGHm3YHtIIr+MKjtdZay6y88soNNaLt3HHHHeaee+6J9rlIm9UAUayAMmJN+zjssMPMHnvsEX2fRx55pOEvTzO7WGB1GMlfYOLAWb6JPKlMfW+e9UySdzf4kKR8ZYhblnaj8aMMraF9GeDTzjvvHGmxbGz6t2effTZaXGXhjPF88cUXN4suumikdZhjjjmiucHDDz9sjj/++Lp5QS+OAep3bMvI98rcsC8FLTRBgwcPrqHLSsc888wT9IpVi5TTzcsvvxzl/Pe//9385S9/MRdccEHdm1hJ2WWXXSJhCjNDPg4m+kz47flfCI2bbbaZGTRokDnxxBN7xrSpDogMHuD5XnvtFXlaA3cmzwip7eiDDz4w/DEJ/etf/xoUtC666CJz1VVXtctKv7dBoKxYo/U87rjjzH777WeWW245M2bMmEjYwuSkqrTgggvWFZ3JbF6u3e2LytT32jJ1+9oNPnS7zknfX4Z2o/EjKde6E3/EiBFm6623rjP3f+yxx8zZZ58dXEhabbXVojnW1FNPHRWY/n333Xc3xx57bN3Cda+NAep3sm2fvibLPnPtO2cYQMtk2acllljCDyr8GbMkn1iBeeeddyLTQCahPCOMHXLIIeajjz6qi77iiiuaI444wsw444x14Xow5mtf+1o0ScbW+s0334wtZPnYzTvvvH5QJNjecMMNDeEK6AyBsmHNiijCFjb9s846qznggANqix2d1bT41CzS+PjmaTZoa1jWvteWr+hrt/hQdD07fV+3243Gj045WEz6TTfd1Oywww41IQttwhlnnBFZrjTT1o8fP96ceuqpdQUcMmSI2XLLLevCeOiVMUD9TgNrMwtwreNof/z1paD11FNPNazcLrbYYpkBnTajpZZaqiEpK3khYrLHXhHfMQZarQ022CCUpG/D6FT23XffyEQTELDDfvfdd1PhseSSSzake+KJJxr40BBJAYkRKCPWOKOh/UCYnmy77baJ61WGBIssskhkLuOW5emnn3Yfc7kva9+bS2VjZNotPsQoWqmidLPdaPwoVVNoWhiELF84uvDCC83NN9/cNI394a677jKvvfaafYyu66+/fnAhrRfGAPU7dazO/MEKW1ar1ZeCFirgZ555pg5cbHW7TV//+tcbitBM0CLik08+aS699NKGNAhaDA6i/yIwevRoM/fcc0cPOA65//77U0MTEoYx+RRlj0BZsYbfEydOjCqM2Ym7oTp7FPLJMbSwxLeRN5W178273s3y7xYfmpWnrOHdbDcaP8raKr4oF9spfCHrlltuMVdfffUXkVrcoXXwBTL2wuNII0RVHwPU74S42lkYbcglK2Rx7UtBCzAef/xxFxODvSofVrcI+2B/BR/GtRK0KCsrMT6DcWXKaozIGMwxcRgCofbHTrsTWnrppRuS+22pIYICUiFQZqxZKbWugPFgiUlqlcgfaHHsETqvKI86+d9Lt/vePOoYN89u8iFuGcsSrxvtRuNHWbjfvByzzTab2X777esi/OMf/zDsm05CbMvwadiwYX5Q7bnKY4D6nRobM7uxgpXN0M7LufatoOXbfE811VSR9xkLUtFXTP78s5rYM9HOIx77t0LCWEg7VnSdyvA+3IXbDwBvQtb5SJqysaeFTt0l+IMjE1G2CJQdaxxHPPjgg1GlZ5555sj1e7YI5JubP9AWoc2yNSpb32vL1Y1rN/nQjfp28s5utBuNH51wrJi0HKMyYMCAupddeeWVkQOrusA2D2+//XZDDGsJ0/DDlIAqjwHqd0IczTaMeSdCVl9rtNhX4wsx3XSIETKTCglQoaZgJ3zub77rTve3frnHG+M3vvGNWnX9FdHaDzFvmvEITZkoWwSqgLX7fa6++urZApBjbvQNCIcuFSlola3vdXEo8r7bfCiyrlm8q+h2o/EjC67lmwdzthVWWKHuJeyhuv766+vC4jygBfMJp0eh87dsvCqOAep3LPfyubqaLCts9a1GC5tv/2A6vPZ1i0JmUv4KXrOyodXyiZPPrbtS/7d+ef7mN79Z02ZR5zwErU7z7BdeJK1nSNAqG9bskbQ033zzNZj+2t/KduUQT5cwgcT9cVFUhr6XvnGZZZYx6623XrDaWASw15U9eBxQmwd1mw951CnPPItuNxo/8uRmNnlvtNFGDRmxB9t3EtYQKRAQmi+Rj7WICSSJ9snb8KqMAep3LMfyudr24l778hwtC++dd95p3JVoDq7Dk1hIhWzT5HGFIf7+LN7jrpa0em/oLChMITm0r6h9F63K163fGCgt4Qr/ueees4+priFhWI4wUkHZNlEVsMZk9NNPP61NxOlLWHUvO/nOO9Bmffjhh4UWu+i+lz4Wc1ScHiFg4b4Zh0HsTbvuuuvq6s4qOQeZW8Ks+7zzzrOPmV3LwIfMKlNQRkW2G40fBTE15Wv4nkOL47SRNORr+ckDbVarswWrOAao30nTOtKl6XvTQWBjkuxqgxiM/UaYDt5kqQZOcdjgn33FmQ/vv/9+rIzSrN7EyrjCkViFdifrkydPbnAakqR62GpzcrxLWQhvbn66/y8CVcGaAdg9sNg3YSkjP9kH6h7WThnTTkw6qV/RfS8HuZ900knmpz/9aaSlsl5ZQ5o8f/KGYJY1lYUPWdcr7/yKajcaP/LmZOf5Dx06tEHbxMJX2sXPBRZYoKFQnF3aamtA1cYA9TsNLM49oK+dYYAuJjN47XPJXcVyw/O8D5lJxdVmUS60cCFyhcjQ770chm21awoQsr9OUv9mPLL2uEnyahd3nnnmqbmjbxe3F38vAmtMaxHEuXZC7qHhtLm8zMw6KaObdrnllqsrI4s0nRx34Oad5L7ovveSSy4xl112WcPq9COPPNJQbCZq7nfN95g1lYUPWdcr7/yKajdVHj+mmWYag+mrNV3Kmyfdyt/df23LgOfAVhooGy905VBqn958800/qOG5SmOA+p0G9mUWYMcMeyVj+w327R4ti66/msskr2hXzaGJZdz9WdQjNBHA0Uc/a7pC3gEtz9NcXe2YTZ/1niFMIXbffXdz8sknm5EjR9rX9N01L6wRvDfffPPIDOz00083hx12mOF6xhlnmG222cZgbpuUXIc6dKqdCm5J3580vq+x//Of/2zYPN4NKrLvvffee824ceOMa2bNgBjSaCF8nXbaabWVbCauWVOZ+JB13fLOr4h2U8Xxg/5trbXWisYPTF99L8Z586XI/FnQCnlW5mDrtBTSXMcZ46s0BqjfSds62qezQpW9koIxhufsR5D25SlVDGxsMf9ZaKGFonIx2aIxcthdEQQTQh1GEo1WSNDqxI15EfXO+x3+QJmHRiutiYJfd/j3/e9/33z7299ONdn38ws977zzzobNulnThAkTzI033phptqGFh06x5rs+9NBDg98aGmEcH7CnEfMyzE/iki+kkMcrr7wSN3mh8ZiI+eaN/qS1yAIV3feykOGa/7L63Wxv2u233x4tYG266aZ1wlkW+JSND1nUqcg8img3VRo/6Ntw2sIY0sodeSc8Ktv4wXccsh544YUXUlWTvmGRRRZpSMuRMO2oKmOA+p12nMzud6vVYn7Pfd8LWkD7xz/+MdIkWJi/853vFCZoYRfsa9DYoP3WW2/Z4rS9cuCnT6xU9zPhmtclvzN0f2t3z+SZP5eYoLn7c9zfktwzMJ5wwgnmjTfeiCb4eR2aPXDKPsCFF144SdFixe1kBTH0gryw3nDDDSMhCyHqjjvuiPAG+1VXXbXmvhezYVaEb7jhhlDRgmF+u/LbSTBRlwKXX375yAGEfT2Och566CH72JVrkX0vZjMuhcwG3d8R7hG03n33XTe44/sy8qHjShWcQd7tpirjB7DvsMMOUT+WZM6QlF1lGz8w7QwRc6c0xCKnT5gExlnwrsoYoH7H53B+z65Wi/vktjL5la1rOd99993mtddeq72fCWlRZ2qFzKSSmA1SVrwl+tTvgpavlejE/CekYYFHdtXCxz7JM+2ODfo/+9nPzDXXXJMkaSnismciS8oDa1byNt5448iU9sADD4xMBa+44orIbPDnP/953UQ6ZD7Sqn5+/XlXWWmdddapKxrtLYs2XJdpwoci+15/T0e7s8Ps+TlZayjLyIeEbOt69LzbTVXGDxiBR8yf/OQnZu+9966Zu3adQTEL4PefMZMZXxC26bIUtFhw89uBfY979etQ1jFA/Y7LtezvGUv98dQ+S6M1BW8+FFbIdtxxxxr66667bt0ZCbUfMr4JTSzjrKLYYoTOkcCumFPL+5nQELk0wwwzuI+J7kPCcBpTNkw8Qh+jPU4g65Vzt5JXXnllwyG17u9p79tNVpPmmwfWHJ2Al7mzzz67wcU/Wp2LLrooEnYpa+h7bFUHfx9EnjxsVY52v2Ge6goaeNPCPK7bVFTfy0KL622RVWj3HLQQDriCh7Js42XlQ6j+ZQ7Lu91Uafxw9whhIu9byGTBx7KNH3YC69etmSmwH899ZqHa337B/vZrr73Wjdb0vgpjgPqdpuzL7AdXi2UztWEStP6HCOZEbJS3ttnDhg2L7vP23Bea2MXVaHHCN+V0iQ7o/PPPd4P68j7LgTLEo6SCFvuA2GB/6qmnGvY1FU04A6gC5YH1/PPPb/AedfPNNwchcL832zEGIwYCfQG+rIIW5tBu3W666abSOMspou9F2HbNcvl+W7ltBivrgTZLQavMfAg071IH5dluNH7Us75s40czb4BpPA6yqO4T2n4Wo+JQFcYA9TtxOJl9HObjjCUStP6HLSriq6++OvI+RhDqXxrn73//++zR/1+OTAB9FTiCXdxDhjfZZJMG5wk48WCzsCWYzGoGrkvZD8aV1cBTTjnFRokEylGjRkVlQbMXx9NOLXFJb+iIbSOniP45ZXGLzaZbf4Mx55txzlkSwnQNjVbIy1mSfHo5bl5YI1Tw14xc85Ckpif+IOsvzJTh+2PT+BprrFGrPqu1119/fe252zdF9L2uNo/6ttufRXz6y6effjoS0rPAqOx8yKKOReaRZ7vR+FEkJ5O/y93q4aZm8TmJqS+m4jgScQknOXgojUtlHwPU78TlZHbx7NyT8Z97CVoOtv/v//0/s/7669dcNLPSgfo4jTraybbpbWj1Pq7Z4Oqrr27WXnvturxZmf/d735XF4ZaG2cLTPJhuiXMhuykH4cAw4cPj37C+86uu+5qo1X2ymo1JnnWy1jo1Pc4lQuZsiXdn8U+OuyjMVVy3UvHeX8/xekW1q43xgceeCAR5O4g+8knn9QdgE5GZfj+mEgMGDCgVi8WlMrWDvPue5MKWt/97ncjvLLcN1kFPtQaSUVu8mo3Gj/K3QBwVMGCsD9msJAcV9Bi8dXdLkKNWYTC82wrbbePTNnHAPU7Psfyf3bn2tzLGYaDOR/ZOeecUwthXwdao7woraCFYOR3ELg1HTt2bMNhfdhvb7nllpGm7plnnqlVxZ14PPHEE7VNfM0OP64lrNCNq5lDewg/k1KIR0nMBjFX2mmnnSJB97777kv6+r6K3y2sV1lllQhnVsiTHOtAB0q7soSJmW+60u3vj9VM3D5bQuN21VVX2cfSXPPse1lkGTjF66YlzMJaTcZwgb/ssstGnimz+marwgeLUVWuebYbjR/lbgUh77AjRoyIVWiErIMOOqjOWoW2dMwxx7TsG/zMyz4GqN/xOVbcM5osSxK0LBL/u95///3mwQcfrIWi1bJakVpgBjeYJoY8nPmmR+6rmDAwaedQW9eL3vjx480BBxxg3BPK3XTcM+FzzztyJ4iYx5x55plRkixclvvv7tazO2mmQwydV9aqbKRxBVIb193TY8NCVw6vPfLII82gQYOin7OatIXeVfWwbmHNwoJ17XvZZZclPlbB1RTRdzSjbn1/aFLdQ5QvueSS0uzN8rHKq+/l+Aval6VWe65wJMCZQRB7XZOsbNv8Q9cq8SFU/jKH5dVuNH6UmevGMJ76x1NwhINvCujXAvPCgw8+2Cy22GK1n+ifGauTLKKSmL6lzGOA+p0ai3O/cQUrXmbHHJkONoEe8zuEINz7siKAk4zTTz+9Sex0wSNHjmzYn0VOP/zhDw2q6MmTJ0cmiwhXdAxDhgyJDlJ2BSzOzbj00ktjew9zvWyRp0vWJSkbjHuFEIjA0ZqGIWglMQ1jdcydpFpc6KARal3tBR8VfKPTBVsOvV5xxRVrG/DZN+dvsLb56WpMt7DedtttI/M+Btg//elPiVjhauDY99iubRX9/dEev/e979XqNGnSpNh9RS1RwTd59L2+R7Fmi0n0rbvssovhjJ6JEyearBwAVJEPBbO949fl0W40fnTMllwzYAKLmd9RRx1VG+N5IVsfWNxkboSWyhIL5pynyN57dx6FpQ+OqtJ4ai7zGKB+x3K+mKsVrEJv0x6tACpMiP/whz+YH/zgB9Gv7Ie67rrrOjqglsk+k3Y+dibhCE4hYlLAuUqt6OWXX47OXGKflTvZb5WG39hAygotQpUrQCBQYiLJnqZbb721XTaV+p36ILxCmAO1InjEgbPwaOjQoU15ZFe8W+Xl/yZtVj0iZcB6vfXWizzL8T396le/Sqy9cAdZzvVp56Wq6O+PfUbW1TPf/W9+85uaiXA9N8rzlEff6+/PdLX5tuY4JeIcIrwTYlVgNfz2906uVeRDJ/XtRto82g310PjRDW7GfycLnvvvv7/Zfvvto0ObScmEd4MNNjBYI9G3I2yx99zVPBEPLRbCGI6BfG0Ev8ehMo8B6nficDC/OLQp2iJ/ErSa4MyG8ZVXXtkstNBC0f4aJteY57FynYa22WYbg+1/EqITwcMdfwwkrLrjwCKpZzT7TsqOFgyNCzbK/HHuBmdxIVwwEWNDfy8Rwuhmm20WaZYGTtmngQDV7DDnNDyKi5UErXqkuo01Cx2jR4+OvocxY8a0NLutL/l/nxi40VhCLHZgkteOivz+WLBh9dbS5ZdfbvCmVQXKuu996qmn6qrNkRjsU6NPZWWbha+tt9466gPpc4844ohEJqR1mXsPVeaDV5XSP2bdbqiwxo/Ssz2aw6DZgldrrrlmNMZjicSCMqZ9LtEHYzqM5Q7zAFfj5caLc1/mMUD9ThwO5hvHarhkOtgCZyZPxx13nDn22GMjk7BFFlkkWiWhM09DRx99dJpkmafBba01G0SrRUeD63Hcld92222Zv6/bGeJdDbMSTIIgtFuYBYX2XpSFR93GrIj3dxNrtBZ77rlnZJrLpJoJd1JCSLPmJ2i74y5+FPH90cHT3u25UezBvOKKK5JWsWvxs+578eTKghILSxDaq5NPPjnS4HNvcSIex16kaQ8hsKrOh1CdyhyWdbuhrho/yszx+rJxZAN/mMwhBDG/wQyYdkG/yx8LzZ0IV+4byzoGqN9xudTde6vVkjOMFnzAMxW2u5a22GKLhhPE7W9VubqTCAQuzBQxHUQYSautK3vdESDvuuuuqJiYrPlu8ctefpUvOwRwtW8102x+xrTEJ0wK/ZVQNw6aaaudRoiJo82y6Yv4/ii/dfzCpAKhomrfdpZ9L4sqCNTPPfecZUMkJNP/IWThdZUV8UMPPTQzIYsX9QIfaoBV5CbLdmOrrPHDIlGNKyaB7InGSQrnJ2L+iRaL/dpZCVllHgPU73SvnbomqFbIojQStNrwhA3R9iwVBBJWijmTqqrEqo4lVmSYkDGQJPW2Y/OoyvWMM86oaR0QmK1Wr0zlt6rmMpWpl8rC3hxc+mJSgkbNPdjb1hPTkx//+MdBRzXEYc8TDjQgTHrRerNiGpfy/v5Yyd1qq62i4tDRI2TFPQA9bh2Kipdl38uG9/3228/stdde0eZ5zhakLWy33XaRB7IJEyak3qcRwqOX+BCqX5nDsmw3tp5VGD8oq8YQy7H8rmUeA9Tv5Mf3pDm73+LUCyywwGFJM+i3+AghgwcPjlTROEtA0KqqYDL33HPX9pawORTTCM6O4AyhXiYmw+zV4MwkztPCDeydd95ZqnqzeZUDFyE0H1l5PetlvsatG4L1L3/5y8iUhA4QBwmcR2f/cAk8atSo6OBuzADPPffchqzRfuAWGG0X3w1aklbnMTVkMCUgz+8PkxmEB3sWHu7Jq24OnGXfi+CJcIzgiYexLM2IXF73Ih/c+lXhPst2Q32rMH6wkOTuy2TPUjsHPVXgZZnKWOYxQP1O91uKFa5cbRb3ErRi8AagHn744WjTNMIJWiBMhqq4UsxqzPDhw2u1xmSmmbvjWqQeucGrIuYEuO5nUMILIc9ZmROkhYl9Ipgi4JTE7vthZYo29uGHH5ZKGExbx26mm2222SIhi0USiM4QE1L3D7ztHh72YbJfxyW++wMPPNAsvvjikRCMmVnI7NBNE7rP6/tj8WefffaJvObxXg7z/P3vfx8qQqXCqtb39iofKtVophQ2j3ZT1vEDxw+MZ3hJ5mqJxSQc4ODgqmqmw7YOZbqWeQxQv1OmltKoWZagFZM///znPyMvNXisYkK2/PLLRxoR7IGrREzkOcMLwn7ZmkVWqQ6dlJUVPjwOMSChpcQLYTc1W5ixcUYbwq8Vsqgf4YSh5eLgTNqfKB0CaKvaHWJpc2ZCcuqpp9bhjQYUz4SDppzNgiMVNMBoQ9JQXt8f5oz24GVczVfBlXtc/KrU9/YyH+Lyqyzx8mg3ZRs/wBpX5r/4xS/qhCzC0byvv/76kbkz/ZYoPQJlHwPU76TnbdYpWeSxmi3y5l7u3ROgjDkX5keYDKGFwHsZk5oqkRWy2LMQMo+qUl3SlhXhmHOTODvM1e6lza+TdGzUHz1lr5woPwRYUOAvLUUd5ZQFirPOOqujfHh/Ht8fJiM2X+r529/+NtP9RmlxyzJdFfrefuBDljwtIq882k2Zxg8wRAOf1htyETzohXeUeQxQv1OOFmYFLCtk2WdKV12vDl3Clj0ZCFuYdFWBMJfiTAVorbXWiiZkrMqxib/X92W14g8fAS6vd99998RnKLXKV7/1HgJ867vuumsqIauI78927OPGjYuEQdp2L1LZ+95+4UPV2lYe7UbjR9VaQWflLfMYoH6nM97mnToSuKaYwvXmqJwzeuzpePfdd6PTxXN+Vers2Yt0yCGHROnxsIbpExoUBEVcGouEgBDID4Givj/MTNlv+NBDD+VXmRLlXNa+t9/4UKImEasoZW03sQqvSJVEoIgxQP1OuZpGJFhNMRd0SaaDLhoJ7pN6G0uQdWZR2exvifOD8JyE8wsJWRYVXYVAfggU9f2xeNIvQhbcKmvf2298yO/LySfnsrabfGqrXMuAQBFjgPqdMnD6izKgYbTCFldIpoNf4NNzd+PHj48O6YPZeLBjb5lchvccm1WhkiKg76+kjFGxhIAQEAIFIKAxoACQS/gKV9iieF+S6WAJuZRxkThoGRevIiEgBIpHQN9f8ZjrjUJACAiBsiCgMaAsnMivHFaLFXqDNFohVHosTEJWjzFU1akUAvr+KsUuFVYICAEhkCkCGgMyhbOUmVmnJLZw1myQqwQti4quQkAICAEhIASEgBAQAkJACAiBDhBwzQclaHUApJIKASEgBISAEBACQkAICAEhIARcTZYVtiRoqV0IASEgBISAEBACQkAICAEhIAQ6QMCaELpXCVodAKqkQkAICAEhIASEgBAQAkJACAgBFwGr3ZKg5aKieyEgBISAEBACQkAICAEhIASEQIcIyBlGhwAquRAQAkJACAgBISAEhIAQEAL9i4DVXtkrSFjzQWm0+rddqOZCQAgIASEgBISAEBACQkAIdICAFarslawQuniepoN8lVQICAEhIASEgBAQAkJACAgBISAEpiBgtVoIWdxL0FKzEAJCQAgIASEgBISAEBACQkAIdIiAq9XiXqaDHQKq5EJACAgBISAEhIAQEAJCQAj0JwJorqwmyyJgn6XRsojoKgSEgBAQAkJACAgBISAEhIAQSICAq8WyyWyYNFoWEV2FgBAQAkJACAgBISAEhIAQEAIdImA1WhK0OgRSyYWAEBACQkAICAEhIASEgBAQAlbAQqPFvQQttQkhIASEgBAQAkJACAgBISAEhECHCFiTQbLhXoJWh4AquRAQAkJACAgBISAEhIAQEAJCAASsVot7CVqgIBICQkAICAEhIASEgBAQAkJACCREwBWsSGq1WjIdTAikogsBISAEhIAQEAJCQAgIASEgBCwCVrCyz+5VGi0XDd0LASEgBISAEBACQkAICAEhIARSImA1XNqjlRJAJRMCQkAICAEhIASEgBAQAkJACPgIWA0XAtf/B3BSUAzGBRbtAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "GJTR0lnD0KPc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y95Ukg090J9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZaZLMWakbPge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724e8c31-d4b6-4359-b753-b5a3287e1ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_intersect_rays_1d` passed!\n",
            "All tests in `test_intersect_rays_1d_special_case` passed!\n"
          ]
        }
      ],
      "source": [
        "def intersect_rays_1d(\n",
        "    rays: Float[Tensor, \"nrays 2 3\"], segments: Float[Tensor, \"nsegments 2 3\"]\n",
        ") -> Bool[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return True if it intersects any segment.\n",
        "    \"\"\"\n",
        "    NR = rays.size(0)\n",
        "    NS = segments.size(0)\n",
        "\n",
        "    # Get just the x and y coordinates\n",
        "    rays = rays[..., :2]\n",
        "    segments = segments[..., :2]\n",
        "\n",
        "    # Repeat rays and segments so that we can compuate the intersection of every (ray, segment) pair\n",
        "    rays = einops.repeat(rays, \"nrays p d -> nrays nsegments p d\", nsegments=NS)\n",
        "    segments = einops.repeat(segments, \"nsegments p d -> nrays nsegments p d\", nrays=NR)\n",
        "\n",
        "    # Each element of `rays` is [[Ox, Oy], [Dx, Dy]]\n",
        "    O = rays[:, :, 0]\n",
        "    D = rays[:, :, 1]\n",
        "    assert O.shape == (NR, NS, 2)\n",
        "\n",
        "    # Each element of `segments` is [[L1x, L1y], [L2x, L2y]]\n",
        "    L_1 = segments[:, :, 0]\n",
        "    L_2 = segments[:, :, 1]\n",
        "    assert L_1.shape == (NR, NS, 2)\n",
        "\n",
        "    # Define matrix on left hand side of equation\n",
        "    mat = t.stack([D, L_1 - L_2], dim=-1)\n",
        "    # Get boolean of where matrix is singular, and replace it with the identity in these positions\n",
        "    dets = t.linalg.det(mat)\n",
        "    is_singular = dets.abs() < 1e-8\n",
        "    assert is_singular.shape == (NR, NS)\n",
        "    mat[is_singular] = t.eye(2)\n",
        "\n",
        "    # Define vector on the right hand side of equation\n",
        "    vec = L_1 - O\n",
        "\n",
        "    # Solve equation, get results\n",
        "    sol = t.linalg.solve(mat, vec)\n",
        "    u = sol[..., 0]\n",
        "    v = sol[..., 1]\n",
        "\n",
        "    # Return boolean of (matrix is nonsingular, and solution is in correct range implying intersection)\n",
        "    return ((u >= 0) & (v >= 0) & (v <= 1) & ~is_singular).any(dim=-1)\n",
        "\n",
        "    ## question: why does it matter if the original matrix was non-singular - if that matters... why can't we just drop them from both A\n",
        "    ## cuz the return requires an answer for each ray\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_intersect_rays_1d(intersect_rays_1d)\n",
        "tests.test_intersect_rays_1d_special_case(intersect_rays_1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJxKNd82bPge"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I don't know how to set all my matrices to the identity</summary>\n",
        "\n",
        "You should have some variable `mat` which is a batch of matrices, i.e. it has shape `(n_rays, n_segments, 2, 2)`. You can then define `is_singular` as a boolean tensor of shape `(n_rays, n_segments)` which is true wherever the matrix is singular. Now, indexing `mat[is_singular]` returns a tensor of shape `(N, 2, 2)` where the `[i, :, :]`-th element is the `i`-th singular matrix. Thanks to broadcasting rules, you can set `mat[is_singular] = t.eye(2)`, and the identity matrix with shape `(2, 2)` will get broadcasted to the left hand shape `(N, 2, 2)`.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def intersect_rays_1d(\n",
        "    rays: Float[Tensor, \"nrays 2 3\"], segments: Float[Tensor, \"nsegments 2 3\"]\n",
        ") -> Bool[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return True if it intersects any segment.\n",
        "    \"\"\"\n",
        "    NR = rays.size(0)\n",
        "    NS = segments.size(0)\n",
        "\n",
        "    # Get just the x and y coordinates\n",
        "    rays = rays[..., :2]\n",
        "    segments = segments[..., :2]\n",
        "\n",
        "    # Repeat rays and segments so that we can compuate the intersection of every (ray, segment) pair\n",
        "    rays = einops.repeat(rays, \"nrays p d -> nrays nsegments p d\", nsegments=NS)\n",
        "    segments = einops.repeat(segments, \"nsegments p d -> nrays nsegments p d\", nrays=NR)\n",
        "\n",
        "    # Each element of `rays` is [[Ox, Oy], [Dx, Dy]]\n",
        "    O = rays[:, :, 0]\n",
        "    D = rays[:, :, 1]\n",
        "    assert O.shape == (NR, NS, 2)\n",
        "\n",
        "    # Each element of `segments` is [[L1x, L1y], [L2x, L2y]]\n",
        "    L_1 = segments[:, :, 0]\n",
        "    L_2 = segments[:, :, 1]\n",
        "    assert L_1.shape == (NR, NS, 2)\n",
        "\n",
        "    # Define matrix on left hand side of equation\n",
        "    mat = t.stack([D, L_1 - L_2], dim=-1)\n",
        "    # Get boolean of where matrix is singular, and replace it with the identity in these positions\n",
        "    dets = t.linalg.det(mat)\n",
        "    is_singular = dets.abs() < 1e-8\n",
        "    assert is_singular.shape == (NR, NS)\n",
        "    mat[is_singular] = t.eye(2)\n",
        "\n",
        "    # Define vector on the right hand side of equation\n",
        "    vec = L_1 - O\n",
        "\n",
        "    # Solve equation, get results\n",
        "    sol = t.linalg.solve(mat, vec)\n",
        "    u = sol[..., 0]\n",
        "    v = sol[..., 1]\n",
        "\n",
        "    # Return boolean of (matrix is nonsingular, and solution is in correct range implying intersection)\n",
        "    return ((u >= 0) & (v >= 0) & (v <= 1) & ~is_singular).any(dim=-1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsX5I6JjbPge"
      },
      "source": [
        "## Using GPT to understand code\n",
        "\n",
        "*Note, the world of LLMs moves fast, so this section is likely to get out of date at some point!*\n",
        "\n",
        "Next week we'll start learning about transformers and how to build them, but it's not too early to start using them to accelerate your own learning!\n",
        "\n",
        "We'll be discussing more advanced ways to use GPT 3 and 4 as coding partners / research assistants in the coming weeks, but for now we'll look at a simple example: **using GPT to understand code**. You're recommended to read the recent [LessWrong post](https://www.lesswrong.com/posts/ptY6X3BdW4kgqpZFo/using-gpt-4-to-understand-code) by Siddharth Hiregowdara in which he explains his process. This works best on GPT-4, but I've found GPT-3.5 works equally well for reasonably straightforward problems (see the section below).\n",
        "\n",
        "Firstly, you should get an account to use GPT with if you haven't already. Next, try asking GPT-3.5 / 4 for an explanation of the function above. You can do this e.g. via the following prompt:\n",
        "\n",
        "> Explain this Python function, line by line. You should break up your explanation by inserting sections of the code.\n",
        ">\n",
        "> ```python\n",
        "> def intersect_rays_1d(rays: Float[Tensor, \"nrays 2 3\"], segments: Float[Tensor, \"nsegments 2 3\"]) -> Bool[Tensor, \"nrays\"]:\n",
        ">     NR = rays.size(0)\n",
        ">     NS = segments.size(0)\n",
        ">     rays = rays[..., :2]\n",
        ">     ...\n",
        "> ```\n",
        "\n",
        "I've found removing comments is often more helpful, because then GPT will answer in its own words rather than just repeating the comments (and the comments can sometimes confuse it).\n",
        "\n",
        "Once you've got a response, here are a few more things you might want to consider asking:\n",
        "\n",
        "* Can you suggest ways to improve the code?\n",
        "    * GPT-4 recommended using a longer docstring and more descriptive variable names, among other things.\n",
        "* Can you explain why the line `mat[is_singular] = t.eye(2)` works?\n",
        "    * GPT-4 gave me a correct and very detailed explanation involving broadcasting and tensor shapes.\n",
        "\n",
        "Is using GPT in this way cheating? It can be, if your first instinct is to jump to GPT rather than trying to understand the code yourself. But it's important here to bring up the distinction of [playing in easy mode](https://www.lesswrong.com/posts/nJPtHHq6L7MAMBvRK/play-in-easy-mode) vs [playing in hard mode](https://www.lesswrong.com/posts/7hLWZf6kFkduecH2g/play-in-hard-mode). There are situations where it's valuable for you to think about a problem for a while before moving forward because that deliberation will directly lead to you becoming a better researcher or engineer (e.g. when you're thinking of a hypothesis for how a circuit works while doing mechanistic interpretability on a transformer, or you're pondering which datastructure best fits your use case while implementing some RL algorithm). But there are also situations (like this one) where you'll get more value from speedrunning towards an understanding of certain code or concepts, and apply your understanding in subsequent exercises. It's important to find a balance!\n",
        "\n",
        "#### When to use GPT-3.5 and GPT-4\n",
        "\n",
        "GPT-3.5 and 4 both have advantages and disadvantages in different situations. GPT-3.5 has a large advantage in speed over GPT-4, and works equally well on simple problems or functions. If it's anything that Copilot is capable of writing, then you're likely better off using it instead of GPT-4.\n",
        "\n",
        "On the other hand, GPT-4 has an advantage at generating coherent code (although we don't expect you to be using it for code generation much at this stage in the program), and is generally better at responding to complex tasks with less prompt engineering.\n",
        "\n",
        "#### Additional notes on using GPT (from Joseph Bloom)\n",
        "\n",
        "* ChatGPT is overly friendly. If you give it bad code it won't tell you it's shit so you need to encourage it to give feedback and/or show you examples of great code. Especially for beginner coders using it, it's important to realise how *under* critical it is.\n",
        "* GPT is great at writing tests (asking it to write a test for a function is often better than asking it if a function is correct), refactoring code (identifying repeated tasks and extracting them) and naming variables well. These are specific things worth doing a few times to see how useful they can be.\n",
        "* GPT-4 does well with whole modules/scripts so don't hesitate to add those. When you start managing repos on GitHub, use tracked files so that when you copy-paste edited code back, all the changes are highlighted for you as if you'd made them. (VSCode highlights changes with small blue bars next to the line numbers in your python files.)\n",
        "\n",
        "Here are some things you can play around with:\n",
        "\n",
        "* Ask GPT it to write tests for the function. You can give more specific instructions (e.g. asking it to use / not to use the `unittests` library, or to print more informative error messages).\n",
        "* Ask GPT how to refactor the function above. (When I did this, it suggested splitting the function up into subfunctions which performed the discrete tasks of \"compute intersection points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cve20PH4bPge"
      },
      "source": [
        "## 2D Rays\n",
        "\n",
        "Now we're going to make use of the z dimension and have rays emitted from the origin in both y and z dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZMqkVnwbPgf"
      },
      "source": [
        "### Exercise - implement `make_rays_2d`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement `make_rays_2d` analogously to `make_rays_1d`. The result should look like a pyramid with the tip at the origin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O7ecGeAbPgf"
      },
      "outputs": [],
      "source": [
        "def make_rays_2d(num_pixels_y: int, num_pixels_z: int, y_limit: float, z_limit: float) -> Float[Tensor, \"nrays 2 3\"]:\n",
        "    \"\"\"\n",
        "    num_pixels_y: The number of pixels in the y dimension\n",
        "    num_pixels_z: The number of pixels in the z dimension\n",
        "\n",
        "    y_limit: At x=1, the rays should extend from -y_limit to +y_limit, inclusive of both.\n",
        "    z_limit: At x=1, the rays should extend from -z_limit to +z_limit, inclusive of both.\n",
        "\n",
        "    Returns: shape (num_rays=num_pixels_y * num_pixels_z, num_points=2, num_dims=3).\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "rays_2d = make_rays_2d(10, 10, 0.3, 0.3)\n",
        "render_lines_with_plotly(rays_2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylYwgFkEbPgf"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to implement this function.</summary>\n",
        "\n",
        "Don't write it as a function right away. The most efficient way is to write and test each line individually in the REPL to verify it does what you expect before proceeding.\n",
        "\n",
        "You can either build up the output tensor using `torch.stack`, or you can initialize the output tensor to its final size and then assign to slices like `rays[:, 1, 1] = ...`. It's good practice to be able to do it both ways.\n",
        "\n",
        "Each y coordinate needs a ray with each corresponding z coordinate - in other words this is an outer product. The most elegant way to do this is with two calls to `einops.repeat`. You can also accomplish this with `unsqueeze`, `expand`, and `reshape` combined.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def make_rays_2d(num_pixels_y: int, num_pixels_z: int, y_limit: float, z_limit: float) -> Float[Tensor, \"nrays 2 3\"]:\n",
        "    \"\"\"\n",
        "    num_pixels_y: The number of pixels in the y dimension\n",
        "    num_pixels_z: The number of pixels in the z dimension\n",
        "\n",
        "    y_limit: At x=1, the rays should extend from -y_limit to +y_limit, inclusive of both.\n",
        "    z_limit: At x=1, the rays should extend from -z_limit to +z_limit, inclusive of both.\n",
        "\n",
        "    Returns: shape (num_rays=num_pixels_y * num_pixels_z, num_points=2, num_dims=3).\n",
        "    \"\"\"\n",
        "    n_pixels = num_pixels_y * num_pixels_z\n",
        "    ygrid = t.linspace(-y_limit, y_limit, num_pixels_y)\n",
        "    zgrid = t.linspace(-z_limit, z_limit, num_pixels_z)\n",
        "    rays = t.zeros((n_pixels, 2, 3), dtype=t.float32)\n",
        "    rays[:, 1, 0] = 1\n",
        "    rays[:, 1, 1] = einops.repeat(ygrid, \"y -> (y z)\", z=num_pixels_z)\n",
        "    rays[:, 1, 2] = einops.repeat(zgrid, \"z -> (y z)\", y=num_pixels_y)\n",
        "    return rays\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIZj1f1ObPgf"
      },
      "source": [
        "# 3️⃣ Triangles\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand how to parametrize triangles in 2D and 3D, and solve for their intersection with rays\n",
        "> - Put everything together, to render your mesh as a 2D image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alUNNZItbPgf"
      },
      "source": [
        "## Triangle Coordinates\n",
        "\n",
        "The area inside a triangle can be defined by three (non-collinear) points $A$, $B$ and $C$, and can be written algebraically as a **convex combination** of those three points:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "P(w, u, v) &= wA + uB + vC \\quad\\quad \\\\\n",
        "    \\\\\n",
        "s.t. \\quad 0 &\\leq w,u,v \\\\\n",
        "1 &= w + u + v\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "Or equivalently:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\quad\\quad\\quad\\quad P(u, v) &= (1 - u - v)A + uB + vC \\\\\n",
        "&= A + u(B - A) + v(C - A) \\\\\n",
        "\\\\\n",
        "s.t. \\quad 0 &\\leq u,v \\\\\n",
        "u + v &\\leq 1\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "These $u, v$ are called \"barycentric coordinates\".\n",
        "\n",
        "If we remove the bounds on $u$ and $v$, we get an equation for the plane containing the triangle. Play with the widget to understand the behavior of $u, v$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBBhBoSkbPgf"
      },
      "outputs": [],
      "source": [
        "one_triangle = t.tensor([[0, 0, 0], [4, 0.5, 0], [2, 3, 0]])\n",
        "A, B, C = one_triangle\n",
        "x, y, z = one_triangle.T\n",
        "\n",
        "fig: go.FigureWidget = setup_widget_fig_triangle(x, y, z)\n",
        "display(fig)\n",
        "\n",
        "\n",
        "@interact(u=(-0.5, 1.5, 0.01), v=(-0.5, 1.5, 0.01))\n",
        "def update(u=0.0, v=0.0):\n",
        "    P = A + u * (B - A) + v * (C - A)\n",
        "    fig.update_traces({\"x\": [P[0]], \"y\": [P[1]]}, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeUzsAARbPgf"
      },
      "source": [
        "### Triangle-Ray Intersection\n",
        "\n",
        "Given a ray with origin $O$ and direction $D$, our intersection algorithm will consist of two steps:\n",
        "\n",
        "- Finding the intersection between the line and the plane containing the triangle, by solving the equation $P(u, v) = P(s)$;\n",
        "- Checking if $u$ and $v$ are within the bounds of the triangle.\n",
        "\n",
        "Expanding the equation $P(u, v) = P(s)$, we have:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "A + u(B - A) + v(C - A) &= O + sD \\\\\n",
        "\\Rightarrow\n",
        "\\begin{pmatrix}\n",
        "    -D & (B - A) & (C - A) \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "    s \\\\\n",
        "    u \\\\\n",
        "    v  \n",
        "\\end{pmatrix}\n",
        "&= \\begin{pmatrix} O - A \\end{pmatrix} \\\\\n",
        "\\Rightarrow \\begin{pmatrix}\n",
        "    -D_x & (B - A)_x & (C - A)_x \\\\\n",
        "    -D_y & (B - A)_y & (C - A)_y \\\\\n",
        "    -D_z & (B - A)_z & (C - A)_z \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "    s \\\\\n",
        "    u \\\\\n",
        "    v  \n",
        "\\end{pmatrix} &= \\begin{pmatrix}\n",
        "    (O - A)_x \\\\\n",
        "    (O - A)_y \\\\\n",
        "    (O - A)_z \\\\\n",
        "\\end{pmatrix}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "$$\n",
        "$$\n",
        "\n",
        "We can therefore find the coordinates `s`, `u`, `v` of the intersection point by solving the linear system above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJDiiv5FbPgf"
      },
      "source": [
        "### Exercise - implement `triangle_ray_intersects`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Using `torch.linalg.solve` and `torch.stack`, implement `triangle_ray_intersects(A, B, C, O, D)`.\n",
        "\n",
        "A few tips:\n",
        "\n",
        "* If you have a 0-dimensional tensor with shape `()` containing a single value, use the `item()` method to convert it to a plain Python value.\n",
        "* If you have a tensor of shape `tensor.shape = (3, ...)`, then you can unpack it along the first dimension into three separate tensors the same way that you'd unpack a normal python list: `s, u, v = tensor`.\n",
        "    * Note - if the dimension you want to unpack isn't at the start, a nice alternative is `s, u, v = tensor.unbind(dim)`, which does the same thing but along the dimension given by `dim` rather than the first dimension.\n",
        "* If your function isn't working, try making a simple ray and triangle with nice round numbers where you can work out manually if it should intersect or not, then debug from there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf_sZ4bObPgf"
      },
      "outputs": [],
      "source": [
        "Point = Float[Tensor, \"points=3\"]\n",
        "\n",
        "\n",
        "def triangle_ray_intersects(A: Point, B: Point, C: Point, O: Point, D: Point) -> bool:\n",
        "    \"\"\"\n",
        "    A: shape (3,), one vertex of the triangle\n",
        "    B: shape (3,), second vertex of the triangle\n",
        "    C: shape (3,), third vertex of the triangle\n",
        "    O: shape (3,), origin point\n",
        "    D: shape (3,), direction point\n",
        "\n",
        "    Return True if the ray and the triangle intersect.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_triangle_ray_intersects(triangle_ray_intersects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wLOVMl3bPgg"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def triangle_ray_intersects(A: Point, B: Point, C: Point, O: Point, D: Point) -> bool:\n",
        "    \"\"\"\n",
        "    A: shape (3,), one vertex of the triangle\n",
        "    B: shape (3,), second vertex of the triangle\n",
        "    C: shape (3,), third vertex of the triangle\n",
        "    O: shape (3,), origin point\n",
        "    D: shape (3,), direction point\n",
        "\n",
        "    Return True if the ray and the triangle intersect.\n",
        "    \"\"\"\n",
        "    s, u, v = t.linalg.solve(t.stack([-D, B - A, C - A], dim=1), O - A)\n",
        "    return ((s >= 0) & (u >= 0) & (v >= 0) & (u + v <= 1)).item()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guDGV8rtbPgg"
      },
      "source": [
        "## Single-Triangle Rendering\n",
        "\n",
        "Implement `raytrace_triangle` using only one call to `torch.linalg.solve`.\n",
        "\n",
        "Reshape the output and visualize with `plt.imshow`. It's normal for the edges to look pixelated and jagged - using a small number of pixels is a good way to debug quickly.\n",
        "\n",
        "If you think it's working, increase the number of pixels and verify that it looks less pixelated at higher resolution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MOhqZkxbPgg"
      },
      "source": [
        "### Views and Copies\n",
        "\n",
        "It's critical to know when you are making a copy of a `Tensor`, versus making a view of it that shares the data with the original tensor. It's preferable to use a view whenever possible to avoid copying memory unnecessarily. On the other hand, modifying a view modifies the original tensor which can be unintended and surprising. Consult [the documentation](https://pytorch.org/docs/stable/tensor_view.html) if you're unsure if a function returns a view. A short reference of common functions:\n",
        "\n",
        "- `torch.expand`: always returns a view\n",
        "- `torch.view`: always returns a view\n",
        "- `torch.detach`: always returns a view\n",
        "- `torch.repeat`: always copies\n",
        "- `torch.clone`: always copies\n",
        "- `torch.flip`: always copies (different than numpy.flip which returns a view)\n",
        "- `torch.tensor`: always copies, but PyTorch recommends using `.clone().detach()` instead.\n",
        "- `torch.Tensor.contiguous`: returns self if possible, otherwise a copy\n",
        "- `torch.transpose`: returns a view if possible, otherwise (sparse tensor) a copy\n",
        "- `torch.reshape`: returns a view if possible, otherwise a copy\n",
        "- `torch.flatten`: returns a view if possible, otherwise a copy (different than numpy.flatten which returns a copy)\n",
        "- `einops.repeat`: returns a view if possible, otherwise a copy\n",
        "- `einops.rearrange`: returns a view if possible, otherwise a copy\n",
        "- Basic indexing returns a view, while advanced indexing returns a copy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM31Ir1ubPgg"
      },
      "source": [
        "### Storage Objects\n",
        "\n",
        "Calling `storage()` on a `Tensor` returns a Python object wrapping the underlying C++ array. This array is 1D regardless of the dimensionality of the `Tensor`. This allows you to look inside the `Tensor` abstraction and see how the actual data is laid out in RAM.\n",
        "\n",
        "Note that a new Python wrapper object is generated each time you call `storage()`, and both `x.storage() == x.storage()` and `x.storage() is x.storage()` evaluates to False.\n",
        "\n",
        "If you want to check if two `Tensor`s share an underlying C++ array, you can compare their `storage().data_ptr()` fields. This can be useful for debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UXcP_5cbPgg"
      },
      "source": [
        "### `Tensor._base`\n",
        "\n",
        "If `x` is a view, you can access the original `Tensor` with `x._base`. This is an undocumented internal feature that's useful to know. Consider the following code:\n",
        "\n",
        "```python\n",
        "x = t.zeros(1024*1024*1024)\n",
        "y = x[0]\n",
        "del x\n",
        "```\n",
        "\n",
        "Here, `y` was created through basic indexing, so `y` is a view and `y._base` refers to `x`. This means `del x` won't actually deallocate the 4GB of memory, and that memory will remain in use which can be quite surprising. `y = x[0].clone()` would be an alternative here that does allow reclaiming the memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn04aFfjbPgg"
      },
      "source": [
        "### Exercise - implement `raytrace_triangle`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> This is about as hard as `intersect_rays_1d`, although hopefully you should find it more familiar.\n",
        "> ```\n",
        "\n",
        "Below, you should implement `raytrace_triangle`, a funtion which checks whether each ray in `ray` intersects a single given triangle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPMJXjBlbPgg"
      },
      "outputs": [],
      "source": [
        "def raytrace_triangle(\n",
        "    rays: Float[Tensor, \"nrays rayPoints=2 dims=3\"], triangle: Float[Tensor, \"trianglePoints=3 dims=3\"]\n",
        ") -> Bool[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return True if the triangle intersects that ray.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "A = t.tensor([1, 0.0, -0.5])\n",
        "B = t.tensor([1, -0.5, 0.0])\n",
        "C = t.tensor([1, 0.5, 0.5])\n",
        "num_pixels_y = num_pixels_z = 15\n",
        "y_limit = z_limit = 0.5\n",
        "\n",
        "# Plot triangle & rays\n",
        "test_triangle = t.stack([A, B, C], dim=0)\n",
        "rays2d = make_rays_2d(num_pixels_y, num_pixels_z, y_limit, z_limit)\n",
        "triangle_lines = t.stack([A, B, C, A, B, C], dim=0).reshape(-1, 2, 3)\n",
        "render_lines_with_plotly(rays2d, triangle_lines)\n",
        "\n",
        "# Calculate and display intersections\n",
        "intersects = raytrace_triangle(rays2d, test_triangle)\n",
        "img = intersects.reshape(num_pixels_y, num_pixels_z).int()\n",
        "imshow(img, origin=\"lower\", width=600, title=\"Triangle (as intersected by rays)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lBSTBddbPgg"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def raytrace_triangle(\n",
        "    rays: Float[Tensor, \"nrays rayPoints=2 dims=3\"], triangle: Float[Tensor, \"trianglePoints=3 dims=3\"]\n",
        ") -> Bool[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return True if the triangle intersects that ray.\n",
        "    \"\"\"\n",
        "    NR = rays.size(0)\n",
        "\n",
        "    # Triangle is [[Ax, Ay, Az], [Bx, By, Bz], [Cx, Cy, Cz]]\n",
        "    A, B, C = einops.repeat(triangle, \"pts dims -> pts NR dims\", NR=NR)\n",
        "    assert A.shape == (NR, 3)\n",
        "\n",
        "    # Each element of `rays` is [[Ox, Oy, Oz], [Dx, Dy, Dz]]\n",
        "    O, D = rays.unbind(dim=1)\n",
        "    assert O.shape == (NR, 3)\n",
        "\n",
        "    # Define matrix on left hand side of equation\n",
        "    mat: Float[Tensor, \"NR 3 3\"] = t.stack([-D, B - A, C - A], dim=-1)\n",
        "\n",
        "    # Get boolean of where matrix is singular, and replace it with the identity in these positions\n",
        "    # Note - this works because mat[is_singular] has shape (NR_where_singular, 3, 3), so we\n",
        "    # can broadcast the identity matrix to that shape.\n",
        "    dets: Float[Tensor, \"NR\"] = t.linalg.det(mat)\n",
        "    is_singular = dets.abs() < 1e-8\n",
        "    mat[is_singular] = t.eye(3)\n",
        "\n",
        "    # Define vector on the right hand side of equation\n",
        "    vec = O - A\n",
        "\n",
        "    # Solve eqns\n",
        "    sol: Float[Tensor, \"NR 3\"] = t.linalg.solve(mat, vec)\n",
        "    s, u, v = sol.unbind(dim=-1)\n",
        "\n",
        "    # Return boolean of (matrix is nonsingular) && (solution is in correct range implying intersection)\n",
        "    return (s >= 0) & (u >= 0) & (v >= 0) & (u + v <= 1) & ~is_singular\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8gDEDo0bPgg"
      },
      "source": [
        "## Debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYeqSGvSbPgg"
      },
      "source": [
        "Debugging code is an extremely important thing to learn. Just like using GPT to assist your coding, it's something that can significantly speedrun your development, and stop you getting hung up on all the frustrating things!\n",
        "\n",
        "To give you practice debugging using VSCode's built-in debugger\\*, we've provided an example function below. This is an implementation of `raytrace_triangle` which has a few mistakes in it. Your task is to use the debugger to find the mistake and fix it. (Note - you're encouraged to actually use the debugger, rather than comparing it to the solution above!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kp1h6LwbPgg"
      },
      "source": [
        "<details>\n",
        "<summary>Incorrect function</summary>\n",
        "\n",
        "```python\n",
        "def raytrace_triangle_with_bug(\n",
        "    rays: Float[Tensor, \"nrays rayPoints=2 dims=3\"],\n",
        "    triangle: Float[Tensor, \"trianglePoints=3 dims=3\"]\n",
        ") -> Bool[Tensor, \"nrays\"]:\n",
        "    '''\n",
        "    For each ray, return True if the triangle intersects that ray.\n",
        "    '''\n",
        "    NR = rays.size[0]\n",
        "\n",
        "    A, B, C = einops.repeat(triangle, \"pts dims -> pts NR dims\", NR=NR)\n",
        "\n",
        "    O, D = rays.unbind(-1)\n",
        "\n",
        "    mat = t.stack([- D, B - A, C - A])\n",
        "    \n",
        "    dets = t.linalg.det(mat)\n",
        "    is_singular = dets.abs() < 1e-8\n",
        "    mat[is_singular] = t.eye(3)\n",
        "\n",
        "    vec = O - A\n",
        "\n",
        "    sol = t.linalg.solve(mat, vec)\n",
        "    s, u, v = sol.unbind(dim=-1)\n",
        "\n",
        "    return ((u >= 0) & (v >= 0) & (u + v <= 1) & ~is_singular)\n",
        "\n",
        "\n",
        "intersects = raytrace_triangle_with_bug(rays2d, test_triangle)\n",
        "img = intersects.reshape(num_pixels_y, num_pixels_z).int()\n",
        "imshow(img, origin=\"lower\", width=600, title=\"Triangle (as intersected by rays)\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGaLhw5LbPgg"
      },
      "source": [
        "You can debug a cell by clicking on the **Debug cell** option at the bottom of your cell. Your cell should contain the code that is actually run to cause an error (rather than needing to contain the function which is the source of the error). Before you run your debugger, you can set breakpoints by clicking on the left-hand side of the line number (a red dot will appear). You can then step through your code, using the toolbar of buttons which will appear when you run the debugger (see [here](https://pawelgrzybek.com/continue-step-over-step-into-and-step-out-actions-in-visual-studio-code-debugger-explained/) for an explanation of what each of the buttons does). When you reach a breakpoint, you can use the following tools:\n",
        "\n",
        "* Inspect local and global variables, in the **VARIABLES** window that appears on the left sidebar.\n",
        "* Add variables expressions to watch, in the **WATCH** window that appears on the left sidebar.\n",
        "    * You can just type in any expression here, e.g. the type of a variable or the length of a list, and this will update as you step through the function.\n",
        "* Evaluate expressions on a one-time basis, by typing them into the **DEBUG CONSOLE** (which appears at the bottom of the screen)\n",
        "\n",
        "Note, when you run the debugger, it will stop *before* the breakpoint line is evaluated. So if you've run a cell and got an error on a specific line, then *that* is the line you want to set a breakpoint on.\n",
        "\n",
        "*This all works basically the same if you're in a notebook in VSCode, except for a few changes e.g. the debug button is on the dropdown at the top-left of the cell (if it doesn't appear for you then you'll need to go into user settings and add the line `\"notebook.consolidatedRunButton\": true`).*\n",
        "\n",
        "There's much more detail we could go into about debugging, but this will suffice for most purposes. It's generally a much more efficient way of debugging than using print statements or asserts (although these can also be helpful in some situations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N9qVyWJbPgg"
      },
      "source": [
        "<details>\n",
        "<summary>Answer - what are the bugs, and how can they be fixed?</summary>\n",
        "\n",
        "```python\n",
        "NR = rays.size[0]\n",
        "```\n",
        "\n",
        "This should be `rays.size(0)` (or equivalently, `rays.shape[0]`). `size` is a method which takes an int and returns the size of that dimension; `shape` returns a `torch.Size` object which can be indexed into.\n",
        "\n",
        "This would have been pretty easy to realise without using the debugger, because the error message is informative.\n",
        "\n",
        "```python\n",
        "O, D = rays.unbind(-1)\n",
        "```\n",
        "\n",
        "We're unbinding from the wrong dimension. `rays` has shape `(nrays, points=2, dims=3)`, and we actually want to unbind along the `points` dimension. So we should use `rays.unbind(1)`.\n",
        "\n",
        "We could have found this by inspecting the `rays` object in the variables pane (you can click on the dropdown next to the variable name to look at its attributes, including `shape`), or you could just type `rays.shape` into the debug console. However, this error should also have been apparent given the type signature of the function (a good case for using typing!).\n",
        "\n",
        "```python\n",
        "mat = t.stack([- D, B - A, C - A])\n",
        "```\n",
        "\n",
        "This should have had the argument `dim=-1` on the end, because `torch.stack` by default stacks along the first dimension.\n",
        "\n",
        "This error is a bit harder to diagnose, because the line causing an error is after the line containing the mistake. Again, we could have diagnosed this with the debugger by inspecting the shape of our `mat` tensor in the variables pane.\n",
        "\n",
        "---\n",
        "\n",
        "These were all relatively easy bugs to diagnose (not all bugs will present as actual errors in your code, some might just be an unexpected set of results). But hopefully this has given you a sense for how to use the debugger. It's a very powerful tool, and can save you a lot of time!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1SCbLrQbPgg"
      },
      "source": [
        "\\**If you're using Colab, you'll have to use different strategies for debugging. See [this page](https://zohaib.me/debugging-in-google-collab-notebook/) for one suggested approach.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bMW3YAKbPgg"
      },
      "source": [
        "## Mesh Loading\n",
        "\n",
        "Use the given code to load the triangles for your Pikachu. By convention, files written with `torch.save` end in the `.pt` extension, but these are actually just zip files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVDFRHs9bPgg"
      },
      "outputs": [],
      "source": [
        "triangles = t.load(section_dir / \"pikachu.pt\", weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxwFJc_XbPgg"
      },
      "source": [
        "## Mesh Rendering\n",
        "\n",
        "For our purposes, a mesh is just a group of triangles, so to render it we'll intersect all rays and all triangles at once. We previously just returned a boolean for whether a given ray intersects the triangle, but now it's possible that more than one triangle intersects a given ray.\n",
        "\n",
        "For each ray (pixel) we will return a float representing the minimum distance to a triangle if applicable, otherwise the special value `float('inf')` representing infinity. We won't return which triangle was intersected for now.\n",
        "\n",
        "Note - by distance to a triangle, we specifically mean **distance along the x-dimension**, not Euclidean distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuFtYIY_bPgg"
      },
      "source": [
        "### Exercise - implement `raytrace_mesh`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 20-25 minutes on this exercise.\n",
        ">\n",
        "> This is the main function we've been building towards, and marks the end of the core exercises. If should involve a lot of repurposed code from the last excercise.\n",
        "> ```\n",
        "\n",
        "Implement `raytrace_mesh` and as before, reshape and visualize the output. Your Pikachu is centered on (0, 0, 0), so you'll want to slide the ray origin back to at least `x=-2` to see it properly.\n",
        "\n",
        "Reminder - `t.linalg.solve` (and most batched operations) can accept multiple dimensions as being batch dims. Previously, you've just used `NR` (the number of rays) as the batch dimension, but you can also use `(NR, NT)` (the number of rays and triangles) as your batch dimensions, so you can solve for all rays and triangles at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itEu-b8DbPgg"
      },
      "outputs": [],
      "source": [
        "def raytrace_mesh(\n",
        "    rays: Float[Tensor, \"nrays rayPoints=2 dims=3\"], triangles: Float[Tensor, \"ntriangles trianglePoints=3 dims=3\"]\n",
        ") -> Float[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return the distance to the closest intersecting triangle, or infinity.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "num_pixels_y = 120\n",
        "num_pixels_z = 120\n",
        "y_limit = z_limit = 1\n",
        "\n",
        "rays = make_rays_2d(num_pixels_y, num_pixels_z, y_limit, z_limit)\n",
        "rays[:, 0] = t.tensor([-2, 0.0, 0.0])\n",
        "dists = raytrace_mesh(rays, triangles)\n",
        "intersects = t.isfinite(dists).view(num_pixels_y, num_pixels_z)\n",
        "dists_square = dists.view(num_pixels_y, num_pixels_z)\n",
        "img = t.stack([intersects, dists_square], dim=0)\n",
        "\n",
        "fig = px.imshow(img, facet_col=0, origin=\"lower\", color_continuous_scale=\"magma\", width=1000)\n",
        "fig.update_layout(coloraxis_showscale=False)\n",
        "for i, text in enumerate([\"Intersects\", \"Distance\"]):\n",
        "    fig.layout.annotations[i][\"text\"] = text\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFjKnhM7bPgh"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def raytrace_mesh(\n",
        "    rays: Float[Tensor, \"nrays rayPoints=2 dims=3\"], triangles: Float[Tensor, \"ntriangles trianglePoints=3 dims=3\"]\n",
        ") -> Float[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return the distance to the closest intersecting triangle, or infinity.\n",
        "    \"\"\"\n",
        "    NR = rays.size(0)\n",
        "    NT = triangles.size(0)\n",
        "\n",
        "    # Each triangle is [[Ax, Ay, Az], [Bx, By, Bz], [Cx, Cy, Cz]]\n",
        "    triangles = einops.repeat(triangles, \"NT pts dims -> pts NR NT dims\", NR=NR)\n",
        "    A, B, C = triangles\n",
        "    assert A.shape == (NR, NT, 3)\n",
        "\n",
        "    # Each ray is [[Ox, Oy, Oz], [Dx, Dy, Dz]]\n",
        "    rays = einops.repeat(rays, \"NR pts dims -> pts NR NT dims\", NT=NT)\n",
        "    O, D = rays\n",
        "    assert O.shape == (NR, NT, 3)\n",
        "\n",
        "    # Define matrix on left hand side of equation\n",
        "    mat: Float[Tensor, \"NR NT 3 3\"] = t.stack([-D, B - A, C - A], dim=-1)\n",
        "    # Get boolean of where matrix is singular, and replace it with the identity in these positions\n",
        "    dets: Float[Tensor, \"NR NT\"] = t.linalg.det(mat)\n",
        "    is_singular = dets.abs() < 1e-8\n",
        "    mat[is_singular] = t.eye(3)\n",
        "\n",
        "    # Define vector on the right hand side of equation\n",
        "    vec: Float[Tensor, \"NR NT 3\"] = O - A\n",
        "\n",
        "    # Solve eqns (note, s is the distance along ray)\n",
        "    sol: Float[Tensor, \"NR NT 3\"] = t.linalg.solve(mat, vec)\n",
        "    s, u, v = sol.unbind(-1)\n",
        "\n",
        "    # Get boolean of intersects, and use it to set distance to infinity wherever there is no intersection\n",
        "    intersects = (u >= 0) & (v >= 0) & (u + v <= 1) & ~is_singular\n",
        "    s[~intersects] = float(\"inf\")  # t.inf\n",
        "\n",
        "    # Get the minimum distance (over all triangles) for each ray\n",
        "    return einops.reduce(s, \"NR NT -> NR\", \"min\")\n",
        "\n",
        "\n",
        "num_pixels_y = 120\n",
        "num_pixels_z = 120\n",
        "y_limit = z_limit = 1\n",
        "\n",
        "rays = make_rays_2d(num_pixels_y, num_pixels_z, y_limit, z_limit)\n",
        "rays[:, 0] = t.tensor([-2, 0.0, 0.0])\n",
        "dists = raytrace_mesh(rays, triangles)\n",
        "intersects = t.isfinite(dists).view(num_pixels_y, num_pixels_z)\n",
        "dists_square = dists.view(num_pixels_y, num_pixels_z)\n",
        "img = t.stack([intersects, dists_square], dim=0)\n",
        "\n",
        "fig = px.imshow(img, facet_col=0, origin=\"lower\", color_continuous_scale=\"magma\", width=1000)\n",
        "fig.update_layout(coloraxis_showscale=False)\n",
        "for i, text in enumerate([\"Intersects\", \"Distance\"]):\n",
        "    fig.layout.annotations[i][\"text\"] = text\n",
        "fig.show()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAX50r28bPgh"
      },
      "source": [
        "Congratulations, you've now got to the end of the exercises! Read on for some more bonus material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ6GIt0vbPgh"
      },
      "source": [
        "# 4️⃣ Video & Lighting\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Learn how surface normal vectors can be used to compute lighting effects\n",
        "> - Render your figures in video form (as an animated camera pan)\n",
        "> - (optional) Learn about the `pytest` library, and write your own tests for the functions you wrote"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_OoH76abPgh"
      },
      "source": [
        "Here, we've included some more raytracing exercises, which extend the previous animation by providing video and lighting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtuJe9f2bPgh"
      },
      "source": [
        "### Exercise - rotation matrix\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Below is some code to iterate through a range of angles, rotating the pikachu model around the y-axis and raytracing the mesh at each angle. These frames are then concatenated together and animated into some dramatic footage! Your job is to fill in the `rotation_matrix` function, which should give you a matrix that rotates counterclockwise around the y-axis by a given angle `theta` (which is a scalar tensor). If you're stuck, see [this Wikipedia page](https://en.wikipedia.org/wiki/Rotation_matrix#Basic_3D_rotations) on basic 3D rotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-1ZBY16bPgh"
      },
      "outputs": [],
      "source": [
        "def rotation_matrix(theta: Float[Tensor, \"\"]) -> Float[Tensor, \"rows cols\"]:\n",
        "    \"\"\"\n",
        "    Creates a rotation matrix representing a counterclockwise rotation of `theta` around the y-axis.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "tests.test_rotation_matrix(rotation_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fOUemk8bPgh"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def rotation_matrix(theta: Float[Tensor, \"\"]) -> Float[Tensor, \"rows cols\"]:\n",
        "    \"\"\"\n",
        "    Creates a rotation matrix representing a counterclockwise rotation of `theta` around the y-axis.\n",
        "    \"\"\"\n",
        "    return t.tensor(\n",
        "        [\n",
        "            [t.cos(theta), 0.0, t.sin(theta)],\n",
        "            [0.0, 1.0, 0.0],\n",
        "            [-t.sin(theta), 0.0, t.cos(theta)],\n",
        "        ]\n",
        "    )\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIdJe3CrbPgh"
      },
      "source": [
        "Once you've passed the tests, you can run the code below to create an animation! It might take a while to run, but should be no longer than 2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_IS33gAbPgh"
      },
      "outputs": [],
      "source": [
        "def raytrace_mesh_video(\n",
        "    rays: Float[Tensor, \"nrays points dim\"],\n",
        "    triangles: Float[Tensor, \"ntriangles points dims\"],\n",
        "    rotation_matrix: Callable[[float], Float[Tensor, \"rows cols\"]],\n",
        "    raytrace_function: Callable,\n",
        "    num_frames: int,\n",
        ") -> Bool[Tensor, \"nframes nrays\"]:\n",
        "    \"\"\"\n",
        "    Creates a stack of raytracing results, rotating the triangles by `rotation_matrix` each frame.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    theta = t.tensor(2 * t.pi) / num_frames\n",
        "    R = rotation_matrix(theta)\n",
        "    for theta in tqdm(range(num_frames)):\n",
        "        triangles = triangles @ R\n",
        "        result.append(raytrace_function(rays, triangles))\n",
        "        t.cuda.empty_cache()  # clears GPU memory (this line will be more important later on!)\n",
        "    return t.stack(result, dim=0)\n",
        "\n",
        "\n",
        "def display_video(distances: Float[Tensor, \"frames y z\"]):\n",
        "    \"\"\"\n",
        "    Displays video of raytracing results, using Plotly. `distances` is a tensor where the [i, y, z] element is distance\n",
        "    to the closest triangle for the i-th frame & the [y, z]-th ray in our 2D grid of rays.\n",
        "    \"\"\"\n",
        "    px.imshow(\n",
        "        distances,\n",
        "        animation_frame=0,\n",
        "        origin=\"lower\",\n",
        "        zmin=0.0,\n",
        "        zmax=distances[distances.isfinite()].quantile(0.99).item(),\n",
        "        color_continuous_scale=\"viridis_r\",  # \"Brwnyl\"\n",
        "    ).update_layout(coloraxis_showscale=False, width=550, height=600, title=\"Raytrace mesh video\").show()\n",
        "\n",
        "\n",
        "num_pixels_y = 250\n",
        "num_pixels_z = 250\n",
        "y_limit = z_limit = 0.8\n",
        "num_frames = 50\n",
        "\n",
        "rays = make_rays_2d(num_pixels_y, num_pixels_z, y_limit, z_limit)\n",
        "rays[:, 0] = t.tensor([-3.0, 0.0, 0.0])\n",
        "dists = raytrace_mesh_video(rays, triangles, rotation_matrix, raytrace_mesh, num_frames)\n",
        "dists = einops.rearrange(dists, \"frames (y z) -> frames y z\", y=num_pixels_y)\n",
        "\n",
        "display_video(dists)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suL9FqZDbPgh"
      },
      "source": [
        "### Exercise - use GPUs\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴⚪⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "We'll discuss GPUs a lot more in later sections and exercises. For now, One last thing to discuss before we move onto training our model: **GPUs**. Essentially, the GPU (graphics processing unit) is a specialized processor for rendering graphics and doing other kinds of parallel processing. Although we are actually using it for graphics in this section, it's much better known today for its role in deep learning, since it allows for efficient parallelized computations.\n",
        "\n",
        "When you create a tensor, by default it's located on the CPU. You can use the `to` method to move your tensor between devices, i.e. `x = x.to(\"cuda\")` to move to the GPU, and `x = x.to(\"cpu\")` to move back to the CPU (or `x = x.cuda()` and `x = x.cpu()` as a shorthand). **CUDA** stands for Compute Unified Device Architecture, a parallel computing platform and programming model developed by NVIDIA which is supported by PyTorch. Note that this method returns a copy of the tensor rather than the tensor itself (unless the `to` command doesn't change its device). You can check whether CUDA is available by calling `t.cuda.is_available()` - if it's not, you can try installing a CUDA-supporting version of PyTorch from the [homepage](https://pytorch.org/).\n",
        "\n",
        "Below, you should write the `raytrace_mesh_gpu` function to be identical to `raytrace_mesh`, except that the computation should be done on the GPU. This means `triangles` and `rays` should be moved to the GPU before the computation is done, and the returned object should be moved back to the CPU before finishing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0ufdp0zbPgh"
      },
      "outputs": [],
      "source": [
        "def raytrace_mesh_gpu(\n",
        "    rays: Float[Tensor, \"nrays rayPoints=2 dims=3\"], triangles: Float[Tensor, \"ntriangles trianglePoints=3 dims=3\"]\n",
        ") -> Float[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return the distance to the closest intersecting triangle, or infinity.\n",
        "\n",
        "    All computations should be performed on the GPU.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "dists = raytrace_mesh_video(rays, triangles, rotation_matrix, raytrace_mesh_gpu, num_frames)\n",
        "dists = einops.rearrange(dists, \"frames (y z) -> frames y z\", y=num_pixels_y)\n",
        "display_video(dists)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ0GS1NgbPgh"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def raytrace_mesh_gpu(\n",
        "    rays: Float[Tensor, \"nrays rayPoints=2 dims=3\"], triangles: Float[Tensor, \"ntriangles trianglePoints=3 dims=3\"]\n",
        ") -> Float[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return the distance to the closest intersecting triangle, or infinity.\n",
        "\n",
        "    All computations should be performed on the GPU.\n",
        "    \"\"\"\n",
        "    NR = rays.size(0)\n",
        "    NT = triangles.size(0)\n",
        "    device = \"cuda\"\n",
        "    triangles = triangles.to(device)\n",
        "    rays = rays.to(device)\n",
        "\n",
        "    # Each triangle is [[Ax, Ay, Az], [Bx, By, Bz], [Cx, Cy, Cz]]\n",
        "    triangles = einops.repeat(triangles, \"NT pts dims -> pts NR NT dims\", NR=NR)\n",
        "    A, B, C = triangles\n",
        "    assert A.shape == (NR, NT, 3)\n",
        "\n",
        "    # Each ray is [[Ox, Oy, Oz], [Dx, Dy, Dz]]\n",
        "    rays = einops.repeat(rays, \"NR pts dims -> pts NR NT dims\", NT=NT)\n",
        "    O, D = rays\n",
        "    assert O.shape == (NR, NT, 3)\n",
        "\n",
        "    # Define matrix on left hand side of equation\n",
        "    mat: Float[Tensor, \"NR NT 3 3\"] = t.stack([-D, B - A, C - A], dim=-1)\n",
        "    # Get boolean of where matrix is singular, and replace it with the identity in these positions\n",
        "    dets: Float[Tensor, \"NR NT\"] = t.linalg.det(mat)\n",
        "    is_singular = dets.abs() < 1e-8\n",
        "    mat[is_singular] = t.eye(3).to(device)\n",
        "\n",
        "    # Define vector on the right hand side of equation\n",
        "    vec: Float[Tensor, \"NR NT 3\"] = O - A\n",
        "\n",
        "    # Solve eqns (note, s is the distance along ray)\n",
        "    sol: Float[Tensor, \"NR NT 3\"] = t.linalg.solve(mat, vec)\n",
        "    s, u, v = sol.unbind(-1)\n",
        "\n",
        "    # Get boolean of intersects, and use it to set distance to infinity wherever there is no intersection\n",
        "    intersects = (s >= 0) & (u >= 0) & (v >= 0) & (u + v <= 1) & ~is_singular\n",
        "    s[~intersects] = t.inf\n",
        "\n",
        "    # Get the minimum distance (over all triangles) for each ray\n",
        "    return einops.reduce(s, \"NR NT -> NR\", \"min\").cpu()\n",
        "\n",
        "\n",
        "dists = raytrace_mesh_video(rays, triangles, rotation_matrix, raytrace_mesh_gpu, num_frames)\n",
        "dists = einops.rearrange(dists, \"frames (y z) -> frames y z\", y=num_pixels_y)\n",
        "display_video(dists)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IDT_H85bPgh"
      },
      "source": [
        "### Exercise (bonus) - add lighting\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴🔴\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You've done all the essential content for today at this point.\n",
        "> You can complete this exercise for fun if you have time, or just read & run the solution!\n",
        "> ```\n",
        "\n",
        "We can improve our images by adding lighting, i.e. coloring triangles based on the angle of some light source rather than just from distance from the origin. The most common way to do this is using the [Lambertian reflection model](https://en.wikipedia.org/wiki/Lambertian_reflectance), which says that the intensity of the light that reflects off a surface is proportional to the cosine of the angle between the light vector and the surface normal (or equivalently, proportional to their dot product, assuming both vectors are normalized).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/raytracing-lighting-2.png\" width=\"750\">\n",
        "\n",
        "You should implement the `raytrace_mesh_lambert` function below, which puts this into practice. In other words, your function should return the following for each ray:\n",
        "\n",
        "- Zero if there is no intersection, i.e. distance to every triangle is infinite\n",
        "- `intensity + ambient_intensity` if there is an interesection, where `ambient_intensity` is a value we give you (minimum brightness for a triangle, to distinguish it from the black background) and `intensity` is the intensity of light hitting the triangle, i.e. the dot product of the triangle's normal vector and the light vector, set to zero if this dot product is negative.\n",
        "\n",
        "To emphasize - unlike in your previous functions where you used the distance of each ray to the nearest triangle to determine the color of a given ray/pixel, here every triangle has a unique intensity value and the color of a given ray/pixel is determined only by what its nearest triangle is. The only reason we still need to compute distances is to compute what (if any) the first triangle is that the ray intersects with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUf3QkPPbPgh"
      },
      "outputs": [],
      "source": [
        "def raytrace_mesh_lambert(\n",
        "    rays: Float[Tensor, \"nrays points=2 dims=3\"],\n",
        "    triangles: Float[Tensor, \"ntriangles points=3 dims=3\"],\n",
        "    light: Float[Tensor, \"dims=3\"],\n",
        "    ambient_intensity: float,\n",
        "    device: str = \"cuda\",\n",
        ") -> Float[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return the intensity of light hitting the triangle it intersects with (or zero if no intersection).\n",
        "\n",
        "    Args:\n",
        "        rays:               A tensor of rays, with shape `[nrays, 2, 3]`.\n",
        "        triangles:          A tensor of triangles, with shape `[ntriangles, 3, 3]`.\n",
        "        light:              A tensor representing the light vector, with shape `[3]`. We compue the intensity as the dot\n",
        "                            product of the triangle normals & the light vector, then set it to be zero if the sign is\n",
        "                            negative.\n",
        "        ambient_intensity:  A float representing the ambient intensity. This is the minimum brightness for a triangle,\n",
        "                            to differentiate it from the black background (rays that don't hit any triangle).\n",
        "        device:             The device to perform the computation on.\n",
        "\n",
        "    Returns:\n",
        "        A tensor of intensities for each of the rays, flattened over the [y, z] dimensions. The values are zero when\n",
        "        there is no intersection, and `ambient_intensity + intensity` when there is an interesection (where `intensity`\n",
        "        is the dot product of the triangle's normal vector and the light vector, truncated at zero).\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def display_video_with_lighting(intensity: Float[Tensor, \"frames y z\"]):\n",
        "    \"\"\"\n",
        "    Displays video of raytracing results, using Plotly. `distances` is a tensor where the [i, y, z] element is the\n",
        "    lighting intensity based on the angle of light & the surface of the triangle which this ray hits first.\n",
        "    \"\"\"\n",
        "    px.imshow(\n",
        "        intensity,\n",
        "        animation_frame=0,\n",
        "        origin=\"lower\",\n",
        "        color_continuous_scale=\"magma\",\n",
        "    ).update_layout(coloraxis_showscale=False, width=550, height=600, title=\"Raytrace mesh video (lighting)\").show()\n",
        "\n",
        "\n",
        "ambient_intensity = 0.5\n",
        "light = t.tensor([0.0, -1.0, 1.0])\n",
        "raytrace_function = partial(raytrace_mesh_lambert, ambient_intensity=ambient_intensity, light=light)\n",
        "\n",
        "intensity = raytrace_mesh_video(rays, triangles, rotation_matrix, raytrace_function, num_frames)\n",
        "intensity = einops.rearrange(intensity, \"frames (y z) -> frames y z\", y=num_pixels_y)\n",
        "display_video_with_lighting(intensity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKyxIVRvbPgh"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm not sure how to compute the normal vectors.</summary>\n",
        "\n",
        "You can use the `torch.cross` function, using two edges of the triangle as arguments. For example, you can compute the un-normalized vectors as:\n",
        "\n",
        "```python\n",
        "normals = t.cross(triangles[:, 2] - triangles[:, 0], triangles[:, 1] - triangles[:, 0], dim=1)\n",
        "```\n",
        "\n",
        "which will have the same shape as each of `triangles[:, i]`.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm not sure how to set the intensity to zero if the light is coming from the wrong side of the triangle.</summary>\n",
        "\n",
        "The `pikachu.stl` file stores triangles in a consistent orientation based on the right hand rule. Assuming you chose a consistent method for computing normal vectors like the one in the dropdown above, your computed intensity values per triangle will either all be the correct sign or all be the opposite sign to the true signed values. This means you can either use `t.where(intensity > 0, intensity, 0.0)` or `t.where(intensity < 0, -intensity, 0.0)` as your final zeroed intensity values and both should look fine (although one will look like the light source is coming from the opposite direction to the other). It doesn't matter which orientation you choose.\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def raytrace_mesh_lambert(\n",
        "    rays: Float[Tensor, \"nrays points=2 dims=3\"],\n",
        "    triangles: Float[Tensor, \"ntriangles points=3 dims=3\"],\n",
        "    light: Float[Tensor, \"dims=3\"],\n",
        "    ambient_intensity: float,\n",
        "    device: str = \"cuda\",\n",
        ") -> Float[Tensor, \"nrays\"]:\n",
        "    \"\"\"\n",
        "    For each ray, return the intensity of light hitting the triangle it intersects with (or zero if no intersection).\n",
        "\n",
        "    Args:\n",
        "        rays:               A tensor of rays, with shape `[nrays, 2, 3]`.\n",
        "        triangles:          A tensor of triangles, with shape `[ntriangles, 3, 3]`.\n",
        "        light:              A tensor representing the light vector, with shape `[3]`. We compue the intensity as the dot\n",
        "                            product of the triangle normals & the light vector, then set it to be zero if the sign is\n",
        "                            negative.\n",
        "        ambient_intensity:  A float representing the ambient intensity. This is the minimum brightness for a triangle,\n",
        "                            to differentiate it from the black background (rays that don't hit any triangle).\n",
        "        device:             The device to perform the computation on.\n",
        "\n",
        "    Returns:\n",
        "        A tensor of intensities for each of the rays, flattened over the [y, z] dimensions. The values are zero when\n",
        "        there is no intersection, and `ambient_intensity + intensity` when there is an interesection (where `intensity`\n",
        "        is the dot product of the triangle's normal vector and the light vector, truncated at zero).\n",
        "    \"\"\"\n",
        "    NR = rays.size(0)\n",
        "    NT = triangles.size(0)\n",
        "    triangles = triangles.to(device)\n",
        "    rays = rays.to(device)\n",
        "\n",
        "    # Each triangle is [[Ax, Ay, Az], [Bx, By, Bz], [Cx, Cy, Cz]]\n",
        "    triangles_repeated = einops.repeat(triangles, \"NT pts dims -> pts NR NT dims\", NR=NR)\n",
        "    A, B, C = triangles_repeated\n",
        "    assert A.shape == (NR, NT, 3)\n",
        "\n",
        "    # Each ray is [[Ox, Oy, Oz], [Dx, Dy, Dz]]\n",
        "    rays_repeated = einops.repeat(rays, \"NR pts dims -> pts NR NT dims\", NT=NT)\n",
        "    O, D = rays_repeated\n",
        "    assert O.shape == (NR, NT, 3)\n",
        "\n",
        "    # Define matrix on left hand side of equation\n",
        "    mat: Float[Tensor, \"NR NT 3 3\"] = t.stack([-D, B - A, C - A], dim=-1)\n",
        "    # Get boolean of where matrix is singular, and replace it with the identity in these positions\n",
        "    dets: Float[Tensor, \"NR NT\"] = t.linalg.det(mat)\n",
        "    is_singular = dets.abs() < 1e-8\n",
        "    mat[is_singular] = t.eye(3).to(device)\n",
        "\n",
        "    # Define vector on the right hand side of equation\n",
        "    vec: Float[Tensor, \"NR NT 3\"] = O - A\n",
        "\n",
        "    # Solve eqns (note, s is the distance along ray)\n",
        "    sol: Float[Tensor, \"NR NT 3\"] = t.linalg.solve(mat, vec)\n",
        "    s, u, v = sol.unbind(-1)  # each shape [NR, NT]\n",
        "\n",
        "    # Get boolean of intersects, and use it to set distance to infinity wherever there is no intersection\n",
        "    intersects = (s >= 0)(u >= 0) & (v >= 0) & (u + v <= 1) & ~is_singular\n",
        "    s[~intersects] = float(\"inf\")\n",
        "\n",
        "    # Get the minimum distance (over all triangles) for each ray\n",
        "    closest_distances, closest_triangles_for_each_ray = s.min(dim=-1)  # both shape [NR]\n",
        "\n",
        "    # Get the intensity by taking dot product of triangle normals & light vector\n",
        "    normals = t.cross(triangles[:, 2] - triangles[:, 0], triangles[:, 1] - triangles[:, 0], dim=1)  # shape [NT dims]\n",
        "    normals /= normals.norm(dim=1, keepdim=True)\n",
        "    intensity_per_triangle = einops.einsum(normals, light.to(device), \"nt dims, dims -> nt\")\n",
        "    intensity_per_triangle_signed = t.where(intensity_per_triangle > 0, intensity_per_triangle, 0.0)\n",
        "\n",
        "    # Get intensity for each ray, and add ambient intensity where there's an intersection\n",
        "    intensity = intensity_per_triangle_signed[closest_triangles_for_each_ray] + ambient_intensity\n",
        "\n",
        "    # Set to zero if the ray doesn't intersect with any triangle\n",
        "    intensity = t.where(closest_distances.isfinite(), intensity, 0.0)\n",
        "\n",
        "    return intensity.cpu()\n",
        "\n",
        "\n",
        "def display_video_with_lighting(intensity: Float[Tensor, \"frames y z\"]):\n",
        "    \"\"\"\n",
        "    Displays video of raytracing results, using Plotly. `distances` is a tensor where the [i, y, z] element is the\n",
        "    lighting intensity based on the angle of light & the surface of the triangle which this ray hits first.\n",
        "    \"\"\"\n",
        "    px.imshow(\n",
        "        intensity,\n",
        "        animation_frame=0,\n",
        "        origin=\"lower\",\n",
        "        color_continuous_scale=\"magma\",\n",
        "    ).update_layout(coloraxis_showscale=False, width=550, height=600, title=\"Raytrace mesh video (lighting)\").show()\n",
        "\n",
        "\n",
        "ambient_intensity = 0.5\n",
        "light = t.tensor([0.0, -1.0, 1.0])\n",
        "raytrace_function = partial(raytrace_mesh_lambert, ambient_intensity=ambient_intensity, light=light)\n",
        "\n",
        "intensity = raytrace_mesh_video(rays, triangles, rotation_matrix, raytrace_function, num_frames)\n",
        "intensity = einops.rearrange(intensity, \"frames (y z) -> frames y z\", y=num_pixels_y)\n",
        "display_video_with_lighting(intensity)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gO5GVyWbPgh"
      },
      "source": [
        "As a final bonus exercise before we conclude, you can try rendering with a **wireframe**, i.e. only including the edges of the triangles rather than the full triangle. All you have to do here is change your `triangle_ray_intersects` function, so that it only detects intersection at a certain subset of the parameter values `u` and `v` (can you see how to do this?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlBp77q9bPgi"
      },
      "source": [
        "## Bonus - testing with `pytest`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO28aaCLbPgi"
      },
      "source": [
        "> *Note - this section was also just written with VSCode in mind, so it might be less suitable for Colab, and you might consider skipping it.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RirPaGEGbPgi"
      },
      "source": [
        "To wrap up today, we're going to have a further discussion of **testing**. So far, our test functions have been pretty simple - we imported a test from the `part1_ray_tracing/tests.py` file, and ran it to compare our answers to the answers in `part1_ray_tracing/solutions.py`. This works perfectly fine, but there are other Python libraries which can make testing easier and more powerful. In particular, two such libraries are `unittest` and `pytest`. Both these libraries provide extensive features for modularizing and running test functions, and have nice integrations with VSCode. `unittest` is very powerful, but also has a steep learning curve and isn't worth the trouble of learning during a 6 week course. However, `pytest` is very useful and easy to learn, so we'll spend some time here discussing it.\n",
        "\n",
        "The pytest framework makes it easy to write small, readable tests, and can scale to support complex functional testing for applications and libraries. Today we'll just discuss a few features which will be particularly useful for the kinds of tests we'll be writing, but you're welcome to explore more tests later on.\n",
        "\n",
        "*Important note - if you're working on Colab or a notebook for these exercises, your tests won't work, because in this setup we'll be importing answers from our test file, rather than importing tests from our answers file. For this reason, we won't be using pytest for the structured exercises in this course (in case anybody is following these exercises in a notebook), but you're strongly recommended to use pytest when you're working from `.py` files instead - which is strongly recommended during much of the bonus content.*\n",
        "\n",
        "First, look at `part1_ray_tracing/tests.py`. The tests in this file all follow a similar pattern: evaluate your function on some input, check it equals the solution. This is a clear sign that we can use modularization to simplify our code! Compare this file to `part1_ray_tracing/test_with_pytest.py`, which contains the same tests but refactored using pytest. The latter is clearly separated into three sections: one for library imports, one for defining the inputs we'll use for our test functions, and one where we define our test functions.\n",
        "\n",
        "### Parametrization\n",
        "\n",
        "We use `pytest.mark.parametrize` to parametrize our tests. This means we can run the same test a bunch of different times on different inputs. In the non-pytest version, we did this by defining different functions (e.g. `test_intersect_ray_1d` and `test_intersect_ray_1d_special_case`), but this isn't necessary here.\n",
        "\n",
        "The syntax of a function decorated by `pytest.mark.parametrize` is:\n",
        "\n",
        "```python\n",
        "@pytest.mark.parametrize(\"arg1, arg2, arg3\", [\n",
        "    (val1, val2, val3),\n",
        "    (val4, val5, val6),\n",
        "    ...\n",
        "])\n",
        "def test_function(arg1, arg2, arg3):\n",
        "    ...\n",
        "```\n",
        "\n",
        "This will result in running `test_function` multiple times, the first time with `arg1=val1, arg2=val2, arg3=val3`, and the second time with `arg1=val4, arg2=val5, arg3=val6`, etc. This is a much better way to write tests, because it makes it easy for us to add new test cases without having to write new functions.\n",
        "\n",
        "### How to run these tests?\n",
        "\n",
        "There are three ways to run the above tests:\n",
        "\n",
        "1. **From the terminal**\n",
        "\n",
        "You can run them from the command line using the pytest command. Open your terminal in VSCode at the bottom of the screen, make sure you're in the directory `chapter0_fundamentals`, then enter the command `pytest`. This will search the current directory (or subdirectories) for any python files with the prefix `test_`, and within that file run all functions with the prefix `test_` (i.e. all the tests for these exercises).\n",
        "\n",
        "You can also add more complicated commands, like:\n",
        "\n",
        "* `pytest test_intersect_ray_1d` to specify the file to run tests from\n",
        "* `pytest test_intersect_ray_1d::test_intersect_ray_1d` to specify the file and test function\n",
        "\n",
        "2. **From your Python file**\n",
        "\n",
        "To do this, you need to call `pytest.main` (make sure this is wrapped in an `if MAIN` block). The first argument of this function is a list of args to `pytest`. This has analogous syntax to the command line option, for instance here are a few ways you can do this:\n",
        "\n",
        "```python\n",
        "pytest.main([])\n",
        "pytest.main([\"test_part1_ray_tracing.py\"])\n",
        "pytest.main([\"test_part1_ray_tracing.py::test_intersect_ray_1d\"])\n",
        "```\n",
        "\n",
        "3. **From VSCode's testing display**\n",
        "\n",
        "This is by far the most useful way to run test functions. VSCode provides a helpful interface to run all test functions in your directory, and see which of them have passed. First, press the test icon on the left hand sidebar (it will look like a triangular flask). If this is your first time, then you'll need to click on the **Configure Python Tests** button, then select `pytest` as your framework (you may have to install pytest when prompted). This should automatically perform test discovery for you, showing you all the test files & functions in your current directory in the left hand window (it detects this the same way pytest does, using the `test_` prefix). You can hover over tests or files to see options like \"run test(s)\" or debug test(s)\". When you run them, you'll see a tick or cross appear next to the test, indicating whether it passed or failed.\n",
        "\n",
        "This is a very useful interface when you're working on a large project, because as you make updates you can easily re-run all tests, then identify & fix problems.\n",
        "\n",
        "<details>\n",
        "<summary>Help - I get <code>Error discovering pytest tests</code></summary>\n",
        "\n",
        "Try opening your terminal (at the bottom of the screen) and running `pytest --collect-only`. This should print output that helps you diagnose the problem.\n",
        "\n",
        "One possible issue is changing directories within your python files (e.g. with `os.chdir`), because this can often confuse PyTest's search for tests.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsVYCTHmbPgi"
      },
      "source": [
        "<details>\n",
        "<summary>Aside - <code># type: ignore</code></summary>\n",
        "\n",
        "Note that the test file has the annotation `# type: ignore` at the end of an import line, at the top of the file. This is because VSCode's typechecker will complain when you try and import a file that doesn't exist yet! This line removes the type error, and allows you to write functions without all those annoying squiggly red lines! However, don't overuse this annotation, because it can often be a signal that you've made a mistake in your code, or else have followed a bad coding practice.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Aside - named tuples</summary>\n",
        "\n",
        "Another way you can clean this code up is to use **named tuples**. These are an especially nice and Pythonic structure which maintains the features of a tuple, but also allows you to define instances & access elements by name. For instance, instead of:\n",
        "\n",
        "```python\n",
        "ray_segment_batch = (\n",
        "    solutions.rays1d,\n",
        "    solutions.segments\n",
        ")\n",
        "```\n",
        "\n",
        "you could have:\n",
        "\n",
        "```python\n",
        "from collections import namedtuple\n",
        "TestCase = namedtuple(\"TestCase\", \"rays segments\")\n",
        "\n",
        "ray_segment_batch = TestCase(\n",
        "    rays = solutions.rays1d,\n",
        "    segments = solutions.segments\n",
        ")\n",
        "```\n",
        "\n",
        "and this `ray_segment_batch` object would still be treated like a tensor when it's used in a parameterized test.\n",
        "\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0a79012eb5c4678b6b4fe43dfe6ee68": {
          "model_module": "jupyterlab-plotly",
          "model_name": "FigureModel",
          "model_module_version": "^5.24.1",
          "state": {
            "_config": {
              "plotlyServerURL": "https://plot.ly"
            },
            "_data": [
              {
                "x": [],
                "y": [],
                "type": "scatter",
                "uid": "999efce1-388c-44ff-8ed9-df8920929091"
              }
            ],
            "_dom_classes": [],
            "_js2py_layoutDelta": null,
            "_js2py_pointsCallback": null,
            "_js2py_relayout": null,
            "_js2py_restyle": {},
            "_js2py_traceDeltas": null,
            "_js2py_update": {},
            "_last_layout_edit_id": 41,
            "_last_trace_edit_id": 4,
            "_layout": {},
            "_model_module": "jupyterlab-plotly",
            "_model_module_version": "^5.24.1",
            "_model_name": "FigureModel",
            "_py2js_addTraces": null,
            "_py2js_animate": {},
            "_py2js_deleteTraces": {},
            "_py2js_moveTraces": {},
            "_py2js_relayout": null,
            "_py2js_removeLayoutProps": null,
            "_py2js_removeTraceProps": {},
            "_py2js_restyle": {},
            "_py2js_update": null,
            "_view_count": 1,
            "_view_module": "jupyterlab-plotly",
            "_view_module_version": "^5.24.1",
            "_view_name": "FigureView"
          }
        },
        "3bef4abd682b4496a7444c7667736126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd75869c15f0470fad4f883dacb48989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae824706a2c42069758ff0f5233f83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "d9c32151f25c4cbb81f22c3c11ea2d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d230dfba894960b77d2062ce1ab315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66b70d30a10e43bdac5f2810d463d8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f8a3669ad340dd9bb43e4f42821f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72d7e2c9a16c4dcdb3f67d709921c604",
              "IPY_MODEL_a525a11a0ecd4c8db87bd03aa2df57d7",
              "IPY_MODEL_7c5c63daf4d641799aaff4e230c1ec75"
            ],
            "layout": "IPY_MODEL_3bef4abd682b4496a7444c7667736126"
          }
        },
        "72d7e2c9a16c4dcdb3f67d709921c604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "v",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_dd75869c15f0470fad4f883dacb48989",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.01,
            "style": "IPY_MODEL_6ae824706a2c42069758ff0f5233f83a",
            "value": 0
          }
        },
        "a525a11a0ecd4c8db87bd03aa2df57d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "0",
              "1",
              "2",
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "seed",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_d9c32151f25c4cbb81f22c3c11ea2d3f",
            "style": "IPY_MODEL_b2d230dfba894960b77d2062ce1ab315"
          }
        },
        "7c5c63daf4d641799aaff4e230c1ec75": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_66b70d30a10e43bdac5f2810d463d8e2",
            "msg_id": "",
            "outputs": []
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}